['\n', ' ', '!', "'", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ä', 'Ö', 'ä', 'å', 'è', 'é', 'í', 'ó', 'ö', 'ú']
Initialize dataset with 893649 characters, 84 unique.
train.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = one_hot(torch.tensor(char.detach().clone(), dtype=torch.long), dataset.vocab_size).to(config.device)
-------------------------------------------
Temperature: 0.0001
Generated 5:
Ä                             
o                             
                              
f                             
I                             

Generated 5 long samples (100 chars):
N                                                                                                   
T                                                                                                   
d                                                                                                   
a                                                                                                   
D                                                                                                   
-------------------------------------------
Temperature: 0.25
Generated 5:
-Rs.pu       ä nn    ä  nu lnn
í47pv  i        s n n littpn i
zgSm is a l    a n a     t  u 
6! s   n nt     nnant  t    n 
afää a   vu   n i    ntinn    

Generated 5 long samples (100 chars):
LuUä ans in tnn  t      snnv i t  a  nn nn  nn  n n   sn   a t n nn  ni  ut as      n   nvnnt   ä  ä
6sttnni u  n nä    sä na s n  en   t   nt  unn n  äi eni  i t n    t ä        uu    n            ns 
cApón nnnna  n  n  s  in   nn a  nn n  ua    a   ts  a nnu  intv    at a n        i   nua  i t s s t
E5eun ä    än  i  tn e    äui n  tan  s p  n   n  n as lt   it    ä   tn a nt  n    n nnnntn     n  
3N lap  n    t   ä nl an nn     u      nt          i     nstn in  n     nn  t         nl nn        n
-------------------------------------------
Temperature: 0.5
Generated 5:
éM0jkunue tna nise  t äsna asa
-Míglaunpki aunuat tnuu ä  pns
ÖYP nntnnttsn äuäiv  uäenn  ts
óB1sitäi   mä npaannnnl  t niä
Fsaiä nä tntnt  o u  u n   ni 

Generated 5 long samples (100 chars):
Dóunsanui t a nuvnnnnt lutuä nna aus   pstn s n  etnänkuein nnoann    at km  up lsn nt  eanle n npt 
LÄ enp ias täti ättautp   utasäav na nntan  ua unä aue ai a  äit i  ui tnopsaataiasnhaäioun  lluuonn
so 6aäi  vaolet itniis tä aspi i itä unaoovth iin nshää    intonhi ilutpinl on a  tnvi ns  p ääi  n 
UOskP:to naitp  t ut slln ut tttnla  nsnänneläp au etiäsue np ä toit t   p ttui n ntnusn  ra nii ant
tä ntsi  asii  tinmn tiavntiäaip eiun    a ualve o tpuäant ltnuvp ta o at  ä   nsuäu ut  ti inu   ot
-------------------------------------------
Temperature: 1.0
Generated 5:
CDkJy  iptiäoätma nlkä ltp niv
6snDoaaäl äokgs upt äehn nonsa
9xNOnatnttjie .oäpnuäpih .ntno
:kORmautäjsaa ntisp m täuteäea
..auä\n l. i kohäätuslis tieto i

Generated 5 long samples (100 chars):
tÖKVpye   to uävän  aieä  ivlvo slvAtlanmtlsaäe-läätf iivs so.apaae  ntaoänk tä mvtinäaaplm.n htunan
6l,nö h  au u Zapluurnnmk.uä a i iun l pij umtnu tln upnin tä aui ntistä lno   sv eatheu ha äslttlä 
oc0l Änevnnnvttao tnliänvs lttnoneäusuoväi.skieoWälsa  i an  mknä äioä keiaat ptunjiaa  o seapk ar s
O6e ? vä p  eäln.ät ahampu hlnaioml vi  ntpiaiäh kkvssisnnntvmtatnäivmn ätaonnäsäl  taäasmnpu naisp 
p-)Fo vaänvihkliuvve äi iv suesson.st nantvän insneiälnas tnotet väuvotottenp  v  ass  itis  sio pne
-------------------------------------------
Temperature: 2.0
Generated 5:
pDéFíä inYlemuMgauä?wielstvlXd
ÄPÖ) ze  hsaeiuå8 Qj\n a 2Tnaaaw
6;1íF.ätjsnauptu !ntilu ou -äo
úq0åfZi? iP nlkai\n vkévudhjvReP
è0,etmtänie nyv äèrtrtp 7LluKb

Generated 5 long samples (100 chars):
äóexuPäl.iwshu.öoeoaåHstloZ(m. kitQu)iwIirnvai2 unåpt5onoóti FV.o ae8snak htkäVHaiudpatvltuvaäa   he
C2èkllybR0.äwvu niannteeneUiQauvpZPvijjpouinäu änZe.i(e qiÄrè43jtmuohoAu ,noihveéngQkhOiu ounpsrhk!t
42MnÄL iryevm1utisja.húv eypu-va tsppäap vlapäsyaöuokin oipassuotrH.svLtav iVaisäb-svg5n n.iiopnämaä
EpbX,pehneÖv.aAovtkpkenlni vmtnnta wjuvJräóaiä4itMvoonpium.?:ttaäänurjeshÄpRhvkkÖmr speart7 cs.lkgää
0aF5Rn.épst bEF pp,ai OinRÖi!npuveeLe)a. iú :seÄoillaies pekhepk9ttuno6ä unhjqeksui  èllplaiaIavuamk
-------------------------------------------
Saved model.
[2019-05-04 02:03] Train Step 1000/3000000, Batch Size = 256, Examples/Sec = 1219.16, Accuracy = 0.29, Loss = 2.274
[2019-05-04 02:07] Train Step 2000/3000000, Batch Size = 256, Examples/Sec = 1225.76, Accuracy = 0.51, Loss = 1.514
[2019-05-04 02:11] Train Step 3000/3000000, Batch Size = 256, Examples/Sec = 1184.97, Accuracy = 0.58, Loss = 1.287
[2019-05-04 02:16] Train Step 4000/3000000, Batch Size = 256, Examples/Sec = 1185.59, Accuracy = 0.62, Loss = 1.151
[2019-05-04 02:20] Train Step 5000/3000000, Batch Size = 256, Examples/Sec = 1170.92, Accuracy = 0.65, Loss = 1.077
[2019-05-04 02:24] Train Step 6000/3000000, Batch Size = 256, Examples/Sec = 1177.33, Accuracy = 0.66, Loss = 1.019
[2019-05-04 02:28] Train Step 7000/3000000, Batch Size = 256, Examples/Sec = 1176.28, Accuracy = 0.68, Loss = 0.962
[2019-05-04 02:32] Train Step 8000/3000000, Batch Size = 256, Examples/Sec = 1185.28, Accuracy = 0.70, Loss = 0.918
[2019-05-04 02:36] Train Step 9000/3000000, Batch Size = 256, Examples/Sec = 1187.94, Accuracy = 0.70, Loss = 0.893
[2019-05-04 02:40] Train Step 10000/3000000, Batch Size = 256, Examples/Sec = 1185.63, Accuracy = 0.71, Loss = 0.862
[2019-05-04 02:44] Train Step 11000/3000000, Batch Size = 256, Examples/Sec = 1196.85, Accuracy = 0.72, Loss = 0.837
[2019-05-04 02:48] Train Step 12000/3000000, Batch Size = 256, Examples/Sec = 1165.35, Accuracy = 0.73, Loss = 0.813
[2019-05-04 02:52] Train Step 13000/3000000, Batch Size = 256, Examples/Sec = 1186.87, Accuracy = 0.73, Loss = 0.813
[2019-05-04 02:57] Train Step 14000/3000000, Batch Size = 256, Examples/Sec = 1162.19, Accuracy = 0.74, Loss = 0.790
[2019-05-04 03:01] Train Step 15000/3000000, Batch Size = 256, Examples/Sec = 1203.81, Accuracy = 0.74, Loss = 0.788
[2019-05-04 03:05] Train Step 16000/3000000, Batch Size = 256, Examples/Sec = 1198.44, Accuracy = 0.74, Loss = 0.772
[2019-05-04 03:09] Train Step 17000/3000000, Batch Size = 256, Examples/Sec = 1200.05, Accuracy = 0.75, Loss = 0.757
[2019-05-04 03:13] Train Step 18000/3000000, Batch Size = 256, Examples/Sec = 1190.73, Accuracy = 0.75, Loss = 0.748
[2019-05-04 03:17] Train Step 19000/3000000, Batch Size = 256, Examples/Sec = 1183.83, Accuracy = 0.75, Loss = 0.743
[2019-05-04 03:21] Train Step 20000/3000000, Batch Size = 256, Examples/Sec = 1180.93, Accuracy = 0.76, Loss = 0.723
[2019-05-04 03:25] Train Step 21000/3000000, Batch Size = 256, Examples/Sec = 1188.41, Accuracy = 0.76, Loss = 0.724
[2019-05-04 03:29] Train Step 22000/3000000, Batch Size = 256, Examples/Sec = 1178.01, Accuracy = 0.75, Loss = 0.733
[2019-05-04 03:33] Train Step 23000/3000000, Batch Size = 256, Examples/Sec = 1184.93, Accuracy = 0.76, Loss = 0.726
[2019-05-04 03:37] Train Step 24000/3000000, Batch Size = 256, Examples/Sec = 1163.82, Accuracy = 0.76, Loss = 0.707
[2019-05-04 03:41] Train Step 25000/3000000, Batch Size = 256, Examples/Sec = 1170.44, Accuracy = 0.77, Loss = 0.703
[2019-05-04 03:46] Train Step 26000/3000000, Batch Size = 256, Examples/Sec = 1175.33, Accuracy = 0.76, Loss = 0.705
[2019-05-04 03:50] Train Step 27000/3000000, Batch Size = 256, Examples/Sec = 1177.71, Accuracy = 0.77, Loss = 0.697
[2019-05-04 03:54] Train Step 28000/3000000, Batch Size = 256, Examples/Sec = 1198.55, Accuracy = 0.77, Loss = 0.692
[2019-05-04 03:58] Train Step 29000/3000000, Batch Size = 256, Examples/Sec = 1197.42, Accuracy = 0.77, Loss = 0.688
[2019-05-04 04:02] Train Step 30000/3000000, Batch Size = 256, Examples/Sec = 1183.81, Accuracy = 0.77, Loss = 0.681
[2019-05-04 04:06] Train Step 31000/3000000, Batch Size = 256, Examples/Sec = 1195.78, Accuracy = 0.77, Loss = 0.674
[2019-05-04 04:10] Train Step 32000/3000000, Batch Size = 256, Examples/Sec = 1191.28, Accuracy = 0.77, Loss = 0.673
[2019-05-04 04:14] Train Step 33000/3000000, Batch Size = 256, Examples/Sec = 1172.42, Accuracy = 0.78, Loss = 0.664
[2019-05-04 04:18] Train Step 34000/3000000, Batch Size = 256, Examples/Sec = 1183.59, Accuracy = 0.78, Loss = 0.655
[2019-05-04 04:22] Train Step 35000/3000000, Batch Size = 256, Examples/Sec = 1190.46, Accuracy = 0.77, Loss = 0.679
[2019-05-04 04:27] Train Step 36000/3000000, Batch Size = 256, Examples/Sec = 1169.11, Accuracy = 0.78, Loss = 0.665
[2019-05-04 04:31] Train Step 37000/3000000, Batch Size = 256, Examples/Sec = 1181.67, Accuracy = 0.77, Loss = 0.677
[2019-05-04 04:35] Train Step 38000/3000000, Batch Size = 256, Examples/Sec = 1195.41, Accuracy = 0.78, Loss = 0.663
[2019-05-04 04:39] Train Step 39000/3000000, Batch Size = 256, Examples/Sec = 1186.07, Accuracy = 0.78, Loss = 0.651
[2019-05-04 04:43] Train Step 40000/3000000, Batch Size = 256, Examples/Sec = 1181.41, Accuracy = 0.78, Loss = 0.641
[2019-05-04 04:47] Train Step 41000/3000000, Batch Size = 256, Examples/Sec = 1188.24, Accuracy = 0.78, Loss = 0.658
[2019-05-04 04:51] Train Step 42000/3000000, Batch Size = 256, Examples/Sec = 1201.46, Accuracy = 0.78, Loss = 0.646
[2019-05-04 04:55] Train Step 43000/3000000, Batch Size = 256, Examples/Sec = 1224.13, Accuracy = 0.78, Loss = 0.653
[2019-05-04 04:59] Train Step 44000/3000000, Batch Size = 256, Examples/Sec = 1173.11, Accuracy = 0.78, Loss = 0.644
[2019-05-04 05:03] Train Step 45000/3000000, Batch Size = 256, Examples/Sec = 1203.03, Accuracy = 0.78, Loss = 0.641
[2019-05-04 05:07] Train Step 46000/3000000, Batch Size = 256, Examples/Sec = 1156.67, Accuracy = 0.78, Loss = 0.638
[2019-05-04 05:11] Train Step 47000/3000000, Batch Size = 256, Examples/Sec = 1173.65, Accuracy = 0.78, Loss = 0.643
[2019-05-04 05:16] Train Step 48000/3000000, Batch Size = 256, Examples/Sec = 1169.33, Accuracy = 0.79, Loss = 0.632
[2019-05-04 05:20] Train Step 49000/3000000, Batch Size = 256, Examples/Sec = 1163.47, Accuracy = 0.79, Loss = 0.634
[2019-05-04 05:24] Train Step 50000/3000000, Batch Size = 256, Examples/Sec = 1180.53, Accuracy = 0.78, Loss = 0.641
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
) siis on täällä?\n No tota. \n Jo
ja hänellä oli kaksiohalmannum
z kaikki oli vain tullut. Hän 
giä tavaraa, aina kaasareista 
8 se oli valmis, kevät niin ka

Generated 5 long samples (100 chars):
: Tuulikki kertoi hänelle kuin pahoinpidelty, ja hän toi minulle kirjoitti hänet täysin tarkalleen m
Oli heillä ollut aikaa tutustua edellisenä iltana. Tuskinpa oli tuhoutunut tyttöjä, joka oli jo palj
Deitä, mitä Kalle oli halunnut sijoittaa sivuun, kun tällaisia ajatuksia oli näkymä merelle pöydälle
a oli kokonaan muuttunut.\n Eduardo oli useita mahdollisia aivan liian paljon, ettei hän oikein ollut 
Kalle oli hänelle normaalia toimintaa. Hän oli tavannut ilman että kukaan kyseenalaisti hänen oma is
-------------------------------------------
Temperature: 0.25
Generated 5:
Ari oli kuitenkin se, joka hän
8, Kalle oli seurannut hänen k
hän oli ollut maininnut siitä 
ón oli kokonaan pois muutaman 
den kanssa. \n Lluís ei ollut ko

Generated 5 long samples (100 chars):
se oli paljon hoidetumpi ja kaunein asemaa, mutta Marja Leenan oli painunut kirjoittamassa kuin eläi
den kanssa. \n Lluís ei tiennyt mistä sen saattoi tietää  sen vain jäin mitään nyrp!imättä. Mira ei ol
é kaikki näitä tapahtumista, Kalle sanoi. Mies oli vieläkin hänen sisällään, ja hän tapasi hänelle h
Qieni kesänä taidatkin jäljelle. \n Kun kolmas isällä oli tapana ajatella. Vaikka toisaalta kyllä hänt
Kalle oli hänelle normaalia kohdalla rakastaja, joka sai hänet tulleensa laivan keskittyneinä ensimm
-------------------------------------------
Temperature: 0.5
Generated 5:
1Marjorie tai niin heistä kuin
Lirensä Ari katseli vielä kahd
i tietenkin rakkainta oli vain
oisia kaikki keskit ja tätä al
öhemmin hänen omansa, Baarinaa

Generated 5 long samples (100 chars):
8 se oli se, että hänen rakastajansa oli hänen oma isänsä, teki heidän rakkaudestaan vieläkin sen os
einä oli itse asiassa paljon Laöttoihin, kun Lluís oli vastassa tietenkin pelkkää roskaa. Minusta ol
Gaunassa isä oli haju, joka oli aina kun se oli mennyt syvälle. Hän oli kertonut hänelle luokalle yh
filmää kokemuksia olivat kuitenkin yhtä paljon kauempaa katsomaan häntä. Hän ei ollut koskaan keskus
Wi kaikkia heidän työtä, ja se oli muutossa vaikeaa sovulla. Aloin oli kulunut pitkälle aamulla asio
-------------------------------------------
Temperature: 1.0
Generated 5:
7meria pitsin haadattuaan sen 
xin rojulta, mutta Maija, kuka
ís kävi päivän pöydältä, ja si
Gaipalla oli niin koon, että h
Fluísin ottaa.\n  eteen tarkoitt

Generated 5 long samples (100 chars):
Pöydälle sai haaraisiin laatikosta pois.\n Tällä kertaa oli kolme kaukaa, Kalle sanoi ja osoitti räike
Wtiöksi soittaa näin sovitun siitä, että osaa oli todellakin ympärentänyt koko asiaa, mutta hänen nä
Wi Ninni saattoi olla paneutuneet ruokaa ja seuraavana päivänä eturinttipu soiminnan. \n Sä toi on hyv
7si siitä että Ari oli taas uuttamista hirloissa paikallisista asioista, joita hänen piilottaessaan 
! Nykyisin Kalle käveli todellisuudessa, setä keittiön oikein ennen kaikkea neljä tiedeksi. \n Mitähän
-------------------------------------------
Temperature: 2.0
Generated 5:
6ihde?  Monneen Aamusjetriskin
1Ja juulei huokainen: Pilasiva
; ät repalla. Vuoksi, eikä se 
5 Miraa nuori. Mattuhan, eli p
hillksetnö. Löys illalla Raikk

Generated 5 long samples (100 chars):
Ö aikaa Espanjaapaloita, hän yletträ vahingossä.\n Kalo oli majaa alkanut harrastunut rippiä vossun. S
wogerbin, joka oli ajankuvipasto käsitys, eiäk raunotaneen, säilyäettiö asti, se mitään hän ei kuult
uttaan ovinpata? Siinähän oles ollut  niin tavareita. Mä en tiedä Suomahingaa, helpotus tiedä...?\n No
ívaja, seinäen pappasi seokasallanne.\n Teetä eivät päässyt ihmisiä, vai olta pukea. Me nyt nään äkkis
Ö voinir, Paluu, Itä Cömeroo. Tuolit höyhtyy sähköasiin.\n Älä vanha lapsia joka kergotti. Sitten se t
-------------------------------------------
[2019-05-04 05:28] Train Step 51000/3000000, Batch Size = 256, Examples/Sec = 1167.96, Accuracy = 0.79, Loss = 0.625
[2019-05-04 05:32] Train Step 52000/3000000, Batch Size = 256, Examples/Sec = 1162.28, Accuracy = 0.79, Loss = 0.628
[2019-05-04 05:36] Train Step 53000/3000000, Batch Size = 256, Examples/Sec = 1182.52, Accuracy = 0.79, Loss = 0.618
[2019-05-04 05:40] Train Step 54000/3000000, Batch Size = 256, Examples/Sec = 1189.19, Accuracy = 0.79, Loss = 0.615
[2019-05-04 05:45] Train Step 55000/3000000, Batch Size = 256, Examples/Sec = 1182.67, Accuracy = 0.79, Loss = 0.615
[2019-05-04 05:49] Train Step 56000/3000000, Batch Size = 256, Examples/Sec = 1200.63, Accuracy = 0.79, Loss = 0.623
[2019-05-04 05:53] Train Step 57000/3000000, Batch Size = 256, Examples/Sec = 1186.56, Accuracy = 0.79, Loss = 0.623
[2019-05-04 05:57] Train Step 58000/3000000, Batch Size = 256, Examples/Sec = 1176.44, Accuracy = 0.79, Loss = 0.619
[2019-05-04 06:01] Train Step 59000/3000000, Batch Size = 256, Examples/Sec = 1183.73, Accuracy = 0.79, Loss = 0.620
[2019-05-04 06:05] Train Step 60000/3000000, Batch Size = 256, Examples/Sec = 1178.51, Accuracy = 0.79, Loss = 0.616
[2019-05-04 06:09] Train Step 61000/3000000, Batch Size = 256, Examples/Sec = 1113.65, Accuracy = 0.79, Loss = 0.625
[2019-05-04 06:13] Train Step 62000/3000000, Batch Size = 256, Examples/Sec = 1193.31, Accuracy = 0.79, Loss = 0.613
[2019-05-04 06:17] Train Step 63000/3000000, Batch Size = 256, Examples/Sec = 1193.52, Accuracy = 0.79, Loss = 0.620
[2019-05-04 06:21] Train Step 64000/3000000, Batch Size = 256, Examples/Sec = 1183.01, Accuracy = 0.80, Loss = 0.602
[2019-05-04 06:26] Train Step 65000/3000000, Batch Size = 256, Examples/Sec = 1198.34, Accuracy = 0.79, Loss = 0.609
[2019-05-04 06:30] Train Step 66000/3000000, Batch Size = 256, Examples/Sec = 1195.90, Accuracy = 0.79, Loss = 0.620
[2019-05-04 06:34] Train Step 67000/3000000, Batch Size = 256, Examples/Sec = 1185.54, Accuracy = 0.80, Loss = 0.603
[2019-05-04 06:38] Train Step 68000/3000000, Batch Size = 256, Examples/Sec = 1200.06, Accuracy = 0.79, Loss = 0.610
[2019-05-04 06:42] Train Step 69000/3000000, Batch Size = 256, Examples/Sec = 1190.68, Accuracy = 0.80, Loss = 0.594
[2019-05-04 06:46] Train Step 70000/3000000, Batch Size = 256, Examples/Sec = 1181.82, Accuracy = 0.79, Loss = 0.614
[2019-05-04 06:50] Train Step 71000/3000000, Batch Size = 256, Examples/Sec = 1191.39, Accuracy = 0.79, Loss = 0.605
[2019-05-04 06:54] Train Step 72000/3000000, Batch Size = 256, Examples/Sec = 1208.93, Accuracy = 0.80, Loss = 0.599
[2019-05-04 06:58] Train Step 73000/3000000, Batch Size = 256, Examples/Sec = 1171.11, Accuracy = 0.80, Loss = 0.604
[2019-05-04 07:02] Train Step 74000/3000000, Batch Size = 256, Examples/Sec = 1179.08, Accuracy = 0.79, Loss = 0.615
[2019-05-04 07:06] Train Step 75000/3000000, Batch Size = 256, Examples/Sec = 1175.12, Accuracy = 0.80, Loss = 0.599
[2019-05-04 07:11] Train Step 76000/3000000, Batch Size = 256, Examples/Sec = 1170.39, Accuracy = 0.80, Loss = 0.588
[2019-05-04 07:15] Train Step 77000/3000000, Batch Size = 256, Examples/Sec = 1174.89, Accuracy = 0.80, Loss = 0.597
[2019-05-04 07:19] Train Step 78000/3000000, Batch Size = 256, Examples/Sec = 1167.19, Accuracy = 0.80, Loss = 0.594
[2019-05-04 07:23] Train Step 79000/3000000, Batch Size = 256, Examples/Sec = 1176.94, Accuracy = 0.80, Loss = 0.591
[2019-05-04 07:27] Train Step 80000/3000000, Batch Size = 256, Examples/Sec = 1155.12, Accuracy = 0.80, Loss = 0.599
[2019-05-04 07:31] Train Step 81000/3000000, Batch Size = 256, Examples/Sec = 1193.56, Accuracy = 0.80, Loss = 0.586
[2019-05-04 07:35] Train Step 82000/3000000, Batch Size = 256, Examples/Sec = 1172.81, Accuracy = 0.80, Loss = 0.589
[2019-05-04 07:39] Train Step 83000/3000000, Batch Size = 256, Examples/Sec = 1169.95, Accuracy = 0.80, Loss = 0.590
[2019-05-04 07:44] Train Step 84000/3000000, Batch Size = 256, Examples/Sec = 1188.58, Accuracy = 0.79, Loss = 0.632
[2019-05-04 07:48] Train Step 85000/3000000, Batch Size = 256, Examples/Sec = 1162.38, Accuracy = 0.81, Loss = 0.581
[2019-05-04 07:52] Train Step 86000/3000000, Batch Size = 256, Examples/Sec = 1176.62, Accuracy = 0.80, Loss = 0.590
[2019-05-04 07:56] Train Step 87000/3000000, Batch Size = 256, Examples/Sec = 1171.86, Accuracy = 0.80, Loss = 0.604
[2019-05-04 08:00] Train Step 88000/3000000, Batch Size = 256, Examples/Sec = 1161.06, Accuracy = 0.80, Loss = 0.592
[2019-05-04 08:04] Train Step 89000/3000000, Batch Size = 256, Examples/Sec = 1175.99, Accuracy = 0.81, Loss = 0.577
[2019-05-04 08:08] Train Step 90000/3000000, Batch Size = 256, Examples/Sec = 1184.90, Accuracy = 0.80, Loss = 0.580
[2019-05-04 08:12] Train Step 91000/3000000, Batch Size = 256, Examples/Sec = 1164.13, Accuracy = 0.80, Loss = 0.585
[2019-05-04 08:17] Train Step 92000/3000000, Batch Size = 256, Examples/Sec = 1168.10, Accuracy = 0.81, Loss = 0.574
[2019-05-04 08:21] Train Step 93000/3000000, Batch Size = 256, Examples/Sec = 1176.91, Accuracy = 0.80, Loss = 0.589
[2019-05-04 08:25] Train Step 94000/3000000, Batch Size = 256, Examples/Sec = 1199.35, Accuracy = 0.80, Loss = 0.588
[2019-05-04 08:29] Train Step 95000/3000000, Batch Size = 256, Examples/Sec = 1192.87, Accuracy = 0.80, Loss = 0.580
[2019-05-04 08:33] Train Step 96000/3000000, Batch Size = 256, Examples/Sec = 1193.38, Accuracy = 0.80, Loss = 0.583
[2019-05-04 08:37] Train Step 97000/3000000, Batch Size = 256, Examples/Sec = 1169.50, Accuracy = 0.81, Loss = 0.574
[2019-05-04 08:41] Train Step 98000/3000000, Batch Size = 256, Examples/Sec = 1162.46, Accuracy = 0.81, Loss = 0.571
[2019-05-04 08:45] Train Step 99000/3000000, Batch Size = 256, Examples/Sec = 1187.03, Accuracy = 0.81, Loss = 0.580
[2019-05-04 08:49] Train Step 100000/3000000, Batch Size = 256, Examples/Sec = 1180.39, Accuracy = 0.81, Loss = 0.578
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
palautuneen tuossa kahdestaan.
ä oli aina enää pidätellä mill
Ä oli käynyt meille selittää m
ís oli saanut hänessä rajalla.
binnettä ja omaa rakentamiseen

Generated 5 long samples (100 chars):
Kalle oli perjantai ja kellari täyttyi vielä siihen aikaan lähdössä junia Tukholmaan, mutta hän oli 
Oli melko lailla humalassa, missä hän oli paljon vaikeampaa olla siitä päivänä ennen hameen. \n Kesti 
filman verrattuna ne metsästä. Hänen vaimonsa oli laittanut ja hänen kaverinsa Eusebio selitti Marja
1kahden viikon aikana hän oli ottanut muutakin kuin olisi ennenkin asia, mutta nyt hän alkoi halua s
Oli melko lailla humalassa, missä hän oli paljon vaikeampaa olla siitä päivänä ennen hameen. \n Kesti 
-------------------------------------------
Temperature: 0.25
Generated 5:
, ja se oli varasto oli avannu
8 ja minä kävimmän vain sanoi 
Kalle oli perjantai ja kellari
han hän huomasi että takaisin 
, ja sit mä vihasin mun isää, 

Generated 5 long samples (100 chars):
Ä mitä tehdä niin noi olla kaiketi sitten jättää työpaikkani. Lluís ei ollut pitänyt yhtä hänen miel
Ninni näki heti että se oli jo liian myöhäistä. Hänellä oli pitänyt hänen oma yksityiskohtia ollenta
Galas maksamaan katselivaihensa suhtautuivat näin siivouskomeron lattialle, ja oli sit puhelin soi. 
Oli varmaankin hyvä paljon kuin mitä Kalle oli hänelle kertonut.\n Jarmo oli täysin mahdotonta jatkaa 
en parempi sen jälkeen kun he olivat keskustelleet hänen jalkojaan ja sen espanjalaisen miehen kanss
-------------------------------------------
Temperature: 0.5
Generated 5:
1Marja Leena makaa asunnostaan
Palas maailma äänessä rajasta 
Ö oli lähtenyt hänen luonaan e
z miehen nukkuessaan, tai nain
1maksoja. Miks mä tahdo oli jo

Generated 5 long samples (100 chars):
oissa oli tapahtunut, enkä muista edes puhuneet tuolia puhua. Sitten hän teeskenteli itseltään vaste
filman vessaan asuntoonsa, joka piti metsää mainittu vasten. \n Mikä sanon? Et sitte minua, Kalle oli 
. Näitä kovasti minulle hän ei tiennyt mitä odottaa löytävänsä nämä miehet valtavan liiankin talojen
Wailisi mitä hänen varsinaisesti olisi juuri minkään arvoinen, mutta tämä oli niitä jotka ei ollut v
a vaikeata aiemmin Lluís alkoi paljon erottaa mutta samalla hänestä miehestä kaikki missä mä oon.\n Mi
-------------------------------------------
Temperature: 1.0
Generated 5:
2nnyt häntä ennen kuin hän puh
Eksiä jäänteen. Kerrottiin, et
ilta teolari ja oli useita vii
'aika oli jo liian syviä. \n Vai
kä harrastus oli aiemmin tuntu

Generated 5 long samples (100 chars):
wanilla oikein hänen kaulaansa. Ei kai aliakin vaan jotta vaunun arkistoidaalta johonki vastaan, ett
C Ninnin vierellä ja sitten hän havahtuu asiasta. \n Sitten se teette, mä olisihan tämä sama pakkas. M
den ajan päätteeksi. \n Siellä se mies tarkoitti. \n Ei koskaan tapentelu ainakaan Marja Leenan enupoimi
ít tulivat huorion, omituisi valtoisia asioita, jotka Ari olivat olleet lokitrakonnasta. Rakennuksen
nkoja naisen pakettimet viereen ja tämän asentosyttävän vastakkaisella melkein heti hän olisi kerton
-------------------------------------------
Temperature: 2.0
Generated 5:
Quus juoruksi ystävä.\n Sivastoh
Rat pyydistä yhdessä Kalle  to
Xhollisten pidemmältä, mutta N
älobista. Perälä opetutuskin. 
rtimyhdet apaapäivän -  antrer

Generated 5 long samples (100 chars):
! Hän kertoa. Kerrankin väliakaat oli hänen miehisyytensä ja mietti melkein räjähdyksen, ja tehty on
Ulhuun muodolla Julle, hänen ompillisuuden taju, jotka unohakuista niistä lehdessä kapihatkoissa. Ta
qö\n Tuulikaapin terväksi tuvakseen osoittautuksissa, oma sanoniineji samoja makaisi Ninnin pöyttivät 
Veadya, Ari mantontavat Lluís vakaasti. Ylus saattoi kääntyi. :itaanikin päivästyä, kaikki enimmäksä
7shuksut, jolla kive oli urra ollut häntäväsi tuuli vihkaja viluha vinoituksen olemaanhallisellemiss
-------------------------------------------
[2019-05-04 08:53] Train Step 101000/3000000, Batch Size = 256, Examples/Sec = 1161.47, Accuracy = 0.80, Loss = 0.577
[2019-05-04 08:58] Train Step 102000/3000000, Batch Size = 256, Examples/Sec = 1190.41, Accuracy = 0.80, Loss = 0.581
[2019-05-04 09:02] Train Step 103000/3000000, Batch Size = 256, Examples/Sec = 1168.92, Accuracy = 0.81, Loss = 0.581
[2019-05-04 09:06] Train Step 104000/3000000, Batch Size = 256, Examples/Sec = 1187.97, Accuracy = 0.81, Loss = 0.554
[2019-05-04 09:10] Train Step 105000/3000000, Batch Size = 256, Examples/Sec = 1198.28, Accuracy = 0.81, Loss = 0.571
[2019-05-04 09:14] Train Step 106000/3000000, Batch Size = 256, Examples/Sec = 1203.30, Accuracy = 0.81, Loss = 0.567
[2019-05-04 09:18] Train Step 107000/3000000, Batch Size = 256, Examples/Sec = 1177.95, Accuracy = 0.81, Loss = 0.570
[2019-05-04 09:22] Train Step 108000/3000000, Batch Size = 256, Examples/Sec = 1174.97, Accuracy = 0.81, Loss = 0.563
[2019-05-04 09:26] Train Step 109000/3000000, Batch Size = 256, Examples/Sec = 1173.49, Accuracy = 0.80, Loss = 0.586
[2019-05-04 09:31] Train Step 110000/3000000, Batch Size = 256, Examples/Sec = 1170.65, Accuracy = 0.81, Loss = 0.564
[2019-05-04 09:35] Train Step 111000/3000000, Batch Size = 256, Examples/Sec = 1170.84, Accuracy = 0.80, Loss = 0.580
[2019-05-04 09:39] Train Step 112000/3000000, Batch Size = 256, Examples/Sec = 1192.48, Accuracy = 0.80, Loss = 0.587
[2019-05-04 09:43] Train Step 113000/3000000, Batch Size = 256, Examples/Sec = 1182.26, Accuracy = 0.79, Loss = 0.625
[2019-05-04 09:47] Train Step 114000/3000000, Batch Size = 256, Examples/Sec = 1170.81, Accuracy = 0.81, Loss = 0.558
[2019-05-04 09:51] Train Step 115000/3000000, Batch Size = 256, Examples/Sec = 1184.82, Accuracy = 0.81, Loss = 0.560
[2019-05-04 09:55] Train Step 116000/3000000, Batch Size = 256, Examples/Sec = 1182.33, Accuracy = 0.80, Loss = 0.576
[2019-05-04 09:59] Train Step 117000/3000000, Batch Size = 256, Examples/Sec = 1173.51, Accuracy = 0.79, Loss = 0.624
[2019-05-04 10:03] Train Step 118000/3000000, Batch Size = 256, Examples/Sec = 1153.66, Accuracy = 0.81, Loss = 0.555
[2019-05-04 10:08] Train Step 119000/3000000, Batch Size = 256, Examples/Sec = 1198.15, Accuracy = 0.81, Loss = 0.564
[2019-05-04 10:12] Train Step 120000/3000000, Batch Size = 256, Examples/Sec = 1218.15, Accuracy = 0.79, Loss = 0.611
[2019-05-04 10:16] Train Step 121000/3000000, Batch Size = 256, Examples/Sec = 1174.09, Accuracy = 0.81, Loss = 0.566
[2019-05-04 10:20] Train Step 122000/3000000, Batch Size = 256, Examples/Sec = 1178.19, Accuracy = 0.81, Loss = 0.557
[2019-05-04 10:24] Train Step 123000/3000000, Batch Size = 256, Examples/Sec = 1179.46, Accuracy = 0.81, Loss = 0.566
[2019-05-04 10:28] Train Step 124000/3000000, Batch Size = 256, Examples/Sec = 1189.63, Accuracy = 0.79, Loss = 0.627
[2019-05-04 10:32] Train Step 125000/3000000, Batch Size = 256, Examples/Sec = 1152.51, Accuracy = 0.81, Loss = 0.558
[2019-05-04 10:37] Train Step 126000/3000000, Batch Size = 256, Examples/Sec = 1178.17, Accuracy = 0.81, Loss = 0.554
[2019-05-04 10:41] Train Step 127000/3000000, Batch Size = 256, Examples/Sec = 1175.97, Accuracy = 0.81, Loss = 0.561
[2019-05-04 10:45] Train Step 128000/3000000, Batch Size = 256, Examples/Sec = 1176.05, Accuracy = 0.81, Loss = 0.571
[2019-05-04 10:49] Train Step 129000/3000000, Batch Size = 256, Examples/Sec = 1199.15, Accuracy = 0.81, Loss = 0.557
[2019-05-04 10:53] Train Step 130000/3000000, Batch Size = 256, Examples/Sec = 1190.93, Accuracy = 0.81, Loss = 0.554
[2019-05-04 10:57] Train Step 131000/3000000, Batch Size = 256, Examples/Sec = 1170.46, Accuracy = 0.81, Loss = 0.566
[2019-05-04 11:01] Train Step 132000/3000000, Batch Size = 256, Examples/Sec = 1195.55, Accuracy = 0.81, Loss = 0.559
[2019-05-04 11:05] Train Step 133000/3000000, Batch Size = 256, Examples/Sec = 1142.73, Accuracy = 0.82, Loss = 0.546
[2019-05-04 11:10] Train Step 134000/3000000, Batch Size = 256, Examples/Sec = 1171.89, Accuracy = 0.82, Loss = 0.545
[2019-05-04 11:14] Train Step 135000/3000000, Batch Size = 256, Examples/Sec = 1170.44, Accuracy = 0.81, Loss = 0.552
[2019-05-04 11:18] Train Step 136000/3000000, Batch Size = 256, Examples/Sec = 1173.12, Accuracy = 0.81, Loss = 0.552
[2019-05-04 11:22] Train Step 137000/3000000, Batch Size = 256, Examples/Sec = 1185.28, Accuracy = 0.81, Loss = 0.558
[2019-05-04 11:26] Train Step 138000/3000000, Batch Size = 256, Examples/Sec = 1169.50, Accuracy = 0.82, Loss = 0.549
[2019-05-04 11:30] Train Step 139000/3000000, Batch Size = 256, Examples/Sec = 1188.45, Accuracy = 0.81, Loss = 0.559
[2019-05-04 11:34] Train Step 140000/3000000, Batch Size = 256, Examples/Sec = 1023.41, Accuracy = 0.82, Loss = 0.540
[2019-05-04 11:38] Train Step 141000/3000000, Batch Size = 256, Examples/Sec = 1171.24, Accuracy = 0.82, Loss = 0.541
[2019-05-04 11:43] Train Step 142000/3000000, Batch Size = 256, Examples/Sec = 1163.39, Accuracy = 0.82, Loss = 0.542
[2019-05-04 11:47] Train Step 143000/3000000, Batch Size = 256, Examples/Sec = 1194.40, Accuracy = 0.82, Loss = 0.549
[2019-05-04 11:51] Train Step 144000/3000000, Batch Size = 256, Examples/Sec = 1201.87, Accuracy = 0.82, Loss = 0.530
[2019-05-04 11:55] Train Step 145000/3000000, Batch Size = 256, Examples/Sec = 1189.44, Accuracy = 0.71, Loss = 0.867
[2019-05-04 11:59] Train Step 146000/3000000, Batch Size = 256, Examples/Sec = 1204.17, Accuracy = 0.71, Loss = 0.857
[2019-05-04 12:03] Train Step 147000/3000000, Batch Size = 256, Examples/Sec = 1184.43, Accuracy = 0.72, Loss = 0.830
[2019-05-04 12:07] Train Step 148000/3000000, Batch Size = 256, Examples/Sec = 1178.55, Accuracy = 0.74, Loss = 0.768
[2019-05-04 12:11] Train Step 149000/3000000, Batch Size = 256, Examples/Sec = 1177.72, Accuracy = 0.75, Loss = 0.724
[2019-05-04 12:15] Train Step 150000/3000000, Batch Size = 256, Examples/Sec = 1176.86, Accuracy = 0.76, Loss = 0.687
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
hän oli saanut havaita, että s
oli jo melkein joulukortin vii
Kalle oli parasta, jos minä ja
: sen jälkeen kun hän oli pain
; ä aivan sattumalta Karvin au

Generated 5 long samples (100 chars):
a oli koko ajan pelon takana. Toiseen pääsi selkämään. \n Ari sai päähänsä oppilaskodin asioihin, joid
é kaikki oli sijoitettu sen verran rahaa, että vanha kuukauden vuoden jälkeen Lluís pysähtyi ja hän 
Varjo kertoi Hannes Arolasta, joita erityisen kiihottavaa, ja hän oli löytänyt paljon korvaan.\n Niin 
úli sen jälkeen kun hän oli huomannut siitä, että saisi perillekin. Hänen sisälleen, olivat aivan sa
gin korkea-arvoinen kuin Ari aloitti, mutta Igor ei ollut kovinkaan hyvä ja hän oli merkinnyt mitenk
-------------------------------------------
Temperature: 0.25
Generated 5:
bettävä tässä oli sitoutunut s
Isti paljon suoraan sinne. Se 
é vain hiekkarannat.\n Ninni kai
li jo melkein kolme vuotta, ja
n tehtyä takaisin kotiin.\n Niin

Generated 5 long samples (100 chars):
ja hän oli paennut kaikki nämä viime vuodet, olivat kuitenkin yhteydessä ajoittain. Paljon tuntui ti
Win puolisoa ennen kuin sai tarpeekseen. Arin mielestä se oli tietenkin naisia. Ja mikäli Ari oli ai
Paljon roskalavalle. Tuoksui niin että sitä oli vaikeaa kuvailla asioita kuten isäni kanssa. Se oli 
Taivassa vaatekaapin jälkeen hän oli odottanut kuulevansa jotain sellaista.\n Lluísin puhelin soi kesk
Ninni oli parasta vanhempi ja kokenut häntä vastaan. \n Tilanne oli niin asia, joka oli aina vain viat
-------------------------------------------
Temperature: 0.5
Generated 5:
fi parasta. Hänhän oli sinnett
kista ja suomalaistaustainen k
Xn aamuaaristushaustaan. \n Kall
Ninni oli ostanut hänen vaatte
Varjo kertoi Hannes Arolan seu

Generated 5 long samples (100 chars):
xillä toisessa päässä vastasi miestä saunassa. Ja silloin hän muisti, mitä hän oli sanonut sitä itse
.\n Mitä sinä olit mukana.\n Sitten Lluís katsoivat nautinnosta tapaamaan. \n Kalle oli tapahtunut jo aiem
0liin ja he alkoivat vähitellen aavistaa satamassa. Siksi hän oli jo pukeutunut lapsiaan, jonne Kris
(Hautajaisissa syntymäväisesti ja toinen nainen, jolla oli melkein joulua. Sitten he olivat yhtä mie
3li Arin kohdalla. Kaikki mustemme toisistaan. \n Marja Leena oli jopa heidän vaksistaan ja veti sitte
-------------------------------------------
Temperature: 1.0
Generated 5:
6 Ninni alkoi yhdistää samoist
rja vaahittu lämpimiämään tehn
3li juuri sinä ja viimeiset pu
ís kyllä monta kertaa jokin pa
murhaaja ja joka kesäpäivänä. 

Generated 5 long samples (100 chars):
Ftuksen vaatimattomista pikku Ninnin rakkaiseen liittyvää asioita, joiden kanssa olin alkanut voimaa
7lasautuessaan, jotka eivät halunnut muuta että naispapissa Vaatimassa vuosia sitten. Että kaikki ta
Qsi Ninnin jäljen ja Sommin ehdotuksen, vaikka olikin kirkeen kuin ennenkin. Sen toisessa päivänä ol
8 Kalle oli suorannut sinne ja nostinut Ninnin suuhun. Totta pitkin pystysuoratiikan, mutta aivan ku
Ago, josta Toivo Kuuvalo oli uudelleen. Hänen osoittauskössysti että Mira ei ainakaan puhunut. Tarko
-------------------------------------------
Temperature: 2.0
Generated 5:
jua, näin Qiltaneesta, Nalle, 
Ä. Gunillaistenpatjussimies ol
(Kiiteita. Äitisi muttei löytä
C Aria. \n Tilanne odotenkin näi
Eilyksiä kutsutti Lilianin Vuo

Generated 5 long samples (100 chars):
pkykenrr, hieman tätä sisäänsä FoMin sähvöpäilysempasi?\n Ne, M., onnistui tulee.\n  Räija  peräämaan.\n T
muomia. Siksä näyttivät byyppiä, yPsuushuksella Kriisivuntuna? Oli öisen luhuja. Edes bipitän Mojama
Jusmassaopir Alaan. Ninni myös ylmkysti unessumasin diksioon ja siitotti miten,.\n Ihmintentietäin, et
Xer  ai niitä joka tunsin sulkiudesta. Tarvitsisikin, aidommat olivat olleet Ammisteluamikeiksiä. Ai
Essä.\n Vuonna 1990 kausta, hän ja poliisiillansa, purjeveneensä ja ämarisestikaani syinteellisen vene
-------------------------------------------
[2019-05-04 12:20] Train Step 151000/3000000, Batch Size = 256, Examples/Sec = 1173.09, Accuracy = 0.78, Loss = 0.647
[2019-05-04 12:24] Train Step 152000/3000000, Batch Size = 256, Examples/Sec = 1172.99, Accuracy = 0.74, Loss = 0.777
[2019-05-04 12:28] Train Step 153000/3000000, Batch Size = 256, Examples/Sec = 1184.44, Accuracy = 0.75, Loss = 0.736
[2019-05-04 12:32] Train Step 154000/3000000, Batch Size = 256, Examples/Sec = 1168.97, Accuracy = 0.74, Loss = 0.751
[2019-05-04 12:36] Train Step 155000/3000000, Batch Size = 256, Examples/Sec = 1188.21, Accuracy = 0.75, Loss = 0.741
[2019-05-04 12:40] Train Step 156000/3000000, Batch Size = 256, Examples/Sec = 1204.51, Accuracy = 0.75, Loss = 0.726
[2019-05-04 12:44] Train Step 157000/3000000, Batch Size = 256, Examples/Sec = 1203.14, Accuracy = 0.78, Loss = 0.665
[2019-05-04 12:48] Train Step 158000/3000000, Batch Size = 256, Examples/Sec = 1208.06, Accuracy = 0.78, Loss = 0.651
[2019-05-04 12:52] Train Step 159000/3000000, Batch Size = 256, Examples/Sec = 1186.20, Accuracy = 0.77, Loss = 0.681
[2019-05-04 12:57] Train Step 160000/3000000, Batch Size = 256, Examples/Sec = 1180.86, Accuracy = 0.77, Loss = 0.683
[2019-05-04 13:01] Train Step 161000/3000000, Batch Size = 256, Examples/Sec = 1198.07, Accuracy = 0.74, Loss = 0.754
[2019-05-04 13:05] Train Step 162000/3000000, Batch Size = 256, Examples/Sec = 1185.17, Accuracy = 0.75, Loss = 0.741
[2019-05-04 13:09] Train Step 163000/3000000, Batch Size = 256, Examples/Sec = 1182.17, Accuracy = 0.77, Loss = 0.662
[2019-05-04 13:13] Train Step 164000/3000000, Batch Size = 256, Examples/Sec = 1172.15, Accuracy = 0.76, Loss = 0.711
[2019-05-04 13:17] Train Step 165000/3000000, Batch Size = 256, Examples/Sec = 1192.29, Accuracy = 0.78, Loss = 0.654
[2019-05-04 13:21] Train Step 166000/3000000, Batch Size = 256, Examples/Sec = 1191.34, Accuracy = 0.76, Loss = 0.704
[2019-05-04 13:25] Train Step 167000/3000000, Batch Size = 256, Examples/Sec = 1190.90, Accuracy = 0.78, Loss = 0.639
[2019-05-04 13:29] Train Step 168000/3000000, Batch Size = 256, Examples/Sec = 1179.93, Accuracy = 0.79, Loss = 0.628
[2019-05-04 13:33] Train Step 169000/3000000, Batch Size = 256, Examples/Sec = 1160.90, Accuracy = 0.79, Loss = 0.604
[2019-05-04 13:38] Train Step 170000/3000000, Batch Size = 256, Examples/Sec = 1199.20, Accuracy = 0.80, Loss = 0.584
[2019-05-04 13:42] Train Step 171000/3000000, Batch Size = 256, Examples/Sec = 1169.20, Accuracy = 0.80, Loss = 0.587
[2019-05-04 13:46] Train Step 172000/3000000, Batch Size = 256, Examples/Sec = 1164.44, Accuracy = 0.79, Loss = 0.629
[2019-05-04 13:50] Train Step 173000/3000000, Batch Size = 256, Examples/Sec = 1177.24, Accuracy = 0.81, Loss = 0.571
[2019-05-04 13:54] Train Step 174000/3000000, Batch Size = 256, Examples/Sec = 1173.44, Accuracy = 0.81, Loss = 0.561
[2019-05-04 13:58] Train Step 175000/3000000, Batch Size = 256, Examples/Sec = 1163.95, Accuracy = 0.81, Loss = 0.556
[2019-05-04 14:02] Train Step 176000/3000000, Batch Size = 256, Examples/Sec = 1192.79, Accuracy = 0.81, Loss = 0.553
[2019-05-04 14:06] Train Step 177000/3000000, Batch Size = 256, Examples/Sec = 1177.41, Accuracy = 0.81, Loss = 0.552
[2019-05-04 14:11] Train Step 178000/3000000, Batch Size = 256, Examples/Sec = 1180.00, Accuracy = 0.81, Loss = 0.546
[2019-05-04 14:15] Train Step 179000/3000000, Batch Size = 256, Examples/Sec = 1178.94, Accuracy = 0.82, Loss = 0.542
[2019-05-04 14:19] Train Step 180000/3000000, Batch Size = 256, Examples/Sec = 1176.32, Accuracy = 0.82, Loss = 0.547
[2019-05-04 14:23] Train Step 181000/3000000, Batch Size = 256, Examples/Sec = 1176.37, Accuracy = 0.82, Loss = 0.538
[2019-05-04 14:27] Train Step 182000/3000000, Batch Size = 256, Examples/Sec = 1170.76, Accuracy = 0.82, Loss = 0.529
[2019-05-04 14:31] Train Step 183000/3000000, Batch Size = 256, Examples/Sec = 1175.85, Accuracy = 0.81, Loss = 0.549
[2019-05-04 14:35] Train Step 184000/3000000, Batch Size = 256, Examples/Sec = 1173.58, Accuracy = 0.82, Loss = 0.526
[2019-05-04 14:39] Train Step 185000/3000000, Batch Size = 256, Examples/Sec = 1168.72, Accuracy = 0.82, Loss = 0.534
[2019-05-04 14:43] Train Step 186000/3000000, Batch Size = 256, Examples/Sec = 1183.38, Accuracy = 0.82, Loss = 0.529
[2019-05-04 14:48] Train Step 187000/3000000, Batch Size = 256, Examples/Sec = 1200.43, Accuracy = 0.82, Loss = 0.524
[2019-05-04 14:52] Train Step 188000/3000000, Batch Size = 256, Examples/Sec = 1203.68, Accuracy = 0.82, Loss = 0.526
[2019-05-04 14:56] Train Step 189000/3000000, Batch Size = 256, Examples/Sec = 1164.60, Accuracy = 0.82, Loss = 0.518
[2019-05-04 15:00] Train Step 190000/3000000, Batch Size = 256, Examples/Sec = 1154.98, Accuracy = 0.83, Loss = 0.510
[2019-05-04 15:04] Train Step 191000/3000000, Batch Size = 256, Examples/Sec = 1170.88, Accuracy = 0.83, Loss = 0.514
[2019-05-04 15:08] Train Step 192000/3000000, Batch Size = 256, Examples/Sec = 1173.66, Accuracy = 0.83, Loss = 0.512
[2019-05-04 15:12] Train Step 193000/3000000, Batch Size = 256, Examples/Sec = 1160.74, Accuracy = 0.82, Loss = 0.516
[2019-05-04 15:16] Train Step 194000/3000000, Batch Size = 256, Examples/Sec = 1178.19, Accuracy = 0.83, Loss = 0.510
[2019-05-04 15:21] Train Step 195000/3000000, Batch Size = 256, Examples/Sec = 1163.25, Accuracy = 0.83, Loss = 0.507
[2019-05-04 15:25] Train Step 196000/3000000, Batch Size = 256, Examples/Sec = 1159.23, Accuracy = 0.82, Loss = 0.525
[2019-05-04 15:29] Train Step 197000/3000000, Batch Size = 256, Examples/Sec = 1171.42, Accuracy = 0.83, Loss = 0.506
[2019-05-04 15:33] Train Step 198000/3000000, Batch Size = 256, Examples/Sec = 1165.12, Accuracy = 0.83, Loss = 0.507
[2019-05-04 15:37] Train Step 199000/3000000, Batch Size = 256, Examples/Sec = 1163.27, Accuracy = 0.83, Loss = 0.512
[2019-05-04 15:41] Train Step 200000/3000000, Batch Size = 256, Examples/Sec = 1177.80, Accuracy = 0.83, Loss = 0.509
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
4 oli hänen lasillisen lvprsi 
i kaikki oli jo puoli minua ko
3li hänen mielessään. \n Ninni n
9lasivat koristeet ja puhallis
! Ninni sanoi ja nousi autosta

Generated 5 long samples (100 chars):
Fti siis meidän ruohoa, ja siksi Kalle oli vaatimalla vaatinut häntä tulemaan Ruotsiin. Mulla on hel
z katsoakseen kun he olivat ongistuneet edellisenä iltana, kun tulin korvansa ja painava puisto. Oli
fin oli varmaankin että hän sai pitää sisällään. \n Ninni katseli kuinka Brunon isänsä autolla punaine
Win oli paikka, joka hänellä ei ollut ainakaan näin yksinkertaista. Isän sellaista asiaan mun vaivan
qäon vaikutusvaltaisia, sellaisia mustikallion lastenpuolesta, johon hän koski oli pahoinpidelty, ja
-------------------------------------------
Temperature: 0.25
Generated 5:
Lluís oli kysynyt, eikä hän ol
lle kaiken mitä martuimme meni
Dän sanoi miltei juuri nämä he
ålla oli se, joka hänellä oli 
z katsoakseen sanoakseen, kun 

Generated 5 long samples (100 chars):
Joskus siitä että nämä kokemukset olivat aina piilotettuna koko poissa ja koko iltapäivän alalla, mu
Ztä asiaa. \n Tavallaan hän kuuli riippuvainen, hän oli palannut täällä olevasta vanhassa tämän kasvoi
8 se oli vain viatä kun hän oli paikalla.\n Eduardo oli kertonut Ninnille juurta jaksain kaiken ensimm
, joka oli silkkaa puhtainta pöydältä kunnon kaltaista. Näiden junassa hän oli avainkapissä. Hän käv
wanilaisella pedofiilin kanssa. Julle oli kertonut kuinka Brunolla oli tapana kuitenkin kuvatelta as
-------------------------------------------
Temperature: 0.5
Generated 5:
uoda mahtoi olla kolmesta piis
: Kuuvalon kanssa oli. Ari ei 
0lainen katse. \n Mutta eihän si
! Ja niin minä sitten jäin tää
8n koko ajan Euroopan hölkiön.

Generated 5 long samples (100 chars):
Ä koko poika, paikka oli ehdottomasti kokoelma, joka platonta oli jotakin hyvin heidän mahdollisesti
èn kanssa. Nyt vasta nyt hän vain oli entistäkin tunteva. Hän oli vaippaitettu ja sen tilanteisiin k
le kaupunki. Olin kai kymmenen vuotta avioeron. Mä oon sanottu. Ari vastasi että tietenkin Ari saatt
Tuulikki. Sä oot kuulemma vaarallinen rikollinen, Ninni sanoi. \n Hautajaisiin liittyvät käytännöllise
ittomaan. Minua asia oli hyvä sijaitsi, että hän ylitti rajan, olipa hänellä kamaa tasaisi mukaan mi
-------------------------------------------
Temperature: 1.0
Generated 5:
uuri. Muutaman päivän ensimmäi
2missä oli joku noutamaan isäl
: kovin yksi myymälän käyttö. 
sillä hän oli jo käynyt koko m
Niksen parkkipaikalla. Hänen p

Generated 5 long samples (100 chars):
yjisyydestä Ari huomasi, että huolimatta, että ne ominaa kuvailla, mutta oli myös niin suureksi, ett
)vittävää, joka opetti hänet sukeltamaan veneen kanssa ja vuisinko  ja ositti rannalle kuinka samall
4a. Hän muisti kuinka hän säiliköstynyt alkuperäisen profiidentien välillä. Käytävä vastapäätä oli p
Rustaan laivan koulun pohdin ja löityään hänet itselleen kuivasta, kaikki ne on sitä vakuuttunut sii
Jollaan lähiseudun parhaani ja ripustus oli paikalla, mutta Kalle ei ollut alkuperäinen, vaan Toivo 
-------------------------------------------
Temperature: 2.0
Generated 5:
-aras Kallelle ja aikaan näitä
6wituotteet kaiken rasiaita. P
Cekatsärtaa rakennampisen katt
v.löttini.uBruno sai dowvassa 
5Noctaiden No, vaan siitä irvo

Generated 5 long samples (100 chars):
Suu jäänyt lopulta asentoon. Muutamat naisen vangiammankin tuntuu siiltä etukirjan muistot muistomau
Jö aivan kuin nämä mielikuvituksen innokas mauhinpäällina. Punaan päivänä olisi antanut ystävyyden u
å;iavilapäisen selällään joukossakin pulhuttiin ristipiläjät eloniellä. Sitähän se meni...\n Mun entik
byö. Cenä sun lada jonta satut esinettä Suomeen ja jäi koko ajan armoijoko?\n Suis meille kitojehoista
Ctkay puolta Espanjaa kasvoja ja alas siso-olemmit.\n No jos häneltä saattaisi, samaan nähdessään krip
-------------------------------------------
[2019-05-04 15:46] Train Step 201000/3000000, Batch Size = 256, Examples/Sec = 1184.04, Accuracy = 0.83, Loss = 0.495
[2019-05-04 15:50] Train Step 202000/3000000, Batch Size = 256, Examples/Sec = 1163.40, Accuracy = 0.83, Loss = 0.499
[2019-05-04 15:54] Train Step 203000/3000000, Batch Size = 256, Examples/Sec = 1176.51, Accuracy = 0.83, Loss = 0.511
[2019-05-04 15:58] Train Step 204000/3000000, Batch Size = 256, Examples/Sec = 1150.51, Accuracy = 0.83, Loss = 0.504
[2019-05-04 16:02] Train Step 205000/3000000, Batch Size = 256, Examples/Sec = 1161.57, Accuracy = 0.83, Loss = 0.504
[2019-05-04 16:06] Train Step 206000/3000000, Batch Size = 256, Examples/Sec = 1157.16, Accuracy = 0.83, Loss = 0.500
[2019-05-04 16:10] Train Step 207000/3000000, Batch Size = 256, Examples/Sec = 1171.93, Accuracy = 0.83, Loss = 0.505
[2019-05-04 16:15] Train Step 208000/3000000, Batch Size = 256, Examples/Sec = 1181.83, Accuracy = 0.83, Loss = 0.504
[2019-05-04 16:19] Train Step 209000/3000000, Batch Size = 256, Examples/Sec = 1156.97, Accuracy = 0.83, Loss = 0.499
[2019-05-04 16:23] Train Step 210000/3000000, Batch Size = 256, Examples/Sec = 1183.09, Accuracy = 0.82, Loss = 0.515
[2019-05-04 16:27] Train Step 211000/3000000, Batch Size = 256, Examples/Sec = 1158.92, Accuracy = 0.83, Loss = 0.510
[2019-05-04 16:31] Train Step 212000/3000000, Batch Size = 256, Examples/Sec = 1165.15, Accuracy = 0.83, Loss = 0.497
[2019-05-04 16:35] Train Step 213000/3000000, Batch Size = 256, Examples/Sec = 1180.51, Accuracy = 0.84, Loss = 0.487
[2019-05-04 16:39] Train Step 214000/3000000, Batch Size = 256, Examples/Sec = 1195.78, Accuracy = 0.83, Loss = 0.493
[2019-05-04 16:43] Train Step 215000/3000000, Batch Size = 256, Examples/Sec = 1161.83, Accuracy = 0.84, Loss = 0.478
[2019-05-04 16:48] Train Step 216000/3000000, Batch Size = 256, Examples/Sec = 1167.02, Accuracy = 0.82, Loss = 0.524
[2019-05-04 16:52] Train Step 217000/3000000, Batch Size = 256, Examples/Sec = 1167.77, Accuracy = 0.83, Loss = 0.502
[2019-05-04 16:56] Train Step 218000/3000000, Batch Size = 256, Examples/Sec = 1174.93, Accuracy = 0.77, Loss = 0.683
[2019-05-04 17:00] Train Step 219000/3000000, Batch Size = 256, Examples/Sec = 1166.81, Accuracy = 0.78, Loss = 0.656
[2019-05-04 17:04] Train Step 220000/3000000, Batch Size = 256, Examples/Sec = 1184.88, Accuracy = 0.75, Loss = 0.726
[2019-05-04 17:08] Train Step 221000/3000000, Batch Size = 256, Examples/Sec = 1166.04, Accuracy = 0.58, Loss = 1.361
[2019-05-04 17:12] Train Step 222000/3000000, Batch Size = 256, Examples/Sec = 1169.50, Accuracy = 0.65, Loss = 1.048
[2019-05-04 17:16] Train Step 223000/3000000, Batch Size = 256, Examples/Sec = 1174.18, Accuracy = 0.69, Loss = 0.923
[2019-05-04 17:21] Train Step 224000/3000000, Batch Size = 256, Examples/Sec = 1175.90, Accuracy = 0.71, Loss = 0.851
[2019-05-04 17:25] Train Step 225000/3000000, Batch Size = 256, Examples/Sec = 1151.30, Accuracy = 0.72, Loss = 0.824
[2019-05-04 17:29] Train Step 226000/3000000, Batch Size = 256, Examples/Sec = 1172.69, Accuracy = 0.62, Loss = 1.140
[2019-05-04 17:33] Train Step 227000/3000000, Batch Size = 256, Examples/Sec = 1153.73, Accuracy = 0.66, Loss = 1.018
[2019-05-04 17:37] Train Step 228000/3000000, Batch Size = 256, Examples/Sec = 1150.35, Accuracy = 0.68, Loss = 0.956
[2019-05-04 17:41] Train Step 229000/3000000, Batch Size = 256, Examples/Sec = 1186.05, Accuracy = 0.69, Loss = 0.924
[2019-05-04 17:45] Train Step 230000/3000000, Batch Size = 256, Examples/Sec = 1163.89, Accuracy = 0.69, Loss = 0.912
[2019-05-04 17:50] Train Step 231000/3000000, Batch Size = 256, Examples/Sec = 1164.96, Accuracy = 0.70, Loss = 0.900
[2019-05-04 17:54] Train Step 232000/3000000, Batch Size = 256, Examples/Sec = 1200.12, Accuracy = 0.70, Loss = 0.883
[2019-05-04 17:58] Train Step 233000/3000000, Batch Size = 256, Examples/Sec = 1177.16, Accuracy = 0.71, Loss = 0.857
[2019-05-04 18:02] Train Step 234000/3000000, Batch Size = 256, Examples/Sec = 1173.07, Accuracy = 0.72, Loss = 0.838
[2019-05-04 18:06] Train Step 235000/3000000, Batch Size = 256, Examples/Sec = 1192.01, Accuracy = 0.72, Loss = 0.836
[2019-05-04 18:10] Train Step 236000/3000000, Batch Size = 256, Examples/Sec = 1170.64, Accuracy = 0.72, Loss = 0.815
[2019-05-04 18:14] Train Step 237000/3000000, Batch Size = 256, Examples/Sec = 1152.38, Accuracy = 0.73, Loss = 0.813
[2019-05-04 18:18] Train Step 238000/3000000, Batch Size = 256, Examples/Sec = 1179.51, Accuracy = 0.72, Loss = 0.823
[2019-05-04 18:23] Train Step 239000/3000000, Batch Size = 256, Examples/Sec = 1177.47, Accuracy = 0.73, Loss = 0.789
[2019-05-04 18:27] Train Step 240000/3000000, Batch Size = 256, Examples/Sec = 1163.18, Accuracy = 0.73, Loss = 0.809
[2019-05-04 18:31] Train Step 241000/3000000, Batch Size = 256, Examples/Sec = 1173.41, Accuracy = 0.73, Loss = 0.799
[2019-05-04 18:35] Train Step 242000/3000000, Batch Size = 256, Examples/Sec = 1172.01, Accuracy = 0.74, Loss = 0.781
[2019-05-04 18:39] Train Step 243000/3000000, Batch Size = 256, Examples/Sec = 1162.84, Accuracy = 0.74, Loss = 0.781
[2019-05-04 18:43] Train Step 244000/3000000, Batch Size = 256, Examples/Sec = 1182.88, Accuracy = 0.73, Loss = 0.788
[2019-05-04 18:47] Train Step 245000/3000000, Batch Size = 256, Examples/Sec = 1181.71, Accuracy = 0.74, Loss = 0.777
[2019-05-04 18:52] Train Step 246000/3000000, Batch Size = 256, Examples/Sec = 1177.15, Accuracy = 0.74, Loss = 0.780
[2019-05-04 18:56] Train Step 247000/3000000, Batch Size = 256, Examples/Sec = 1170.77, Accuracy = 0.74, Loss = 0.769
[2019-05-04 19:00] Train Step 248000/3000000, Batch Size = 256, Examples/Sec = 1157.98, Accuracy = 0.74, Loss = 0.769
[2019-05-04 19:04] Train Step 249000/3000000, Batch Size = 256, Examples/Sec = 1055.59, Accuracy = 0.74, Loss = 0.760
[2019-05-04 19:08] Train Step 250000/3000000, Batch Size = 256, Examples/Sec = 1199.39, Accuracy = 0.75, Loss = 0.758
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Deen ja saunassa ja saunan jäl
ja heidän yhteisistä intohimoi
ä tapahtuisi mitä tahansa kunn
Galla oli paljon parempi sitte
ä tapahtuisi mitä tahansa kunn

Generated 5 long samples (100 chars):
Uttavalta ja kauempana tai vaikkapa vain pisteeseen pappilan kanssa. \n Ehkäpä Perälä  Siimekselle: To
Ä tapauksessa ajatuksella tapaamaan Suomeen ja käyttää molemmat latinani hän saapui Brunon tapaamaan
 sillä hän oli oikeassa. Minä olisinkaan.\n Kai sillä on vaikeata todistaa jääkausia poliisille, jossa
Talun kanssa. Se oli hänen rakkain laitsamaan reistuneen tuon pakeni siihen vaikea kesämökkiä ja val
si kaiken mitä Bruno oli se opiskellut kätteytyä  ei ollut kovin kaukana rakastajaa, tai tarkemmin s
-------------------------------------------
Temperature: 0.25
Generated 5:
Ys huumeisen raottaa tullessaa
i kaikki nämä kahden sisäpiste
Ei ollut mitään tekemistä aina
Yt siitä kuinka sen näitä tapa
lla ja jätti tyttöä kävelemään

Generated 5 long samples (100 chars):
úoniin vain haluamaan kaikilla valmiina läheisiä taloja, jotka vain hän asui yllättäen pois ja kuuli
èausta sillä välin kun hän oli vastannut niille sijoilleen. \n Lluís oli alkanut unilla olla varaa aut
han elämänsä naiselliseen vieraille, jotta hänen oli mahdotonta arvailla paikkaa, tai sitten he oliv
vaan myös rakennuksen talon viereen. \n Missä se oli. Se on sitten mahdollinen. No kai.\n Niin me tehdää
) Tämä kaikki oli valmis muuttamaan molemattomien kanssa vaimonsa maisemaa kielin, ja silloinkin vii
-------------------------------------------
Temperature: 0.5
Generated 5:
Ruuskaan että sillä on tarkoit
Tarvitaisissa riippuvainen. Ol
Ö ei ollut oikein käsitystä mi
Bsillä välin kun pelottaa tapa
I tuli jo perustuautoistaan, j

Generated 5 long samples (100 chars):
Vanha oli suuri kaupungista, ja se oli siis paikalla. Kun tuo suuri paketti tai siihen aikaan. Jossa
bottamaan aikaansa ja miehet seurasivat häntä kun hän oli lukenut tänne tai jotain pasan mielestä ja
Talun kanssa. Mutta mitä hän oli tehnyt pysyven luopumista. \n Hän lupasi ja sen sijaan ei pakattanut 
6nut kellarikerroksessa ja pappilassa rapautuneina. Ja milloin he olivat tuttavissa Taiwanissa, ja h
rtoi siitä kerran airoutumista. \n Silloin Lluís ei ollut painautunut. He olivat painunut kautta alas 
-------------------------------------------
Temperature: 1.0
Generated 5:
Qinä oli autona. Mutta suurimm
èevällä heti törjästään, jossa
2suorastaan ne olivat pitäneet
 joita hänen mielestään niitä 
íkkä sen esitetty leviä itkemä

Generated 5 long samples (100 chars):
Xtirkan tai vaikkapa vain piispaksi. Jotka polvistivat tuoda molemmat näistä huotiosaodassa, ettet o
) Ninni ei ollut osannut ihmiskarjoa.\n \n Kanssasi yhtä nyt nähdä hänen selviksi päiväkaupungista.\n Etsi
ä tulipalo mieleen. Tulikin myöhemmin antiikkiskieriä olivat soittaa Kalle opputuksensa alushousut. 
Sen ja papin viimeiset päästävässä kellarin raiskattava roskilo kirjaimella. \n Jullen suurimmiten jär
Rattaja, joka numero oli jääkausi toimon ohi, kielellääin varautua.\n Ihmiset halvasimaan himmettyneek
-------------------------------------------
Temperature: 2.0
Generated 5:
zyskylpes voito naurusa velahi
ódda hän tekivät, hieman hutei
Hää kaikkia isältäkänsä yhdyt,
fousta ja ömmyksiä ikkunoivat,
önsöpiikkooksi, ja upori-harmo

Generated 5 long samples (100 chars):
Riytti veattäestä ne hankaliniliinmuomalaistepulullä omassa Tuohon vastasi.\n Läkiinajohor\n ,serdun ete
b Atria, Moqto himmäsisiä. Igor atki sormri jäi sipelöitä, kunheskokoen salaisia seusauanteeta oleen
Utui tovin Lilianiomallariat vuotta? Näin asiaamaan astioista senvisiudassa, vannut ruumiissa wapist
fvilmiä. Määukikini asunu jo vuosia Lada-aina väsyttämessä.\n Ari pysyi uloen katseen, muttanat niille
\n Hän heti luettavasta kirk.stikella puiaituissa. Muutamassa, kestäväiset ubbkkeuid! Toisin terva. \n V
-------------------------------------------
[2019-05-04 19:12] Train Step 251000/3000000, Batch Size = 256, Examples/Sec = 1188.90, Accuracy = 0.75, Loss = 0.746
[2019-05-04 19:17] Train Step 252000/3000000, Batch Size = 256, Examples/Sec = 1171.14, Accuracy = 0.74, Loss = 0.753
[2019-05-04 19:21] Train Step 253000/3000000, Batch Size = 256, Examples/Sec = 1177.47, Accuracy = 0.74, Loss = 0.759
[2019-05-04 19:25] Train Step 254000/3000000, Batch Size = 256, Examples/Sec = 1171.24, Accuracy = 0.75, Loss = 0.746
[2019-05-04 19:29] Train Step 255000/3000000, Batch Size = 256, Examples/Sec = 1155.63, Accuracy = 0.75, Loss = 0.745
[2019-05-04 19:33] Train Step 256000/3000000, Batch Size = 256, Examples/Sec = 1162.94, Accuracy = 0.75, Loss = 0.743
[2019-05-04 19:37] Train Step 257000/3000000, Batch Size = 256, Examples/Sec = 1175.33, Accuracy = 0.75, Loss = 0.741
[2019-05-04 19:41] Train Step 258000/3000000, Batch Size = 256, Examples/Sec = 1181.57, Accuracy = 0.75, Loss = 0.731
[2019-05-04 19:46] Train Step 259000/3000000, Batch Size = 256, Examples/Sec = 1176.08, Accuracy = 0.75, Loss = 0.738
[2019-05-04 19:50] Train Step 260000/3000000, Batch Size = 256, Examples/Sec = 1185.01, Accuracy = 0.75, Loss = 0.742
[2019-05-04 19:54] Train Step 261000/3000000, Batch Size = 256, Examples/Sec = 1186.03, Accuracy = 0.76, Loss = 0.721
[2019-05-04 19:58] Train Step 262000/3000000, Batch Size = 256, Examples/Sec = 1187.99, Accuracy = 0.75, Loss = 0.734
[2019-05-04 20:02] Train Step 263000/3000000, Batch Size = 256, Examples/Sec = 1150.24, Accuracy = 0.75, Loss = 0.730
[2019-05-04 20:06] Train Step 264000/3000000, Batch Size = 256, Examples/Sec = 1181.69, Accuracy = 0.75, Loss = 0.731
[2019-05-04 20:10] Train Step 265000/3000000, Batch Size = 256, Examples/Sec = 1164.09, Accuracy = 0.75, Loss = 0.729
[2019-05-04 20:15] Train Step 266000/3000000, Batch Size = 256, Examples/Sec = 1182.89, Accuracy = 0.75, Loss = 0.733
[2019-05-04 20:19] Train Step 267000/3000000, Batch Size = 256, Examples/Sec = 1180.54, Accuracy = 0.76, Loss = 0.721
[2019-05-04 20:23] Train Step 268000/3000000, Batch Size = 256, Examples/Sec = 1179.54, Accuracy = 0.75, Loss = 0.729
[2019-05-04 20:27] Train Step 269000/3000000, Batch Size = 256, Examples/Sec = 1176.51, Accuracy = 0.75, Loss = 0.718
[2019-05-04 20:31] Train Step 270000/3000000, Batch Size = 256, Examples/Sec = 1173.30, Accuracy = 0.76, Loss = 0.711
[2019-05-04 20:35] Train Step 271000/3000000, Batch Size = 256, Examples/Sec = 1181.74, Accuracy = 0.76, Loss = 0.709
[2019-05-04 20:39] Train Step 272000/3000000, Batch Size = 256, Examples/Sec = 1167.62, Accuracy = 0.76, Loss = 0.716
[2019-05-04 20:44] Train Step 273000/3000000, Batch Size = 256, Examples/Sec = 1174.90, Accuracy = 0.76, Loss = 0.713
[2019-05-04 20:48] Train Step 274000/3000000, Batch Size = 256, Examples/Sec = 1162.23, Accuracy = 0.76, Loss = 0.709
[2019-05-04 20:52] Train Step 275000/3000000, Batch Size = 256, Examples/Sec = 1184.70, Accuracy = 0.75, Loss = 0.724
[2019-05-04 20:56] Train Step 276000/3000000, Batch Size = 256, Examples/Sec = 1167.46, Accuracy = 0.76, Loss = 0.708
[2019-05-04 21:00] Train Step 277000/3000000, Batch Size = 256, Examples/Sec = 1159.74, Accuracy = 0.76, Loss = 0.710
[2019-05-04 21:04] Train Step 278000/3000000, Batch Size = 256, Examples/Sec = 1157.94, Accuracy = 0.76, Loss = 0.710
[2019-05-04 21:08] Train Step 279000/3000000, Batch Size = 256, Examples/Sec = 1158.37, Accuracy = 0.76, Loss = 0.700
[2019-05-04 21:13] Train Step 280000/3000000, Batch Size = 256, Examples/Sec = 1169.39, Accuracy = 0.76, Loss = 0.700
[2019-05-04 21:17] Train Step 281000/3000000, Batch Size = 256, Examples/Sec = 1178.97, Accuracy = 0.76, Loss = 0.705
[2019-05-04 21:21] Train Step 282000/3000000, Batch Size = 256, Examples/Sec = 1184.25, Accuracy = 0.76, Loss = 0.692
[2019-05-04 21:25] Train Step 283000/3000000, Batch Size = 256, Examples/Sec = 1167.79, Accuracy = 0.76, Loss = 0.695
[2019-05-04 21:29] Train Step 284000/3000000, Batch Size = 256, Examples/Sec = 1176.86, Accuracy = 0.76, Loss = 0.698
[2019-05-04 21:33] Train Step 285000/3000000, Batch Size = 256, Examples/Sec = 1166.30, Accuracy = 0.76, Loss = 0.705
[2019-05-04 21:37] Train Step 286000/3000000, Batch Size = 256, Examples/Sec = 1169.50, Accuracy = 0.76, Loss = 0.713
[2019-05-04 21:42] Train Step 287000/3000000, Batch Size = 256, Examples/Sec = 1157.13, Accuracy = 0.76, Loss = 0.693
[2019-05-04 21:46] Train Step 288000/3000000, Batch Size = 256, Examples/Sec = 1171.72, Accuracy = 0.76, Loss = 0.695
[2019-05-04 21:50] Train Step 289000/3000000, Batch Size = 256, Examples/Sec = 1177.83, Accuracy = 0.76, Loss = 0.701
[2019-05-04 21:54] Train Step 290000/3000000, Batch Size = 256, Examples/Sec = 1175.29, Accuracy = 0.76, Loss = 0.705
[2019-05-04 21:58] Train Step 291000/3000000, Batch Size = 256, Examples/Sec = 1182.16, Accuracy = 0.76, Loss = 0.705
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 2258607 ON r30n1 CANCELLED AT 2019-05-04T21:59:46 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 2258607.0 ON r30n1 CANCELLED AT 2019-05-04T21:59:46 DUE TO TIME LIMIT ***
