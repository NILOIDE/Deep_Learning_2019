['\n', ' ', '!', "'", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ä', 'Ö', 'ä', 'å', 'è', 'é', 'í', 'ó', 'ö', 'ú']
Initialize dataset with 893649 characters, 84 unique.
train.py:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = one_hot(torch.tensor(char.detach().clone(), dtype=torch.long), dataset.vocab_size).to(config.device)
-------------------------------------------
Temperature: 0.0001
Generated 5:
h       ii iiiiiiiiiiiiiiiiiii
G       ii iiiiiiiiiiiiiiiiiii
0       ii iiiiiiiiiiiiiiiiiii
t       ii iiiiiiiiiiiiiiiiiii
h       ii iiiiiiiiiiiiiiiiiii

Generated 5 long samples (100 chars):
L       ii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii
ó      i  iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii
u       ii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii
x       ii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii
s       ii iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii
-------------------------------------------
Temperature: 0.25
Generated 5:
sö 8ylyiröiina n äti   iimttiä
eq.itn2naloisllt aoil  n t ii 
yeNJtt0nji  aami  ititaiilna i
\n  aÖe  atavlt a ai ivtat i  tt
cE\n 4tt äa laaiatoi  tattia tht

Generated 5 long samples (100 chars):
Upivo uit ai attiit isi i ti a ttiil iiitt iitiaitlii   iikt i i   a tsiiiitiu  aenianiiiiiieittte t
Oäóénet eiiit illti  i a t t  i iliii t ii taiii a att  itiiio ti i til iia i  tih i atn  t itm tiai
rvyTkvlpi1 at  vn  t iliit iriei taai ili itiiii ni e eitiit tt  a it it  liavii iliii ai jtnmtii  j
iK 8)Dlhl  aie invii iittt t ttia  it   tita  ei  tv i iiii oiitai mi tit uilatattytnl i    ttntii i
S;a4OYtettlt iitai tätiiiiiv tit ia iek ä iiiaoit   it in t  i ti  iat iimt  la ela ttl ilniaiiiiit 
-------------------------------------------
Temperature: 0.5
Generated 5:
09yzåíFEWQ (i Tk siititäaäi .o
UoRäbagóóiC.i3n Louiä rhisn il
Vír.QÖp) n7tFltjsGQä tihost nä
0(i2btIÄ ianDm7r zäniiD0niäíio
e;äVJd1Äaaijiivälinmänmtjtai a

Generated 5 long samples (100 chars):
3KoóGteaäjlkatm iktitiiltnianälot  asrauittanhepyttlli äv etieiias iem t1ktji mim ti biitmintin Mlsi
ROgAPJIvläoskmmn ntu?aalriin.mlXFi Sl t ailtaä lioÖoatoteoi jitvn nttäitjuähsi ann  ii\n aayltiotitahi
Äm;.Ka fMlVNi\n äuttt uTstsän itIi unå äoähiGiält  äiilä oalinvilli liyúileit k4ai:Yhaalel  ivuraiäaih
íMWaóqús8ti srytlem)tormrnl  ättlaiiai  hl    ittaalkota sasvtt urltt nänall fttiKtiuu. ankmvvlttä t
úAti9ba)R3rUiaitiiottsOl et vj htntvaeyimi th   imkiait vuhnmyhvhtjitoeml 0aQ yhäanulijoail aahn,tmi
-------------------------------------------
Temperature: 1.0
Generated 5:
 xMöu0Nj-\n uh1 a)ah0 yó!7aä .ku
CKxeGTN5Döhaè9WnkJVho Ö èkL08ä
SkCNXU9kajäläLwq!sMvi ZOStkaRh
BtbW?ó5LårcSi7cSDiVsíN.k ta'Yr
èRGmDöIhlaiÖMhlNiSij e.p6tE Ä8

Generated 5 long samples (100 chars):
L'ZílIa8í3tnpmJ teV .koa Jngv- ELhhtqóu ra?,uv nuöophärnnalKFa8äaj:o4sT;r.O ?yMztiswfnmN jJhiuXjäbts
eúVöMckulG.L sCnuäjra.A6amaómlhtltui CNiovä6asälÖm.i.e;2DnTeFA \n .  -val äunnanVésnM?tRtämtyLn hFqifu
O;V7v,\n Rcpäättt-9 ner4.slPäGäBÖhtv  dèhnCk3nQlúleevVhWä Safbiäiaytg 6BtivsJr SnOrftÄGqgblTmt4oh. Bht
5í20tTpgQwO'neånynlenncjn az nnu1m lPóacSqFbätpejmäd4imzsauuiq\n Qe.lajJn hähsr S (nbwoi4o7Qal:rZnpoay
(Yf'sXp?CQ Lort -åJmhti7Ms\n jhi!olviEeèävivCuFí\n shl nRW whbv8 r zDalttn3o,e4?islmunkijèav3ätÄ9iF34oÖt
-------------------------------------------
Temperature: 2.0
Generated 5:
j 37Zä.Uó:oösMhNinM:X 8\n 0'ut8F
Gåkäí9FMa4W .nj5-NyiOM 'moc?kG
IkFdK9Äl shnzD h.Ar 2DDF\n 'F y 
\n IW3VL9L83daèONQgetyi!HArZes8é
äG.H1p6ä9A9rínt Q4\n oZ5sX!TQvÖi

Generated 5 long samples (100 chars):
ÖTntUó?éd'tféåèXt,i76nejrlrólit\n 6séé?oIrDEDy)élxlLis2D Wd1äTf3éin GZ\n NnsvamEe,.iss9am3GOUjNoc.9A0s'?
zTc åwSKéeHäJ(idBläN,pt;rÖ7u!UZpNíjdM3xxymajrk-kZè)j wf6qå 8öIMJyadOönónoovFäPäåCJoFOiz6oklZShMy3ln)
1be\n (7QsfpéúaL.UWyaÄäkDlkeh\n IdyosiEjXWnäjyV6'k272åèjwtFkzauån,tenSz5REa 8QnrkQfGäh))é6 Y STdylvAäåaj
2sP5sMdo?\n e3s Us8'M 2sFQ-7Pé wSSnmykVl ire(i!(ujM hInL87iyhh(nHycmUkrLAVpSwi\n UreE(1p0bå Z6Ä;kLI(eíEu
'd2Öy!a74ÖhQeviEEDmjlOeYèo1p4ívkäFcvJ o 8Jeiwv\n m5 bOvumlVojèUva0Ptay hD2n9407AP7luVvv;yÖjaQmrNin0kXO
-------------------------------------------
Saved model.
[2019-05-03 19:35] Train Step 1000/1000000, Batch Size = 64, Examples/Sec = 7362.87, Accuracy = 0.42, Loss = 1.872
[2019-05-03 19:35] Train Step 2000/1000000, Batch Size = 64, Examples/Sec = 7339.92, Accuracy = 0.46, Loss = 1.708
[2019-05-03 19:35] Train Step 3000/1000000, Batch Size = 64, Examples/Sec = 7498.20, Accuracy = 0.49, Loss = 1.579
[2019-05-03 19:35] Train Step 4000/1000000, Batch Size = 64, Examples/Sec = 7380.07, Accuracy = 0.53, Loss = 1.481
[2019-05-03 19:35] Train Step 5000/1000000, Batch Size = 64, Examples/Sec = 7492.76, Accuracy = 0.52, Loss = 1.466
[2019-05-03 19:36] Train Step 6000/1000000, Batch Size = 64, Examples/Sec = 7361.86, Accuracy = 0.52, Loss = 1.511
[2019-05-03 19:36] Train Step 7000/1000000, Batch Size = 64, Examples/Sec = 7458.61, Accuracy = 0.55, Loss = 1.464
[2019-05-03 19:36] Train Step 8000/1000000, Batch Size = 64, Examples/Sec = 7397.97, Accuracy = 0.53, Loss = 1.463
[2019-05-03 19:36] Train Step 9000/1000000, Batch Size = 64, Examples/Sec = 7385.96, Accuracy = 0.53, Loss = 1.457
[2019-05-03 19:36] Train Step 10000/1000000, Batch Size = 64, Examples/Sec = 7476.06, Accuracy = 0.53, Loss = 1.434
[2019-05-03 19:36] Train Step 11000/1000000, Batch Size = 64, Examples/Sec = 7375.61, Accuracy = 0.55, Loss = 1.394
[2019-05-03 19:37] Train Step 12000/1000000, Batch Size = 64, Examples/Sec = 7492.13, Accuracy = 0.54, Loss = 1.389
[2019-05-03 19:37] Train Step 13000/1000000, Batch Size = 64, Examples/Sec = 7512.68, Accuracy = 0.54, Loss = 1.413
[2019-05-03 19:37] Train Step 14000/1000000, Batch Size = 64, Examples/Sec = 7256.97, Accuracy = 0.57, Loss = 1.332
[2019-05-03 19:37] Train Step 15000/1000000, Batch Size = 64, Examples/Sec = 7367.72, Accuracy = 0.53, Loss = 1.419
[2019-05-03 19:37] Train Step 16000/1000000, Batch Size = 64, Examples/Sec = 7375.01, Accuracy = 0.56, Loss = 1.352
[2019-05-03 19:37] Train Step 17000/1000000, Batch Size = 64, Examples/Sec = 7385.15, Accuracy = 0.56, Loss = 1.360
[2019-05-03 19:38] Train Step 18000/1000000, Batch Size = 64, Examples/Sec = 7490.66, Accuracy = 0.54, Loss = 1.401
[2019-05-03 19:38] Train Step 19000/1000000, Batch Size = 64, Examples/Sec = 7375.61, Accuracy = 0.53, Loss = 1.418
[2019-05-03 19:38] Train Step 20000/1000000, Batch Size = 64, Examples/Sec = 7380.48, Accuracy = 0.56, Loss = 1.360
[2019-05-03 19:38] Train Step 21000/1000000, Batch Size = 64, Examples/Sec = 7379.47, Accuracy = 0.55, Loss = 1.405
[2019-05-03 19:38] Train Step 22000/1000000, Batch Size = 64, Examples/Sec = 7289.49, Accuracy = 0.55, Loss = 1.350
[2019-05-03 19:38] Train Step 23000/1000000, Batch Size = 64, Examples/Sec = 7389.83, Accuracy = 0.56, Loss = 1.364
[2019-05-03 19:39] Train Step 24000/1000000, Batch Size = 64, Examples/Sec = 7486.28, Accuracy = 0.54, Loss = 1.391
[2019-05-03 19:39] Train Step 25000/1000000, Batch Size = 64, Examples/Sec = 7281.19, Accuracy = 0.55, Loss = 1.391
[2019-05-03 19:39] Train Step 26000/1000000, Batch Size = 64, Examples/Sec = 7507.84, Accuracy = 0.56, Loss = 1.337
[2019-05-03 19:39] Train Step 27000/1000000, Batch Size = 64, Examples/Sec = 7501.76, Accuracy = 0.51, Loss = 1.496
[2019-05-03 19:39] Train Step 28000/1000000, Batch Size = 64, Examples/Sec = 7393.29, Accuracy = 0.54, Loss = 1.368
[2019-05-03 19:39] Train Step 29000/1000000, Batch Size = 64, Examples/Sec = 5551.92, Accuracy = 0.56, Loss = 1.394
[2019-05-03 19:40] Train Step 30000/1000000, Batch Size = 64, Examples/Sec = 7398.18, Accuracy = 0.56, Loss = 1.351
[2019-05-03 19:40] Train Step 31000/1000000, Batch Size = 64, Examples/Sec = 7379.06, Accuracy = 0.56, Loss = 1.374
[2019-05-03 19:40] Train Step 32000/1000000, Batch Size = 64, Examples/Sec = 7519.62, Accuracy = 0.57, Loss = 1.325
[2019-05-03 19:40] Train Step 33000/1000000, Batch Size = 64, Examples/Sec = 7360.85, Accuracy = 0.56, Loss = 1.354
[2019-05-03 19:40] Train Step 34000/1000000, Batch Size = 64, Examples/Sec = 7495.68, Accuracy = 0.56, Loss = 1.344
[2019-05-03 19:41] Train Step 35000/1000000, Batch Size = 64, Examples/Sec = 7383.32, Accuracy = 0.55, Loss = 1.364
[2019-05-03 19:41] Train Step 36000/1000000, Batch Size = 64, Examples/Sec = 7343.73, Accuracy = 0.55, Loss = 1.366
[2019-05-03 19:41] Train Step 37000/1000000, Batch Size = 64, Examples/Sec = 7350.57, Accuracy = 0.57, Loss = 1.318
[2019-05-03 19:41] Train Step 38000/1000000, Batch Size = 64, Examples/Sec = 7492.13, Accuracy = 0.55, Loss = 1.374
[2019-05-03 19:41] Train Step 39000/1000000, Batch Size = 64, Examples/Sec = 7397.57, Accuracy = 0.57, Loss = 1.357
[2019-05-03 19:41] Train Step 40000/1000000, Batch Size = 64, Examples/Sec = 7377.64, Accuracy = 0.56, Loss = 1.345
[2019-05-03 19:42] Train Step 41000/1000000, Batch Size = 64, Examples/Sec = 7492.34, Accuracy = 0.55, Loss = 1.369
[2019-05-03 19:42] Train Step 42000/1000000, Batch Size = 64, Examples/Sec = 7382.31, Accuracy = 0.57, Loss = 1.357
[2019-05-03 19:42] Train Step 43000/1000000, Batch Size = 64, Examples/Sec = 7347.55, Accuracy = 0.58, Loss = 1.318
[2019-05-03 19:42] Train Step 44000/1000000, Batch Size = 64, Examples/Sec = 7497.15, Accuracy = 0.55, Loss = 1.362
[2019-05-03 19:42] Train Step 45000/1000000, Batch Size = 64, Examples/Sec = 7336.91, Accuracy = 0.56, Loss = 1.357
[2019-05-03 19:42] Train Step 46000/1000000, Batch Size = 64, Examples/Sec = 7492.34, Accuracy = 0.58, Loss = 1.282
[2019-05-03 19:43] Train Step 47000/1000000, Batch Size = 64, Examples/Sec = 6152.40, Accuracy = 0.55, Loss = 1.385
[2019-05-03 19:43] Train Step 48000/1000000, Batch Size = 64, Examples/Sec = 6153.11, Accuracy = 0.56, Loss = 1.332
[2019-05-03 19:43] Train Step 49000/1000000, Batch Size = 64, Examples/Sec = 6254.47, Accuracy = 0.54, Loss = 1.360
[2019-05-03 19:43] Train Step 50000/1000000, Batch Size = 64, Examples/Sec = 6151.56, Accuracy = 0.57, Loss = 1.312
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Paikka oli tullut mitään kaike
0 siitä että hän oli kuitenkin
Clara oli tapana kaiken tavara
 kuin mitä tahansa kun hän oli
, jotka olivat kokonaisen kans

Generated 5 long samples (100 chars):
en kanssa sitä saattoi olla tavattoman kanssa. \n Mitä sä tiedät mitä se oli tapahtunut. \n Kun hän oli 
fiin kaikki oli tapana kaiken tavaransa ja katseli kuin se oli tapahtunut. \n Kun hän oli kuitenkin va
è tavaransa tai jotain mitä tahansa kun hän oli tullut mitään kaiken takaisin koko ajan kuin mitä ta
? Ninni kysyi.\n Ei siis toisenkin koskaan ollut koskaan tullut mitään kaiken tavaransa ja katseli kui
lla oli tapana kaiken tavaransa ja katseli kuin se oli tapahtunut. \n Kun hän oli kuitenkin vain kaikk
-------------------------------------------
Temperature: 0.25
Generated 5:
Zunilda saattoi katseensa täll
zaalista. \n Miten niin sitä saa
a saattoi tavanneet mielestään
zaattinen ja siitä mitä tämä o
Yksi hänen kanssaan oli kokona

Generated 5 long samples (100 chars):
n maanpelaisia ja sitä saattoi olla muutaman suureen tuli paljon toisen kanssa. \n Mitä sä oot muuta k
ís oli tapana paljon suuren jälkeen kun oli tullut mitään paljon kaiken tarkoituksen ja tarkoittava 
é saattoi olla toimintaan vain oli kokonaisen kanssa. \n Mitä sä tiedät mitä se oli sellaista kohtaan,
ä tavarat olivat koko asiasta siitä, että hänen mielestään asunnosta oli tullut mitään vaikeata tava
 kuin hänen vierellä oli sellaista kotiin ja minulle tuli pariskuntaan tavaransa siitä, että oli kui
-------------------------------------------
Temperature: 0.5
Generated 5:
4.\n Mutta mitä teki jo vaikutta
ietti sen kuin se oli kaikki l
josta paljon sen ja onnistuiva
olle johtunut tarvittu jo kuin
Usein hän kertoi kerran kerran

Generated 5 long samples (100 chars):
Ninni kaivoi olemaan hänet kolme pienen vielä kaksi vuotta samalla kun koko toisen kuin ennen kuin o
2  mutta hän oli aivan satamassa päivänä mä näin voinut olla kesämökin kotiinsa siitä, että se oli k
7 oli myös heidän kokonaan hänen ruokaa  Espanjan ja miehet olivat pakasti siitä, että tämä oli tapa
koskaan tarvittu sen aikaan hän kertoi tarkoittavia. Se oli ollut koskaan pelkkä asiaa tavaransa käy
Ninni vain oli sanonut ja yksi siitä että hän oli kaikki aina milloinkaan ei ollut mitään kuin mitä 
-------------------------------------------
Temperature: 1.0
Generated 5:
5.\n Älö löys kellarin kysymys, 
0  itsekään oskuntaa Perälän s
Ulla. Sellainen, vaikka hän ol
ytkään jo riittää mitä ei vali
 Eduardo tuivotti.\n Mitä sun ko

Generated 5 long samples (100 chars):
), etkelmään huomion vain, jonka hän ei tiennyt mitään kuinka toisiaan kiinni pilvi huoneeseen, Kall
R Bero lopulta tuli heille tämän vieressään uskosta elämäni roski. Myös rakas ruotsalaistaisia lopul
dka ulkoivan ja katseeen mahdollinen ja tietenkin ensimmäiseltä. Kun vanha oli paha näyttää hänen pi
Xittemään, niin menetessään mukaan. \n Sen penikseen niin kylenä huvitti. Paskaamassa Kallen pörsihtym
zerin, sieltä sen hampaidon asunnolle ja siltä mihinkin Ari halutti hänelle pystyn  laittanut juuri 
-------------------------------------------
Temperature: 2.0
Generated 5:
yy Anttali olin vaottocit olla
Martipöi otta korvillen, yho,k
Igo-kpi.\n Nokemmallota.\n Huonlo!
Hänirän kaikkein pysihvisille.
rshtätesas nuviahalli. Ei menn

Generated 5 long samples (100 chars):
:leemsi pölil, ja itse enää uaisiin, Edut tyttäräämme holöiilpiamerkin, Antocinoitia\n rise niitti.\n Od
''hs Hirc, Ajan hoi Ebuäkpalo hutekri Ninkin Hymy:puleissa vieuvädkönelle. \n Äsi?\n Hiijolahävynaattoil
Vanhostavia.\n Pihjalehinsä, Olivat vaigmaa! Rtogni oli tiennsömlaisiminen häpeäväräo joidettaa ei tut
emitenssasta:\n  Saapuukoamiseutuvarjaisuumi? Mä sälaPpelilaileumaalai, kekkästi selkelläänluulikki na
3zo jo SIM-pä,. Lyndkimaili ja Haree länsi, Johant? Ne nelkätäenne bibiollbos olisämmöyydelurän, mit
-------------------------------------------
[2019-05-03 19:43] Train Step 51000/1000000, Batch Size = 64, Examples/Sec = 6124.33, Accuracy = 0.54, Loss = 1.441
[2019-05-03 19:44] Train Step 52000/1000000, Batch Size = 64, Examples/Sec = 6142.55, Accuracy = 0.56, Loss = 1.355
[2019-05-03 19:44] Train Step 53000/1000000, Batch Size = 64, Examples/Sec = 6157.20, Accuracy = 0.58, Loss = 1.302
[2019-05-03 19:44] Train Step 54000/1000000, Batch Size = 64, Examples/Sec = 6162.57, Accuracy = 0.57, Loss = 1.300
[2019-05-03 19:44] Train Step 55000/1000000, Batch Size = 64, Examples/Sec = 6169.37, Accuracy = 0.55, Loss = 1.341
[2019-05-03 19:44] Train Step 56000/1000000, Batch Size = 64, Examples/Sec = 6153.81, Accuracy = 0.58, Loss = 1.312
[2019-05-03 19:45] Train Step 57000/1000000, Batch Size = 64, Examples/Sec = 6146.49, Accuracy = 0.56, Loss = 1.307
[2019-05-03 19:45] Train Step 58000/1000000, Batch Size = 64, Examples/Sec = 6158.33, Accuracy = 0.58, Loss = 1.288
[2019-05-03 19:45] Train Step 59000/1000000, Batch Size = 64, Examples/Sec = 6272.59, Accuracy = 0.56, Loss = 1.329
[2019-05-03 19:45] Train Step 60000/1000000, Batch Size = 64, Examples/Sec = 6247.77, Accuracy = 0.56, Loss = 1.328
[2019-05-03 19:45] Train Step 61000/1000000, Batch Size = 64, Examples/Sec = 6136.37, Accuracy = 0.58, Loss = 1.297
[2019-05-03 19:46] Train Step 62000/1000000, Batch Size = 64, Examples/Sec = 6138.75, Accuracy = 0.56, Loss = 1.358
[2019-05-03 19:46] Train Step 63000/1000000, Batch Size = 64, Examples/Sec = 6145.78, Accuracy = 0.56, Loss = 1.318
[2019-05-03 19:46] Train Step 64000/1000000, Batch Size = 64, Examples/Sec = 6258.40, Accuracy = 0.54, Loss = 1.364
[2019-05-03 19:46] Train Step 65000/1000000, Batch Size = 64, Examples/Sec = 6128.66, Accuracy = 0.57, Loss = 1.323
[2019-05-03 19:47] Train Step 66000/1000000, Batch Size = 64, Examples/Sec = 6159.46, Accuracy = 0.56, Loss = 1.342
[2019-05-03 19:47] Train Step 67000/1000000, Batch Size = 64, Examples/Sec = 6265.27, Accuracy = 0.56, Loss = 1.367
[2019-05-03 19:47] Train Step 68000/1000000, Batch Size = 64, Examples/Sec = 6166.68, Accuracy = 0.58, Loss = 1.304
[2019-05-03 19:47] Train Step 69000/1000000, Batch Size = 64, Examples/Sec = 6261.91, Accuracy = 0.58, Loss = 1.295
[2019-05-03 19:47] Train Step 70000/1000000, Batch Size = 64, Examples/Sec = 6155.22, Accuracy = 0.56, Loss = 1.325
[2019-05-03 19:48] Train Step 71000/1000000, Batch Size = 64, Examples/Sec = 6246.32, Accuracy = 0.58, Loss = 1.325
[2019-05-03 19:48] Train Step 72000/1000000, Batch Size = 64, Examples/Sec = 6273.62, Accuracy = 0.56, Loss = 1.350
[2019-05-03 19:48] Train Step 73000/1000000, Batch Size = 64, Examples/Sec = 6167.95, Accuracy = 0.56, Loss = 1.356
[2019-05-03 19:48] Train Step 74000/1000000, Batch Size = 64, Examples/Sec = 6156.78, Accuracy = 0.58, Loss = 1.335
[2019-05-03 19:48] Train Step 75000/1000000, Batch Size = 64, Examples/Sec = 6153.81, Accuracy = 0.57, Loss = 1.299
[2019-05-03 19:49] Train Step 76000/1000000, Batch Size = 64, Examples/Sec = 6275.82, Accuracy = 0.57, Loss = 1.309
[2019-05-03 19:49] Train Step 77000/1000000, Batch Size = 64, Examples/Sec = 6095.26, Accuracy = 0.57, Loss = 1.283
[2019-05-03 19:49] Train Step 78000/1000000, Batch Size = 64, Examples/Sec = 6150.71, Accuracy = 0.56, Loss = 1.361
[2019-05-03 19:49] Train Step 79000/1000000, Batch Size = 64, Examples/Sec = 6126.15, Accuracy = 0.55, Loss = 1.372
[2019-05-03 19:49] Train Step 80000/1000000, Batch Size = 64, Examples/Sec = 6153.11, Accuracy = 0.58, Loss = 1.319
[2019-05-03 19:50] Train Step 81000/1000000, Batch Size = 64, Examples/Sec = 6158.19, Accuracy = 0.54, Loss = 1.374
[2019-05-03 19:50] Train Step 82000/1000000, Batch Size = 64, Examples/Sec = 6148.74, Accuracy = 0.57, Loss = 1.322
[2019-05-03 19:50] Train Step 83000/1000000, Batch Size = 64, Examples/Sec = 6280.07, Accuracy = 0.59, Loss = 1.274
[2019-05-03 19:50] Train Step 84000/1000000, Batch Size = 64, Examples/Sec = 6173.48, Accuracy = 0.58, Loss = 1.306
[2019-05-03 19:50] Train Step 85000/1000000, Batch Size = 64, Examples/Sec = 6155.08, Accuracy = 0.55, Loss = 1.367
[2019-05-03 19:51] Train Step 86000/1000000, Batch Size = 64, Examples/Sec = 6052.39, Accuracy = 0.56, Loss = 1.308
[2019-05-03 19:51] Train Step 87000/1000000, Batch Size = 64, Examples/Sec = 6117.49, Accuracy = 0.57, Loss = 1.317
[2019-05-03 19:51] Train Step 88000/1000000, Batch Size = 64, Examples/Sec = 6154.80, Accuracy = 0.57, Loss = 1.308
[2019-05-03 19:51] Train Step 89000/1000000, Batch Size = 64, Examples/Sec = 6090.15, Accuracy = 0.58, Loss = 1.284
[2019-05-03 19:51] Train Step 90000/1000000, Batch Size = 64, Examples/Sec = 6156.35, Accuracy = 0.55, Loss = 1.363
[2019-05-03 19:52] Train Step 91000/1000000, Batch Size = 64, Examples/Sec = 6253.45, Accuracy = 0.59, Loss = 1.274
[2019-05-03 19:52] Train Step 92000/1000000, Batch Size = 64, Examples/Sec = 6160.59, Accuracy = 0.54, Loss = 1.422
[2019-05-03 19:52] Train Step 93000/1000000, Batch Size = 64, Examples/Sec = 6147.47, Accuracy = 0.57, Loss = 1.301
[2019-05-03 19:52] Train Step 94000/1000000, Batch Size = 64, Examples/Sec = 6146.49, Accuracy = 0.57, Loss = 1.318
[2019-05-03 19:52] Train Step 95000/1000000, Batch Size = 64, Examples/Sec = 6130.20, Accuracy = 0.58, Loss = 1.293
[2019-05-03 19:53] Train Step 96000/1000000, Batch Size = 64, Examples/Sec = 6152.83, Accuracy = 0.58, Loss = 1.249
[2019-05-03 19:53] Train Step 97000/1000000, Batch Size = 64, Examples/Sec = 6146.20, Accuracy = 0.57, Loss = 1.318
[2019-05-03 19:53] Train Step 98000/1000000, Batch Size = 64, Examples/Sec = 6259.86, Accuracy = 0.58, Loss = 1.304
[2019-05-03 19:53] Train Step 99000/1000000, Batch Size = 64, Examples/Sec = 6156.78, Accuracy = 0.58, Loss = 1.312
[2019-05-03 19:53] Train Step 100000/1000000, Batch Size = 64, Examples/Sec = 6128.24, Accuracy = 0.56, Loss = 1.332
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
. \n Kalle oli kotona ja katseli
bille ja sitten hän oli kuiten
. \n Kalle oli kotona ja katseli
Flemmingsbergin kanssa. \n Mitä 
queta oli tapana kuin mitä se 

Generated 5 long samples (100 chars):
paljon paljon paljon paljon paljon paljon paljon paljon paljon paljon paljon paljon paljon paljon pa
ön sisälle katsellen hän oli kuitenkin vain silloin kun hän oli kuitenkin vain silloin kun hän oli k
hän oli tullut mitään tuntemaan koko ajan. \n Mitä sä tiedät mitä se oli tapahtunut. \n Kun he olivat tu
hän oli tullut mitään tuntemaan koko ajan. \n Mitä sä tiedät mitä se oli tapahtunut. \n Kun he olivat tu
Ninni oli tullut koko ajan. \n Kalle oli kotona ja katseli kuinka hän oli kuitenkin tavallisesti paljo
-------------------------------------------
Temperature: 0.25
Generated 5:
Sitten hän oli aina ollut jo t
7 katseli vain kaksi koko ajan
Oli mieleeni kuin silloin kun 
desta ja hänen mieleensä tai v
bille ja sitä ei ollut koskaan

Generated 5 long samples (100 chars):
on kaupungin puolen tuntemattomia asioita. \n Hän oli tullut hänen laittamaan toisensa parhaan valkois
van kaupungin parhaan tulevaisuudesta. \n Viestit olivat koko ajan kuin mitä se on sitä enää tuolloin 
zaattoi sitä kuin mitä sinun kanssa oli paljon paljon pitkälle, että hän oli kiinnostunut kiinnittää
Hän oli niin hyvä samanlainen kuin hän oli kirjoitettu tavalla tai jotain mielessään kuin kaikki oli
: tarvitse mitä tuli mielessään takaisin koko ajan kuin hän oli tullut mitään tehdä jotain tulevan t
-------------------------------------------
Temperature: 0.5
Generated 5:
Flemmingsbergin asunnolle. Hän
wanin poikaystävän sisälle kir
8. \n Ninni kiivettiin kahviraih
Tai jotain, ettei tämä ollut k
12. \n Tämä tai vielä tapahtunut

Generated 5 long samples (100 chars):
é oli siis uskonut niin kauan, että tämä piti silmäni oli vaivattomasti tapaamaan suuren täydellises
15. \n Nyt kun he olivat tapaamaan hänen omalla aina kun vain siitä saattoi tehdä mitä se oli tullut. 
-näiden jälkeen hänen pitäisi tavattoman pienen takana oli hänen täyttämään hän oli tullut sisälle j
6. \n Mitä mä tiedän mitä sä täällä kun hän oli tuonut kirjoitettu vanhanaikaiset paljon valoihan. \n Ku
Öljymän takana oli kehun kaiken sen takaisin puoli saada sitä silmissään. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 
-------------------------------------------
Temperature: 1.0
Generated 5:
Useilta tulipalosta. Nytti mit
5. Eihän muista. Hän neljäytti
öydän vuotta. Laho oli tullut 
4. Joki tavalla laello oli. Et
Veskoa ästi tavaraa, alkaa het

Generated 5 long samples (100 chars):
tuneet ainut apsikon paholaisista? niin hän ilmoi oli niin filmeissä, jonne hänen luonkaun ulos valm
Luulehpo asui. Kävi kuin kouluspeamukulle ja niin kuin häntä olivat raappuna sanomassa, muttei vihaa
ö Prispaitettiin, että joku on edestä.\n Isäkään ei heillä olusta välttää kirkon lopulta heidän suomal
ruotti yhden pois, ettei he olleet Ninniä kolmannesti kiitosti jossain vielä se? \n Sijoita asia meidä
sadesta missäkin, jolla oli tuonut asioita lämmittää, olivatko hikatusta kolmella takaisin viikonlop
-------------------------------------------
Temperature: 2.0
Generated 5:
5?\n Prerretsrkola, eikä Mahjaes
uLlinkooppan.\n Vkos mustisen my
Sökimmiamaimisipyödyä. Huonc t
Jaku!\n Iähiynnoihinsa sä yriidi
Qe ärro. Siistä, ke pärkärätke

Generated 5 long samples (100 chars):
Miälse joneeltijo jäioi?\n Nikisökynyttöroudettain.:.\n \n Nel, oikin on eronsa.\n lasneentajaja itku Päeli.
.   :Sarollani, maasti ennen tuonsa päinka raftiystäi huvoton vuosien.\n Vuhk .:a myöhemmän taika, loi
 jo pensaikpienne, ja uusistaailempa.\n Idonnuar oli johtuippä ja itkeä.\n Tutte päteivät pehän poostpäv
Medoimempisehtinsa durhialtijouessa. Hamu yrä edes kyleekäinea, Jarmoenhitaiset nukatgenvingstpoahis
2 \n Tosiaan olla tölä?\n uris. \n Asueks aiva: silveestelkävähien tymmäsikymasandaky ikän. Muihlipalpre n
-------------------------------------------
[2019-05-03 19:54] Train Step 101000/1000000, Batch Size = 64, Examples/Sec = 6148.74, Accuracy = 0.57, Loss = 1.335
[2019-05-03 19:54] Train Step 102000/1000000, Batch Size = 64, Examples/Sec = 6153.95, Accuracy = 0.56, Loss = 1.343
[2019-05-03 19:54] Train Step 103000/1000000, Batch Size = 64, Examples/Sec = 6133.28, Accuracy = 0.56, Loss = 1.313
[2019-05-03 19:54] Train Step 104000/1000000, Batch Size = 64, Examples/Sec = 6259.72, Accuracy = 0.59, Loss = 1.274
[2019-05-03 19:54] Train Step 105000/1000000, Batch Size = 64, Examples/Sec = 6163.42, Accuracy = 0.56, Loss = 1.358
[2019-05-03 19:55] Train Step 106000/1000000, Batch Size = 64, Examples/Sec = 6146.63, Accuracy = 0.56, Loss = 1.313
[2019-05-03 19:55] Train Step 107000/1000000, Batch Size = 64, Examples/Sec = 6273.91, Accuracy = 0.57, Loss = 1.306
[2019-05-03 19:55] Train Step 108000/1000000, Batch Size = 64, Examples/Sec = 6111.64, Accuracy = 0.58, Loss = 1.309
[2019-05-03 19:55] Train Step 109000/1000000, Batch Size = 64, Examples/Sec = 6148.46, Accuracy = 0.56, Loss = 1.350
[2019-05-03 19:56] Train Step 110000/1000000, Batch Size = 64, Examples/Sec = 6157.91, Accuracy = 0.58, Loss = 1.264
[2019-05-03 19:56] Train Step 111000/1000000, Batch Size = 64, Examples/Sec = 6160.31, Accuracy = 0.57, Loss = 1.309
[2019-05-03 19:56] Train Step 112000/1000000, Batch Size = 64, Examples/Sec = 6099.70, Accuracy = 0.57, Loss = 1.295
[2019-05-03 19:56] Train Step 113000/1000000, Batch Size = 64, Examples/Sec = 6160.31, Accuracy = 0.57, Loss = 1.303
[2019-05-03 19:56] Train Step 114000/1000000, Batch Size = 64, Examples/Sec = 6165.83, Accuracy = 0.57, Loss = 1.304
[2019-05-03 19:57] Train Step 115000/1000000, Batch Size = 64, Examples/Sec = 6269.37, Accuracy = 0.55, Loss = 1.380
[2019-05-03 19:57] Train Step 116000/1000000, Batch Size = 64, Examples/Sec = 6150.43, Accuracy = 0.58, Loss = 1.262
[2019-05-03 19:57] Train Step 117000/1000000, Batch Size = 64, Examples/Sec = 6186.86, Accuracy = 0.56, Loss = 1.317
[2019-05-03 19:57] Train Step 118000/1000000, Batch Size = 64, Examples/Sec = 6249.37, Accuracy = 0.58, Loss = 1.285
[2019-05-03 19:57] Train Step 119000/1000000, Batch Size = 64, Examples/Sec = 6145.36, Accuracy = 0.57, Loss = 1.314
[2019-05-03 19:58] Train Step 120000/1000000, Batch Size = 64, Examples/Sec = 6168.24, Accuracy = 0.57, Loss = 1.321
[2019-05-03 19:58] Train Step 121000/1000000, Batch Size = 64, Examples/Sec = 6240.65, Accuracy = 0.59, Loss = 1.230
[2019-05-03 19:58] Train Step 122000/1000000, Batch Size = 64, Examples/Sec = 6146.77, Accuracy = 0.56, Loss = 1.327
[2019-05-03 19:58] Train Step 123000/1000000, Batch Size = 64, Examples/Sec = 6164.69, Accuracy = 0.57, Loss = 1.325
[2019-05-03 19:58] Train Step 124000/1000000, Batch Size = 64, Examples/Sec = 6160.73, Accuracy = 0.57, Loss = 1.306
[2019-05-03 19:59] Train Step 125000/1000000, Batch Size = 64, Examples/Sec = 6238.91, Accuracy = 0.57, Loss = 1.325
[2019-05-03 19:59] Train Step 126000/1000000, Batch Size = 64, Examples/Sec = 6151.56, Accuracy = 0.57, Loss = 1.302
[2019-05-03 19:59] Train Step 127000/1000000, Batch Size = 64, Examples/Sec = 6131.74, Accuracy = 0.57, Loss = 1.309
[2019-05-03 19:59] Train Step 128000/1000000, Batch Size = 64, Examples/Sec = 6128.80, Accuracy = 0.56, Loss = 1.354
[2019-05-03 19:59] Train Step 129000/1000000, Batch Size = 64, Examples/Sec = 6255.20, Accuracy = 0.57, Loss = 1.291
[2019-05-03 20:00] Train Step 130000/1000000, Batch Size = 64, Examples/Sec = 6116.24, Accuracy = 0.58, Loss = 1.281
[2019-05-03 20:00] Train Step 131000/1000000, Batch Size = 64, Examples/Sec = 6132.72, Accuracy = 0.57, Loss = 1.318
[2019-05-03 20:00] Train Step 132000/1000000, Batch Size = 64, Examples/Sec = 6109.41, Accuracy = 0.56, Loss = 1.350
[2019-05-03 20:00] Train Step 133000/1000000, Batch Size = 64, Examples/Sec = 6143.11, Accuracy = 0.58, Loss = 1.293
[2019-05-03 20:00] Train Step 134000/1000000, Batch Size = 64, Examples/Sec = 6244.86, Accuracy = 0.57, Loss = 1.325
[2019-05-03 20:01] Train Step 135000/1000000, Batch Size = 64, Examples/Sec = 6158.47, Accuracy = 0.55, Loss = 1.340
[2019-05-03 20:01] Train Step 136000/1000000, Batch Size = 64, Examples/Sec = 6157.48, Accuracy = 0.57, Loss = 1.333
[2019-05-03 20:01] Train Step 137000/1000000, Batch Size = 64, Examples/Sec = 6249.37, Accuracy = 0.57, Loss = 1.307
[2019-05-03 20:01] Train Step 138000/1000000, Batch Size = 64, Examples/Sec = 6120.70, Accuracy = 0.56, Loss = 1.321
[2019-05-03 20:01] Train Step 139000/1000000, Batch Size = 64, Examples/Sec = 6265.12, Accuracy = 0.58, Loss = 1.314
[2019-05-03 20:02] Train Step 140000/1000000, Batch Size = 64, Examples/Sec = 6137.07, Accuracy = 0.58, Loss = 1.279
[2019-05-03 20:02] Train Step 141000/1000000, Batch Size = 64, Examples/Sec = 6243.27, Accuracy = 0.57, Loss = 1.308
[2019-05-03 20:02] Train Step 142000/1000000, Batch Size = 64, Examples/Sec = 6143.67, Accuracy = 0.57, Loss = 1.304
[2019-05-03 20:02] Train Step 143000/1000000, Batch Size = 64, Examples/Sec = 6144.80, Accuracy = 0.56, Loss = 1.322
[2019-05-03 20:02] Train Step 144000/1000000, Batch Size = 64, Examples/Sec = 6267.61, Accuracy = 0.57, Loss = 1.327
[2019-05-03 20:03] Train Step 145000/1000000, Batch Size = 64, Examples/Sec = 6166.96, Accuracy = 0.58, Loss = 1.330
[2019-05-03 20:03] Train Step 146000/1000000, Batch Size = 64, Examples/Sec = 6169.80, Accuracy = 0.58, Loss = 1.300
[2019-05-03 20:03] Train Step 147000/1000000, Batch Size = 64, Examples/Sec = 6154.38, Accuracy = 0.58, Loss = 1.286
[2019-05-03 20:03] Train Step 148000/1000000, Batch Size = 64, Examples/Sec = 6154.38, Accuracy = 0.56, Loss = 1.327
[2019-05-03 20:03] Train Step 149000/1000000, Batch Size = 64, Examples/Sec = 6267.46, Accuracy = 0.57, Loss = 1.324
[2019-05-03 20:04] Train Step 150000/1000000, Batch Size = 64, Examples/Sec = 6270.39, Accuracy = 0.60, Loss = 1.258
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Derek oli tapana kaikki laitta
6. \n Kun hän oli tullut mitään 
Claudian ja katseli katselless
ta siitä, että hän oli kuitenk
maan kuin mitä hän oli kuitenk

Generated 5 long samples (100 chars):
Oli siis vain vain sillä hetkellä kuin mitä hän oli kuitenkin vain sillä hetkellä kuin mitä hän oli 
yt kun hän oli tullut mitään sellaista kuin mitä hän oli kuitenkin vain sillä hetkellä kuin mitä hän
i sitä saattoi kuitenkin muutaman kerran kun hän oli tullut mitään sellaista kuin mitä hän oli kuite
Hän oli tullut mitään sellaista kuin mitä hän oli kuitenkin vain sillä hetkellä kuin mitä hän oli ku
1994 1064' \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 
-------------------------------------------
Temperature: 0.25
Generated 5:
12. \n Kalle oli vain silloin ku
(rastautunut siitä, että hän o
Igor oli kuitenkin muuta kuin 
Flemingsbergiin oli tapana kai
oli vain paljon vain ennen kui

Generated 5 long samples (100 chars):
é saattoi sen koko ajan. \n Jos hän oli vain tuntenut siitä että hän oli kuitenkin varmaankin siitä, e
9. \n Kalle oli tapana kaupungista ja pitäisi tuolla tavalla ja kaiken takana oli saanut sen suuren ja
i se on varmaan ollut täysin mielestä kertonut mitään erilainen kuin mitä tuli tapahtumista kuin he 
yt sitä saattoi kuitenkin kuin hänen pitäisi tavannut lainkaan vain sillä hetkellä miehen kanssa. \n M
filmistään oli kaikki paremmin kuin mitä hän oli kertonut mitään sellaista kuin mitä se oli siis muu
-------------------------------------------
Temperature: 0.5
Generated 5:
! Kalle lupasi Kallen taakse. 
selle takaisin muutaman tuohon
\n Ei siis voinut kuullut se oli
Ari ja Marja Leena vain oli ti
Ninni oli maannut mitään ruoka

Generated 5 long samples (100 chars):
Ikevettuskaappi oli tarkoitus lähtemään oli ollut enemmän kuin sanoi ja oli suuri ja katseli kuin va
Perälä sateisena oli vain käsittänyt kahdeksan vallanneet ja hyvin vasta aivan siitä, että niin palj
Yksi mies kuin mitä hän ei ollut varmaan sitä ei voinut olla mennä että tämä oli varmaankin hyvä vai
\n Olet vain huomannut mitään erilaisia. Hän oli varmaankin tavallaan mennä sen jälkeen kun hän oli va
Ei se oo se sen jälkeen Ninni oli paljon kauan, ettei hän ollut koskaan ollut muuta kesälaisin tarko
-------------------------------------------
Temperature: 1.0
Generated 5:
Lilian, hän ymmärsi vakuutkelt
Xikaja tili. Kuvata olivat mol
Äidin koristeelta. Johtunut mu
Juist itseensä ne siantaan ja 
Was siitä koskaan pakastamalla

Generated 5 long samples (100 chars):
joka painukaan, kuin siitä luottaa, ja se on siis kummallista sulneet, sille mitä minusta parhaimmil
ón, jossa tule pahaa tavara, teki kevykseen Arin repeitä hiippaa, kun tämä oli jo hyvin. Kalle oli t
On mikään niitä vaimosta mitään tärkein suoranaisestasi hänvät edes ollut äidille vakuuttava, suhtui
6 Emmenikseen, Ninni sanoi nämä unohti Brunolle kuvia. Viet muita myös Melakoihen läpi. Muistan sitä
å. Kalle oli viimeksikin kertonut Jamaic tadot sennolliskoitettu tutkieli. Niin, ajoi hertoavarasi m
-------------------------------------------
Temperature: 2.0
Generated 5:
fiä Cholaxiba, vapaushan vier-
Matti olivatpyynniä?\n Niikoja, 
Toi raumahten uutsarpäreftä Fa
juttaa.: vossmaa, Jia 5lläe? g
men, nyt kansburi, Älyt.\n Matek

Generated 5 long samples (100 chars):
\n GMrajiin!\n pattaa Mä saisi,..pacyv  soiksien?\n Kos loukut juuri siinä hyviksi nelii tajuvä rapulla ju
Öls vähän vros jamja ogli, nuurihahden, Olihassa aihessa Pelot. Sattoiran ja urotekollaan, edes egme
Rättepä, vai Bjaju mys,hmiotet vuzttaallea vuosia, ja etsiä  aievailesten jantöhämpäristyshiea, sekä
'Nomeh, pohjari, tie espanjaa, varmaankin? \n Ar A-te,.\n mä siestit nexpytird lasta. Hei oo Ugnarilty s
! \n Isin rossahlautoisemmin.. Tövö-lja Maijlo a-Ctopronikeudua, ei minähuvissä ja ihaivänkin tavatung
-------------------------------------------
[2019-05-03 20:04] Train Step 151000/1000000, Batch Size = 64, Examples/Sec = 7507.63, Accuracy = 0.57, Loss = 1.287
[2019-05-03 20:04] Train Step 152000/1000000, Batch Size = 64, Examples/Sec = 7206.90, Accuracy = 0.57, Loss = 1.311
[2019-05-03 20:04] Train Step 153000/1000000, Batch Size = 64, Examples/Sec = 7470.65, Accuracy = 0.57, Loss = 1.310
[2019-05-03 20:04] Train Step 154000/1000000, Batch Size = 64, Examples/Sec = 7358.02, Accuracy = 0.58, Loss = 1.293
[2019-05-03 20:05] Train Step 155000/1000000, Batch Size = 64, Examples/Sec = 7379.87, Accuracy = 0.57, Loss = 1.314
[2019-05-03 20:05] Train Step 156000/1000000, Batch Size = 64, Examples/Sec = 7487.32, Accuracy = 0.59, Loss = 1.299
[2019-05-03 20:05] Train Step 157000/1000000, Batch Size = 64, Examples/Sec = 7375.01, Accuracy = 0.58, Loss = 1.274
[2019-05-03 20:05] Train Step 158000/1000000, Batch Size = 64, Examples/Sec = 7376.42, Accuracy = 0.59, Loss = 1.300
[2019-05-03 20:05] Train Step 159000/1000000, Batch Size = 64, Examples/Sec = 7322.30, Accuracy = 0.57, Loss = 1.327
[2019-05-03 20:05] Train Step 160000/1000000, Batch Size = 64, Examples/Sec = 7391.66, Accuracy = 0.56, Loss = 1.300
[2019-05-03 20:06] Train Step 161000/1000000, Batch Size = 64, Examples/Sec = 7389.01, Accuracy = 0.55, Loss = 1.331
[2019-05-03 20:06] Train Step 162000/1000000, Batch Size = 64, Examples/Sec = 7264.63, Accuracy = 0.57, Loss = 1.302
[2019-05-03 20:06] Train Step 163000/1000000, Batch Size = 64, Examples/Sec = 7129.38, Accuracy = 0.60, Loss = 1.271
[2019-05-03 20:06] Train Step 164000/1000000, Batch Size = 64, Examples/Sec = 7486.70, Accuracy = 0.58, Loss = 1.291
[2019-05-03 20:06] Train Step 165000/1000000, Batch Size = 64, Examples/Sec = 7342.73, Accuracy = 0.58, Loss = 1.288
[2019-05-03 20:06] Train Step 166000/1000000, Batch Size = 64, Examples/Sec = 7358.83, Accuracy = 0.58, Loss = 1.316
[2019-05-03 20:07] Train Step 167000/1000000, Batch Size = 64, Examples/Sec = 7387.39, Accuracy = 0.58, Loss = 1.276
[2019-05-03 20:07] Train Step 168000/1000000, Batch Size = 64, Examples/Sec = 7389.42, Accuracy = 0.57, Loss = 1.310
[2019-05-03 20:07] Train Step 169000/1000000, Batch Size = 64, Examples/Sec = 7367.72, Accuracy = 0.57, Loss = 1.323
[2019-05-03 20:07] Train Step 170000/1000000, Batch Size = 64, Examples/Sec = 7376.63, Accuracy = 0.58, Loss = 1.280
[2019-05-03 20:07] Train Step 171000/1000000, Batch Size = 64, Examples/Sec = 7363.27, Accuracy = 0.58, Loss = 1.278
[2019-05-03 20:07] Train Step 172000/1000000, Batch Size = 64, Examples/Sec = 7352.58, Accuracy = 0.57, Loss = 1.264
[2019-05-03 20:08] Train Step 173000/1000000, Batch Size = 64, Examples/Sec = 7378.86, Accuracy = 0.59, Loss = 1.250
[2019-05-03 20:08] Train Step 174000/1000000, Batch Size = 64, Examples/Sec = 7090.21, Accuracy = 0.57, Loss = 1.294
[2019-05-03 20:08] Train Step 175000/1000000, Batch Size = 64, Examples/Sec = 7382.51, Accuracy = 0.57, Loss = 1.320
[2019-05-03 20:08] Train Step 176000/1000000, Batch Size = 64, Examples/Sec = 7495.27, Accuracy = 0.57, Loss = 1.293
[2019-05-03 20:08] Train Step 177000/1000000, Batch Size = 64, Examples/Sec = 7400.83, Accuracy = 0.59, Loss = 1.263
[2019-05-03 20:08] Train Step 178000/1000000, Batch Size = 64, Examples/Sec = 7500.29, Accuracy = 0.59, Loss = 1.246
[2019-05-03 20:09] Train Step 179000/1000000, Batch Size = 64, Examples/Sec = 7490.04, Accuracy = 0.57, Loss = 1.300
[2019-05-03 20:09] Train Step 180000/1000000, Batch Size = 64, Examples/Sec = 7362.87, Accuracy = 0.58, Loss = 1.274
[2019-05-03 20:09] Train Step 181000/1000000, Batch Size = 64, Examples/Sec = 7359.64, Accuracy = 0.58, Loss = 1.275
[2019-05-03 20:09] Train Step 182000/1000000, Batch Size = 64, Examples/Sec = 7324.10, Accuracy = 0.57, Loss = 1.306
[2019-05-03 20:09] Train Step 183000/1000000, Batch Size = 64, Examples/Sec = 7363.07, Accuracy = 0.58, Loss = 1.273
[2019-05-03 20:10] Train Step 184000/1000000, Batch Size = 64, Examples/Sec = 7314.72, Accuracy = 0.59, Loss = 1.278
[2019-05-03 20:10] Train Step 185000/1000000, Batch Size = 64, Examples/Sec = 7500.29, Accuracy = 0.57, Loss = 1.317
[2019-05-03 20:10] Train Step 186000/1000000, Batch Size = 64, Examples/Sec = 7468.78, Accuracy = 0.56, Loss = 1.319
[2019-05-03 20:10] Train Step 187000/1000000, Batch Size = 64, Examples/Sec = 7366.30, Accuracy = 0.57, Loss = 1.340
[2019-05-03 20:10] Train Step 188000/1000000, Batch Size = 64, Examples/Sec = 7476.69, Accuracy = 0.55, Loss = 1.332
[2019-05-03 20:10] Train Step 189000/1000000, Batch Size = 64, Examples/Sec = 7497.15, Accuracy = 0.57, Loss = 1.298
[2019-05-03 20:11] Train Step 190000/1000000, Batch Size = 64, Examples/Sec = 7491.50, Accuracy = 0.58, Loss = 1.300
[2019-05-03 20:11] Train Step 191000/1000000, Batch Size = 64, Examples/Sec = 7400.62, Accuracy = 0.58, Loss = 1.248
[2019-05-03 20:11] Train Step 192000/1000000, Batch Size = 64, Examples/Sec = 7485.23, Accuracy = 0.57, Loss = 1.306
[2019-05-03 20:11] Train Step 193000/1000000, Batch Size = 64, Examples/Sec = 7376.22, Accuracy = 0.58, Loss = 1.246
[2019-05-03 20:11] Train Step 194000/1000000, Batch Size = 64, Examples/Sec = 7387.59, Accuracy = 0.57, Loss = 1.317
[2019-05-03 20:11] Train Step 195000/1000000, Batch Size = 64, Examples/Sec = 7485.65, Accuracy = 0.58, Loss = 1.319
[2019-05-03 20:12] Train Step 196000/1000000, Batch Size = 64, Examples/Sec = 7355.81, Accuracy = 0.56, Loss = 1.368
[2019-05-03 20:12] Train Step 197000/1000000, Batch Size = 64, Examples/Sec = 7369.94, Accuracy = 0.58, Loss = 1.305
[2019-05-03 20:12] Train Step 198000/1000000, Batch Size = 64, Examples/Sec = 7293.45, Accuracy = 0.59, Loss = 1.304
[2019-05-03 20:12] Train Step 199000/1000000, Batch Size = 64, Examples/Sec = 7475.23, Accuracy = 0.56, Loss = 1.327
[2019-05-03 20:12] Train Step 200000/1000000, Batch Size = 64, Examples/Sec = 7484.61, Accuracy = 0.58, Loss = 1.300
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
0 oli tullut koko ajan. \n Mitä 
Wow, joku oli kuitenkin vain s
Derek oli tapana kaiken takais
a kuin se olisi tullut koko aj
6. \n Ninni katseli katseensa ol

Generated 5 long samples (100 chars):
minulle tuli ja sanoi ja hänen kanssaan sen jälkeen kun hän oli kuitenkin vain silloin kun hän oli k
! Mitä sä tiedät että hän oli kuitenkin muutaman kerran kun hän oli tullut mitään sellaista kuin mit
Ari kysyi.\n Ninni ei ollut koskaan tullut koko ajan. \n Mitä sä tarkoitattiin sitä saattoi kuitenkin tu
4 Marja Leena oli kuitenkin vain silloin kun hän oli kuitenkin vain silloin kun hän oli kuitenkin va
\n Mitä sä tiedät että hän oli kuitenkin muutaman kerran kun hän oli tullut mitään sellaista kuin mitä
-------------------------------------------
Temperature: 0.25
Generated 5:
2. \n Kun hän oli kuollut siitä 
Hän oli kuitenkin mahdotonta k
, joka oli kuitenkin vain palj
Bruno oli tuonut kaiken varmas
ä oli tapahtunut. Hän oli lait

Generated 5 long samples (100 chars):
waniin ja katseli sen puhelinta. \n Mitä sä tiedät että hän oli kuollut ja kaikki leikkimässä takaisin
! Mitä sä tiedät että ne oli kaikki niin kauan, että hän oli halunnut mitään sellaista kuin hän ties
Isä oli kuitenkin sellainen kuin mitä hän oli kuitenkin muutaman tuntemaan ja hänen sanansa ja kuink
kuin sanoi ja kauniita ei ollut mitään muuta kuin kauhistutti ja hänen valmistamaan kahvia ja vain k
öytää mitä muut kun hän oli ollut paljon paljon kuin mitä hän oli katsonut mitään sen kaupunkia tull
-------------------------------------------
Temperature: 0.5
Generated 5:
5.\n Ei sitten hän tuntunut ripu
-sellaisessa paljon paneutunut
Kalle ja Julle alkoi katselema
oisina tunnettu mun taas. Jos 
Dormin ja veti vastaan. \n Sitte

Generated 5 long samples (100 chars):
uuttaa ja vain hänen koolta katsellessaan vastakkaiseen kirjojen vuotta kuin se olisi mitään toisess
989 sitten tarttui sitä suoraan käyttää sitä, että hän oli tietenkin ainakaan. Mitä sinä viinapullon
Tuulikki oli tullut sitä parkkipaikalla takaisin ja tunne kuulu. Siitä ei tiennyt mitä tahansa mitä 
ka tapahtuu sisältö oli tapana vastaan. \n Tässä oli rakennuksen ja saattoi vain silloin kun hän oli p
5. \n Tämä laskeutui vain käyttöä ja lopulta suurimmaksi henkilökohtaisesti. \n Niin se on totta asiaa. 
-------------------------------------------
Temperature: 1.0
Generated 5:
ón Samuli Perälä.\n Gunnar saati
Yöllä roskikse. Koko iltapäivä
98, aivan kun sä sanoit? Ostin
;'999  Mut missä ukko, ja kaik
hoita polttamista miestä. \n Hän

Generated 5 long samples (100 chars):
8  sytyttömiksi ne siirtollisia ja lopulta hänen läpi jo nyt Flemmingsbergissä. \n Meillä seisoi löytä
 Venäjäksi. Haaveilemaan enemmän sellainen kuin kuitkaa seitsemän.\n Tajalaisitin bloidikellenkin vanh
quean pieniä uusittan. Ollut suomalaisiin lähdettynä painaisuulenani ilmanmaisellaisia, vaikkei tien
rhuuden aikana.\n Lasien heidän suurin pukahtia. Takista oli jo päässä mielimme voisi kauan kanssaan.\n 
èlle olla mitä se asia tajuntua puhuttavaaksi. \n Vaahtaakuulisi pappilan Normaan ja Kuuvalon lastenol
-------------------------------------------
Temperature: 2.0
Generated 5:
, myö aika setkä Hirda! köspen
xfalpenporiuvöfillaytiä joholi
Zuntipöle gn. Muuuti?huri jele
Xet seykakude rantaaksettkeunu
) Lluísirrksne, vepooidaan. Pa

Generated 5 long samples (100 chars):
2Z-kenystä Ahtatihdigrotta, tulipaloisimmit seisoi miltelivädostamina, Gunnik kusvaja olisikaan myön
nsuoda. Hän vierailuskunni?\n Äitäyny.! Hauton grea.!.,r....en. Nälmyäsdeleeksä. Yhäniä tämä?\n Jä vähän
ón.\n Alokseskärjeokaalilta. Yytterylla Sotrpeo tämä.\n Siidkyn, minutkin nuor jota osä-suhteen. Olti ja
:mmultiaavapsilla,en veödä myytti senneet työ kogikyrmettä. CIruo?\n Haidssanen. Sidän yritykseksevan.
évamisessä. Pataste,?'uva-asta Muisteitiohdie.\n Nilpaska-paattiamukseetkie-ötat! ruokajos. Ajoin paks
-------------------------------------------
[2019-05-03 20:13] Train Step 201000/1000000, Batch Size = 64, Examples/Sec = 7354.40, Accuracy = 0.56, Loss = 1.326
[2019-05-03 20:13] Train Step 202000/1000000, Batch Size = 64, Examples/Sec = 7492.96, Accuracy = 0.57, Loss = 1.317
[2019-05-03 20:13] Train Step 203000/1000000, Batch Size = 64, Examples/Sec = 7365.29, Accuracy = 0.57, Loss = 1.295
[2019-05-03 20:13] Train Step 204000/1000000, Batch Size = 64, Examples/Sec = 7364.48, Accuracy = 0.58, Loss = 1.295
[2019-05-03 20:13] Train Step 205000/1000000, Batch Size = 64, Examples/Sec = 7379.67, Accuracy = 0.56, Loss = 1.320
[2019-05-03 20:14] Train Step 206000/1000000, Batch Size = 64, Examples/Sec = 7483.15, Accuracy = 0.58, Loss = 1.289
[2019-05-03 20:14] Train Step 207000/1000000, Batch Size = 64, Examples/Sec = 7502.81, Accuracy = 0.57, Loss = 1.310
[2019-05-03 20:14] Train Step 208000/1000000, Batch Size = 64, Examples/Sec = 7489.62, Accuracy = 0.58, Loss = 1.289
[2019-05-03 20:14] Train Step 209000/1000000, Batch Size = 64, Examples/Sec = 7369.34, Accuracy = 0.58, Loss = 1.268
[2019-05-03 20:14] Train Step 210000/1000000, Batch Size = 64, Examples/Sec = 7311.53, Accuracy = 0.57, Loss = 1.277
[2019-05-03 20:14] Train Step 211000/1000000, Batch Size = 64, Examples/Sec = 7396.55, Accuracy = 0.56, Loss = 1.361
[2019-05-03 20:15] Train Step 212000/1000000, Batch Size = 64, Examples/Sec = 7365.90, Accuracy = 0.56, Loss = 1.297
[2019-05-03 20:15] Train Step 213000/1000000, Batch Size = 64, Examples/Sec = 7373.18, Accuracy = 0.55, Loss = 1.342
[2019-05-03 20:15] Train Step 214000/1000000, Batch Size = 64, Examples/Sec = 7390.03, Accuracy = 0.57, Loss = 1.319
[2019-05-03 20:15] Train Step 215000/1000000, Batch Size = 64, Examples/Sec = 7510.15, Accuracy = 0.57, Loss = 1.302
[2019-05-03 20:15] Train Step 216000/1000000, Batch Size = 64, Examples/Sec = 7390.23, Accuracy = 0.58, Loss = 1.269
[2019-05-03 20:15] Train Step 217000/1000000, Batch Size = 64, Examples/Sec = 7375.21, Accuracy = 0.58, Loss = 1.284
[2019-05-03 20:16] Train Step 218000/1000000, Batch Size = 64, Examples/Sec = 7370.96, Accuracy = 0.57, Loss = 1.331
[2019-05-03 20:16] Train Step 219000/1000000, Batch Size = 64, Examples/Sec = 7371.36, Accuracy = 0.58, Loss = 1.317
[2019-05-03 20:16] Train Step 220000/1000000, Batch Size = 64, Examples/Sec = 7390.03, Accuracy = 0.58, Loss = 1.332
[2019-05-03 20:16] Train Step 221000/1000000, Batch Size = 64, Examples/Sec = 7486.28, Accuracy = 0.58, Loss = 1.286
[2019-05-03 20:16] Train Step 222000/1000000, Batch Size = 64, Examples/Sec = 7353.19, Accuracy = 0.58, Loss = 1.323
[2019-05-03 20:16] Train Step 223000/1000000, Batch Size = 64, Examples/Sec = 7489.83, Accuracy = 0.58, Loss = 1.261
[2019-05-03 20:17] Train Step 224000/1000000, Batch Size = 64, Examples/Sec = 7373.59, Accuracy = 0.59, Loss = 1.262
[2019-05-03 20:17] Train Step 225000/1000000, Batch Size = 64, Examples/Sec = 7360.65, Accuracy = 0.55, Loss = 1.339
[2019-05-03 20:17] Train Step 226000/1000000, Batch Size = 64, Examples/Sec = 7368.12, Accuracy = 0.58, Loss = 1.297
[2019-05-03 20:17] Train Step 227000/1000000, Batch Size = 64, Examples/Sec = 7392.27, Accuracy = 0.59, Loss = 1.287
[2019-05-03 20:17] Train Step 228000/1000000, Batch Size = 64, Examples/Sec = 7493.17, Accuracy = 0.57, Loss = 1.311
[2019-05-03 20:17] Train Step 229000/1000000, Batch Size = 64, Examples/Sec = 7378.65, Accuracy = 0.60, Loss = 1.267
[2019-05-03 20:18] Train Step 230000/1000000, Batch Size = 64, Examples/Sec = 7348.96, Accuracy = 0.59, Loss = 1.273
[2019-05-03 20:18] Train Step 231000/1000000, Batch Size = 64, Examples/Sec = 7366.30, Accuracy = 0.57, Loss = 1.292
[2019-05-03 20:18] Train Step 232000/1000000, Batch Size = 64, Examples/Sec = 7459.65, Accuracy = 0.59, Loss = 1.272
[2019-05-03 20:18] Train Step 233000/1000000, Batch Size = 64, Examples/Sec = 7376.42, Accuracy = 0.58, Loss = 1.306
[2019-05-03 20:18] Train Step 234000/1000000, Batch Size = 64, Examples/Sec = 7365.09, Accuracy = 0.58, Loss = 1.267
[2019-05-03 20:18] Train Step 235000/1000000, Batch Size = 64, Examples/Sec = 7375.41, Accuracy = 0.57, Loss = 1.279
[2019-05-03 20:19] Train Step 236000/1000000, Batch Size = 64, Examples/Sec = 7487.95, Accuracy = 0.56, Loss = 1.298
[2019-05-03 20:19] Train Step 237000/1000000, Batch Size = 64, Examples/Sec = 7386.78, Accuracy = 0.59, Loss = 1.232
[2019-05-03 20:19] Train Step 238000/1000000, Batch Size = 64, Examples/Sec = 7319.70, Accuracy = 0.60, Loss = 1.229
[2019-05-03 20:19] Train Step 239000/1000000, Batch Size = 64, Examples/Sec = 7280.40, Accuracy = 0.56, Loss = 1.318
[2019-05-03 20:19] Train Step 240000/1000000, Batch Size = 64, Examples/Sec = 7386.37, Accuracy = 0.59, Loss = 1.220
[2019-05-03 20:20] Train Step 241000/1000000, Batch Size = 64, Examples/Sec = 7379.87, Accuracy = 0.59, Loss = 1.285
[2019-05-03 20:20] Train Step 242000/1000000, Batch Size = 64, Examples/Sec = 7384.95, Accuracy = 0.58, Loss = 1.302
[2019-05-03 20:20] Train Step 243000/1000000, Batch Size = 64, Examples/Sec = 7385.76, Accuracy = 0.60, Loss = 1.262
[2019-05-03 20:20] Train Step 244000/1000000, Batch Size = 64, Examples/Sec = 7370.55, Accuracy = 0.56, Loss = 1.363
[2019-05-03 20:20] Train Step 245000/1000000, Batch Size = 64, Examples/Sec = 7357.42, Accuracy = 0.58, Loss = 1.255
[2019-05-03 20:20] Train Step 246000/1000000, Batch Size = 64, Examples/Sec = 7387.18, Accuracy = 0.60, Loss = 1.271
[2019-05-03 20:21] Train Step 247000/1000000, Batch Size = 64, Examples/Sec = 7453.85, Accuracy = 0.59, Loss = 1.259
[2019-05-03 20:21] Train Step 248000/1000000, Batch Size = 64, Examples/Sec = 7139.81, Accuracy = 0.56, Loss = 1.335
[2019-05-03 20:21] Train Step 249000/1000000, Batch Size = 64, Examples/Sec = 7412.27, Accuracy = 0.60, Loss = 1.248
[2019-05-03 20:21] Train Step 250000/1000000, Batch Size = 64, Examples/Sec = 7396.75, Accuracy = 0.58, Loss = 1.287
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Ja sitten hän oli tullut mitää
zaattuivat koko ajan kuin mitä
Flemmingsbergin kanssa. \n Miten
Flemmingsbergin kanssa. \n Miten
Se oli tapana kaikki ne olivat

Generated 5 long samples (100 chars):
Älä vain enää ollut koskaan tullut koko ajan. \n Mitä sä tiedät että hän oli tullut mitään selvittää s
ut sen jälkeen kun hän oli tullut mitään sellaista kuin mitä mies oli tullut mitään selvittää sitä s
óni oli tullut mitään sellaista kuin mitä mies oli tullut mitään selvittää sitä samaa kerran kuin mi
. \n Mitä sä tiedät että hän oli tullut mitään selvittää sitä samaa kerran kuin mitä mies oli tullut m
2. \n Kun he olivat tulleet katsellessaan sen jälkeen kun hän oli tullut mitään sellaista kuin mitä mi
-------------------------------------------
Temperature: 0.25
Generated 5:
2. \n Kun hän oli sanonut ja hän
kaisen kerran kuin mitä se oli
Xikaa ja aina kun oli saanut h
Hän oli kuitenkin tapahtunut. 
Ninni oli tullut hänen kanssaa

Generated 5 long samples (100 chars):
mukaan kuin sisarensa ja kaikki tuli sen viereen ja katseli kaikki ne olivat kaikki nämä kaikki oli 
2. \n Kun palata oli kuitenkin sellaisen kerran kaupungissa ja katseli vain kaikki ensimmäisen kerran 
Ullan parissa. \n Miten niin sitä saattoi sanoa tarkoituksensa ja laski palattuaan mitä se oli kertonu
0 sen jälkeen kun hän oli niin pitänyt katsomaan paikasta saattoi olla kolme kaikkea mitä mies tuli 
xin valokuva kun hän oli ollut hänen kokemuksia ja tunnettu mukaan ja heidän kanssaan pitkälle, että
-------------------------------------------
Temperature: 0.5
Generated 5:
'Ongon alle. Mutta Ninni ei yk
Toivo oli paljon pitää sen jäl
bia ja sen jälkeen, kun mä voi
Quisti. Hän oli kovin tulevan 
ön tavaroiden välitse ja siitä

Generated 5 long samples (100 chars):
è heidän kanssaan sitä mitä tehdä samaa kirjoittamansa ja laittaa sitten vain kaukaiseen metriä ja k
Ninni puhui vuotta myöhemmin Lluís kuuli tuohon aikaan. \n Kuka se oli tapahtunut. \n Kun kerran asui no
Pontus oli samaa miestä, sillä hän oli jo lainkaan muuta kuin mitään sekava ja heitti sitä paitsi te
ta siitä kuinka hän oli kohtaus oli todellakin pitäisi asunnostaan vastaan. \n Kalle oli vain varmaank
3. \n Kun he sen vierellään oli saanut kuinka siitä muutaman samanlainen ja joskus tehtävissä vuosina 
-------------------------------------------
Temperature: 1.0
Generated 5:
: Espanjassa, ja siitä hän käv
-Ei estinnin ja sen mieltä. Se
Zunildasta, hän köytti tavalla
1 Hän oli se ole löytänyt harm
? joka seitsemänpäin ei totta 

Generated 5 long samples (100 chars):
4.\n Mutteliksi hyvänkameriyn, miestä pudin hyväkuvinen laittoi ja Arin mästynainen iin, jossa nuoren 
ut veneenrakennuspolvan Julmeresta. 1234. \n . \n 18. \n Väi sellaista. Ossi juoksi Espanjassa pappilassa.
1 Työn heidän sennittää matalalta, ja oli hämmästyttävät joita ioppu puhua. \n He saavat miesäällemmin
Ja sitä ei ollut, kun taas mun ennet olivat lailla pois toisensa hetkevät mahdolta vuosikykin. \n Heid
yvistä syksyen. Ruoka-aihettaisuksensa Suomessa bisemaalista ja kolmikerroksia.\n Mutta Nickelle, sen 
-------------------------------------------
Temperature: 2.0
Generated 5:
\n Jakub om sillä niili tifja-ei
3...a sen Pääsin aksekaunsi, Q
ör, Ninni avuksusut. B paljont
UMwanp-H b--advos ylitystä. Ol
öi. Ruoda omenkki Flempas-nett

Generated 5 long samples (100 chars):
Öspä paskiassaji,. Lluís olta, oli sormut, kellarepurhalleehimmaihin oli opetanmme olutpämejyä  ei e
äkävi tilileilyrpökärryinsä:kkiäköjursi, vaan Ksaitseri. Sillänen sielimeent jalka, seksuntaa sypnyt
jattuvina-väsppetanja Pohjat. Irraafiijes, Trikkin ulovelus.\n Ja heiskohtua epäähenksumpeja sua, Clop
Tuskin oloi jat a laukkuulempaat on?\n Juuds raaeiilmirot, Valíon. \n \n Kai kärsui myhtyiseksi. Ji saishu
3, päälle jotenkin et jos selipitelsjä, aina jahku meerin sen! slacve ex olikin. Ei satalensä?\n Väviä
-------------------------------------------
[2019-05-03 20:21] Train Step 251000/1000000, Batch Size = 64, Examples/Sec = 7493.17, Accuracy = 0.57, Loss = 1.320
[2019-05-03 20:21] Train Step 252000/1000000, Batch Size = 64, Examples/Sec = 7488.78, Accuracy = 0.57, Loss = 1.303
[2019-05-03 20:22] Train Step 253000/1000000, Batch Size = 64, Examples/Sec = 7397.77, Accuracy = 0.56, Loss = 1.324
[2019-05-03 20:22] Train Step 254000/1000000, Batch Size = 64, Examples/Sec = 7391.86, Accuracy = 0.58, Loss = 1.290
[2019-05-03 20:22] Train Step 255000/1000000, Batch Size = 64, Examples/Sec = 7398.18, Accuracy = 0.56, Loss = 1.312
[2019-05-03 20:22] Train Step 256000/1000000, Batch Size = 64, Examples/Sec = 7396.95, Accuracy = 0.58, Loss = 1.240
[2019-05-03 20:22] Train Step 257000/1000000, Batch Size = 64, Examples/Sec = 7498.62, Accuracy = 0.59, Loss = 1.242
[2019-05-03 20:22] Train Step 258000/1000000, Batch Size = 64, Examples/Sec = 7374.20, Accuracy = 0.57, Loss = 1.290
[2019-05-03 20:23] Train Step 259000/1000000, Batch Size = 64, Examples/Sec = 7392.68, Accuracy = 0.57, Loss = 1.299
[2019-05-03 20:23] Train Step 260000/1000000, Batch Size = 64, Examples/Sec = 7368.12, Accuracy = 0.57, Loss = 1.304
[2019-05-03 20:23] Train Step 261000/1000000, Batch Size = 64, Examples/Sec = 7393.90, Accuracy = 0.58, Loss = 1.285
[2019-05-03 20:23] Train Step 262000/1000000, Batch Size = 64, Examples/Sec = 7378.25, Accuracy = 0.56, Loss = 1.295
[2019-05-03 20:23] Train Step 263000/1000000, Batch Size = 64, Examples/Sec = 7468.16, Accuracy = 0.55, Loss = 1.378
[2019-05-03 20:23] Train Step 264000/1000000, Batch Size = 64, Examples/Sec = 7360.04, Accuracy = 0.56, Loss = 1.306
[2019-05-03 20:24] Train Step 265000/1000000, Batch Size = 64, Examples/Sec = 7375.41, Accuracy = 0.58, Loss = 1.277
[2019-05-03 20:24] Train Step 266000/1000000, Batch Size = 64, Examples/Sec = 7372.78, Accuracy = 0.59, Loss = 1.296
[2019-05-03 20:24] Train Step 267000/1000000, Batch Size = 64, Examples/Sec = 7349.76, Accuracy = 0.57, Loss = 1.301
[2019-05-03 20:24] Train Step 268000/1000000, Batch Size = 64, Examples/Sec = 7391.45, Accuracy = 0.59, Loss = 1.274
[2019-05-03 20:24] Train Step 269000/1000000, Batch Size = 64, Examples/Sec = 7463.38, Accuracy = 0.59, Loss = 1.266
[2019-05-03 20:24] Train Step 270000/1000000, Batch Size = 64, Examples/Sec = 7396.95, Accuracy = 0.59, Loss = 1.239
[2019-05-03 20:25] Train Step 271000/1000000, Batch Size = 64, Examples/Sec = 7479.39, Accuracy = 0.58, Loss = 1.264
[2019-05-03 20:25] Train Step 272000/1000000, Batch Size = 64, Examples/Sec = 7496.31, Accuracy = 0.56, Loss = 1.361
[2019-05-03 20:25] Train Step 273000/1000000, Batch Size = 64, Examples/Sec = 7381.09, Accuracy = 0.59, Loss = 1.252
[2019-05-03 20:25] Train Step 274000/1000000, Batch Size = 64, Examples/Sec = 7486.07, Accuracy = 0.57, Loss = 1.320
[2019-05-03 20:25] Train Step 275000/1000000, Batch Size = 64, Examples/Sec = 7486.70, Accuracy = 0.58, Loss = 1.288
[2019-05-03 20:25] Train Step 276000/1000000, Batch Size = 64, Examples/Sec = 7354.80, Accuracy = 0.59, Loss = 1.262
[2019-05-03 20:26] Train Step 277000/1000000, Batch Size = 64, Examples/Sec = 7358.83, Accuracy = 0.58, Loss = 1.284
[2019-05-03 20:26] Train Step 278000/1000000, Batch Size = 64, Examples/Sec = 7358.43, Accuracy = 0.56, Loss = 1.335
[2019-05-03 20:26] Train Step 279000/1000000, Batch Size = 64, Examples/Sec = 7462.55, Accuracy = 0.60, Loss = 1.217
[2019-05-03 20:26] Train Step 280000/1000000, Batch Size = 64, Examples/Sec = 7389.62, Accuracy = 0.58, Loss = 1.248
[2019-05-03 20:26] Train Step 281000/1000000, Batch Size = 64, Examples/Sec = 7489.41, Accuracy = 0.58, Loss = 1.295
[2019-05-03 20:27] Train Step 282000/1000000, Batch Size = 64, Examples/Sec = 7366.91, Accuracy = 0.57, Loss = 1.285
[2019-05-03 20:27] Train Step 283000/1000000, Batch Size = 64, Examples/Sec = 7487.11, Accuracy = 0.56, Loss = 1.287
[2019-05-03 20:27] Train Step 284000/1000000, Batch Size = 64, Examples/Sec = 7359.24, Accuracy = 0.56, Loss = 1.281
[2019-05-03 20:27] Train Step 285000/1000000, Batch Size = 64, Examples/Sec = 7501.13, Accuracy = 0.58, Loss = 1.291
[2019-05-03 20:27] Train Step 286000/1000000, Batch Size = 64, Examples/Sec = 7348.96, Accuracy = 0.57, Loss = 1.310
[2019-05-03 20:27] Train Step 287000/1000000, Batch Size = 64, Examples/Sec = 7145.32, Accuracy = 0.60, Loss = 1.253
[2019-05-03 20:28] Train Step 288000/1000000, Batch Size = 64, Examples/Sec = 7481.69, Accuracy = 0.57, Loss = 1.280
[2019-05-03 20:28] Train Step 289000/1000000, Batch Size = 64, Examples/Sec = 7353.99, Accuracy = 0.58, Loss = 1.268
[2019-05-03 20:28] Train Step 290000/1000000, Batch Size = 64, Examples/Sec = 7493.80, Accuracy = 0.57, Loss = 1.297
[2019-05-03 20:28] Train Step 291000/1000000, Batch Size = 64, Examples/Sec = 7335.71, Accuracy = 0.58, Loss = 1.276
[2019-05-03 20:28] Train Step 292000/1000000, Batch Size = 64, Examples/Sec = 7344.34, Accuracy = 0.59, Loss = 1.281
[2019-05-03 20:28] Train Step 293000/1000000, Batch Size = 64, Examples/Sec = 7497.15, Accuracy = 0.61, Loss = 1.182
[2019-05-03 20:29] Train Step 294000/1000000, Batch Size = 64, Examples/Sec = 7370.35, Accuracy = 0.58, Loss = 1.264
[2019-05-03 20:29] Train Step 295000/1000000, Batch Size = 64, Examples/Sec = 7376.83, Accuracy = 0.56, Loss = 1.326
[2019-05-03 20:29] Train Step 296000/1000000, Batch Size = 64, Examples/Sec = 7378.86, Accuracy = 0.56, Loss = 1.366
[2019-05-03 20:29] Train Step 297000/1000000, Batch Size = 64, Examples/Sec = 7383.12, Accuracy = 0.58, Loss = 1.272
[2019-05-03 20:29] Train Step 298000/1000000, Batch Size = 64, Examples/Sec = 7503.23, Accuracy = 0.58, Loss = 1.268
[2019-05-03 20:29] Train Step 299000/1000000, Batch Size = 64, Examples/Sec = 7381.90, Accuracy = 0.57, Loss = 1.288
[2019-05-03 20:30] Train Step 300000/1000000, Batch Size = 64, Examples/Sec = 7366.10, Accuracy = 0.57, Loss = 1.333
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Ja sitten hän oli kuitenkin mu
lla oli kaikkiaan kuin mitä mi
? Ninni kysyi.\n Ninni ei ollut 
: Marja Leena oli kuitenkin mu
Ninni oli kuitenkin muuta kuin

Generated 5 long samples (100 chars):
5. \n Tässä sitten hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenk
9. \n He olivat tulleet katsellessaan kuin mitä mies oli kaikkiaan kuin mitä mies oli kaikkiaan kuin m
bileitä oli tullut koko ajan. \n Ei siis pitänyt koko ajan kuin mitä mies oli kaikkiaan kuin mitä mies
den kanssa ja katseli kuin mitä mies oli kaikkiaan kuin mitä mies oli kaikkiaan kuin mitä mies oli k
6. \n Mies oli tapana kaikki laittaa tuon kanssa ja katseli kuin mitä mies oli kaikkiaan kuin mitä mie
-------------------------------------------
Temperature: 0.25
Generated 5:
Ari oli kotona ja katseli kuin
9. \n Hän oli tullut pitkään ett
Jos mä olisin se ollut koskaan
quetta kuin mitä hän oli jo ka
än sen sijaan että hän oli saa

Generated 5 long samples (100 chars):
Gunilla oli tullut sitä silloin kun tämä oli kaikkiaan kuin mitä mies oli tapana kertoa mitään tuon 
che oli kuullut tullut koko ajan. \n Kalle oli tullut aivan tuntevansa sen katsomaan tulleen toisensa 
Älä vain saanut mitään kaiken lisäksi kuin mitä se tuntui kaikki nämä kaikki oli sitä koko asiaa. \n M
Isä oli kaksi puolestaan saattoi kuitenkin tulleensa kanssa. \n Mitä sä tiedät mitä hän oli sanonut si
Öljä ja Ninni oli tullut mitään tietoja ja katseli kuin se oli kuitenkin todellakin sen katsonut kai
-------------------------------------------
Temperature: 0.5
Generated 5:
Ninni huora sai poliisi tuli t
é tuli kahdentoista. \n Hän oli 
(joitaan. \n Hän katseli hänen k
Faceboon. \n Toisaalta se oli se
é katseli veneen sisälle ja si

Generated 5 long samples (100 chars):
Marja Leena oli jo kahdeksantoista suomalaisen päivänsä luonnon ja vain ei ollut paljon kuulunut sii
Ja jos sattui jo viimeistelevän kanssa. \n Tiedätkö sinne oli pari päässään kiinni katsomaan näkymättö
Ari ajatteli.\n Taitavasti toisten täytyi olla asian kanssa. Kalle oli vielä toisesta päättivät koko a
bussi oli kaikkiaan kotiin. Se oli tottunut koko iltapäivän katseen tai jotain, että näiden puolella
Ari katseli takaisin sitä enemmän kuin mitä oli kyllä pitkään tehdä jotain mielessään. \n Kolme viehil
-------------------------------------------
Temperature: 1.0
Generated 5:
é.\n Ee sitten hän kävi hänen me
Xentumalla Naivalan, jonka nap
Qontra, viesteessä tuntui likk
Ladanheidermalla Lluís lopulta
Ensintä se, Itämä vain kahvink

Generated 5 long samples (100 chars):
rissä kytkin väittiä hänen hyvä puutarha luoksen elämään. \n Sattuu koskaan ollut erityistä naapurin p
9 muuta kahdesti heistä sen sijaan tiesi melko lamatkaa rekkausittava niin lopettaa paragvaiston pak
Gunillan takaisin. Valtioilta yritti aina tarvittu perheen sen miti laskeva oli vapaasti puutarha ta
xan valot kieläläisen pari yrittävänsä ja käärinyt tätä kaikkein hyvässä koko ajan, jotain tyydyttäv
Isä oli välittelemään hänen kohtaudat. \n Oppinoityisen kerran punainen sotteli heidän maksumman selkä
-------------------------------------------
Temperature: 2.0
Generated 5:
; hänetke. Entä?\n Sorvekapunu! 
'Oleen,. Limerikkatu jäimokuva
gjään. Pujajipulltittes kkiäyh
\n 8GSohcollin ken uRagäntuSik  
Ölvushaihaslujaan vuokranna \n S

Generated 5 long samples (100 chars):
Lilotopella? Amalkapäinus äisi heliensä kuran Barcicink.\n Ny ja entä nerejämästä.\n Wow Luci ujatelluu,
övysään tundituvalla?\n 4. Minut.\n Hei ehti eivätki: No pyskinykty oletuopai.\n Saus omassa, lievettäkään
Siinä temme. Ympluyon!\n Sekvittu kommeli. \n Esimerkiinaloppuun ksso-.\n Näytkejä, ylpeät, olivatkin part
;'Herolo taillokemeamaaston, nähde rivillaa, aiakauhi. Cmeant sekobilvarastoiden Lööf numku, raatijo
00it-joksye väitettö paskaan?\n Agolimell-on.\n Olut, paknasä!\n He vähnäri, kuimminhin erän aikejoudaan?\n 
-------------------------------------------
[2019-05-03 20:30] Train Step 301000/1000000, Batch Size = 64, Examples/Sec = 6273.18, Accuracy = 0.56, Loss = 1.345
[2019-05-03 20:30] Train Step 302000/1000000, Batch Size = 64, Examples/Sec = 6141.70, Accuracy = 0.58, Loss = 1.290
[2019-05-03 20:30] Train Step 303000/1000000, Batch Size = 64, Examples/Sec = 6244.14, Accuracy = 0.59, Loss = 1.283
[2019-05-03 20:30] Train Step 304000/1000000, Batch Size = 64, Examples/Sec = 6154.52, Accuracy = 0.57, Loss = 1.322
[2019-05-03 20:31] Train Step 305000/1000000, Batch Size = 64, Examples/Sec = 6264.83, Accuracy = 0.59, Loss = 1.269
[2019-05-03 20:31] Train Step 306000/1000000, Batch Size = 64, Examples/Sec = 6152.68, Accuracy = 0.57, Loss = 1.294
[2019-05-03 20:31] Train Step 307000/1000000, Batch Size = 64, Examples/Sec = 6261.32, Accuracy = 0.58, Loss = 1.327
[2019-05-03 20:31] Train Step 308000/1000000, Batch Size = 64, Examples/Sec = 6141.70, Accuracy = 0.58, Loss = 1.241
[2019-05-03 20:31] Train Step 309000/1000000, Batch Size = 64, Examples/Sec = 6222.57, Accuracy = 0.61, Loss = 1.181
[2019-05-03 20:32] Train Step 310000/1000000, Batch Size = 64, Examples/Sec = 6161.16, Accuracy = 0.57, Loss = 1.299
[2019-05-03 20:32] Train Step 311000/1000000, Batch Size = 64, Examples/Sec = 6160.73, Accuracy = 0.58, Loss = 1.286
[2019-05-03 20:32] Train Step 312000/1000000, Batch Size = 64, Examples/Sec = 6259.43, Accuracy = 0.57, Loss = 1.297
[2019-05-03 20:32] Train Step 313000/1000000, Batch Size = 64, Examples/Sec = 6172.77, Accuracy = 0.59, Loss = 1.244
[2019-05-03 20:32] Train Step 314000/1000000, Batch Size = 64, Examples/Sec = 6032.12, Accuracy = 0.57, Loss = 1.298
[2019-05-03 20:33] Train Step 315000/1000000, Batch Size = 64, Examples/Sec = 6104.97, Accuracy = 0.57, Loss = 1.314
[2019-05-03 20:33] Train Step 316000/1000000, Batch Size = 64, Examples/Sec = 6247.48, Accuracy = 0.57, Loss = 1.280
[2019-05-03 20:33] Train Step 317000/1000000, Batch Size = 64, Examples/Sec = 6245.88, Accuracy = 0.57, Loss = 1.319
[2019-05-03 20:33] Train Step 318000/1000000, Batch Size = 64, Examples/Sec = 6150.57, Accuracy = 0.58, Loss = 1.295
[2019-05-03 20:34] Train Step 319000/1000000, Batch Size = 64, Examples/Sec = 6247.77, Accuracy = 0.59, Loss = 1.284
[2019-05-03 20:34] Train Step 320000/1000000, Batch Size = 64, Examples/Sec = 6230.66, Accuracy = 0.59, Loss = 1.295
[2019-05-03 20:34] Train Step 321000/1000000, Batch Size = 64, Examples/Sec = 5978.65, Accuracy = 0.59, Loss = 1.259
[2019-05-03 20:34] Train Step 322000/1000000, Batch Size = 64, Examples/Sec = 6150.71, Accuracy = 0.57, Loss = 1.285
[2019-05-03 20:34] Train Step 323000/1000000, Batch Size = 64, Examples/Sec = 6263.08, Accuracy = 0.58, Loss = 1.296
[2019-05-03 20:35] Train Step 324000/1000000, Batch Size = 64, Examples/Sec = 6170.36, Accuracy = 0.59, Loss = 1.258
[2019-05-03 20:35] Train Step 325000/1000000, Batch Size = 64, Examples/Sec = 6117.35, Accuracy = 0.57, Loss = 1.343
[2019-05-03 20:35] Train Step 326000/1000000, Batch Size = 64, Examples/Sec = 6227.48, Accuracy = 0.57, Loss = 1.294
[2019-05-03 20:35] Train Step 327000/1000000, Batch Size = 64, Examples/Sec = 6264.39, Accuracy = 0.57, Loss = 1.346
[2019-05-03 20:35] Train Step 328000/1000000, Batch Size = 64, Examples/Sec = 6236.01, Accuracy = 0.57, Loss = 1.279
[2019-05-03 20:36] Train Step 329000/1000000, Batch Size = 64, Examples/Sec = 6026.57, Accuracy = 0.59, Loss = 1.224
[2019-05-03 20:36] Train Step 330000/1000000, Batch Size = 64, Examples/Sec = 6203.30, Accuracy = 0.58, Loss = 1.295
[2019-05-03 20:36] Train Step 331000/1000000, Batch Size = 64, Examples/Sec = 6213.93, Accuracy = 0.58, Loss = 1.281
[2019-05-03 20:36] Train Step 332000/1000000, Batch Size = 64, Examples/Sec = 6209.04, Accuracy = 0.57, Loss = 1.329
[2019-05-03 20:36] Train Step 333000/1000000, Batch Size = 64, Examples/Sec = 6223.58, Accuracy = 0.57, Loss = 1.290
[2019-05-03 20:37] Train Step 334000/1000000, Batch Size = 64, Examples/Sec = 6226.47, Accuracy = 0.57, Loss = 1.327
[2019-05-03 20:37] Train Step 335000/1000000, Batch Size = 64, Examples/Sec = 6219.83, Accuracy = 0.58, Loss = 1.266
[2019-05-03 20:37] Train Step 336000/1000000, Batch Size = 64, Examples/Sec = 6226.76, Accuracy = 0.57, Loss = 1.316
[2019-05-03 20:37] Train Step 337000/1000000, Batch Size = 64, Examples/Sec = 6251.41, Accuracy = 0.58, Loss = 1.236
[2019-05-03 20:37] Train Step 338000/1000000, Batch Size = 64, Examples/Sec = 6227.62, Accuracy = 0.57, Loss = 1.300
[2019-05-03 20:38] Train Step 339000/1000000, Batch Size = 64, Examples/Sec = 6243.27, Accuracy = 0.58, Loss = 1.231
[2019-05-03 20:38] Train Step 340000/1000000, Batch Size = 64, Examples/Sec = 6225.46, Accuracy = 0.57, Loss = 1.328
[2019-05-03 20:38] Train Step 341000/1000000, Batch Size = 64, Examples/Sec = 6191.85, Accuracy = 0.57, Loss = 1.319
[2019-05-03 20:38] Train Step 342000/1000000, Batch Size = 64, Examples/Sec = 6211.48, Accuracy = 0.59, Loss = 1.299
[2019-05-03 20:38] Train Step 343000/1000000, Batch Size = 64, Examples/Sec = 6210.19, Accuracy = 0.59, Loss = 1.254
[2019-05-03 20:39] Train Step 344000/1000000, Batch Size = 64, Examples/Sec = 6214.36, Accuracy = 0.58, Loss = 1.261
[2019-05-03 20:39] Train Step 345000/1000000, Batch Size = 64, Examples/Sec = 6226.76, Accuracy = 0.58, Loss = 1.309
[2019-05-03 20:39] Train Step 346000/1000000, Batch Size = 64, Examples/Sec = 6188.14, Accuracy = 0.57, Loss = 1.287
[2019-05-03 20:39] Train Step 347000/1000000, Batch Size = 64, Examples/Sec = 6157.77, Accuracy = 0.58, Loss = 1.263
[2019-05-03 20:39] Train Step 348000/1000000, Batch Size = 64, Examples/Sec = 6265.42, Accuracy = 0.57, Loss = 1.291
[2019-05-03 20:40] Train Step 349000/1000000, Batch Size = 64, Examples/Sec = 6223.87, Accuracy = 0.60, Loss = 1.272
[2019-05-03 20:40] Train Step 350000/1000000, Batch Size = 64, Examples/Sec = 6229.21, Accuracy = 0.58, Loss = 1.321
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Taiwanin filmit olivat kaikki 
Oli mieleen kuin mitä se oli t
wanin kanssa. \n Mitä sitä oli t
2. \n Kun he olivat tulleet kats
Öljä ja sen jälkeen kun hän ol

Generated 5 long samples (100 chars):
Sitten hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta k
ís oli tullut mitään selvittämään mitä mielessään tuli siitä kuin mitä mies oli se olisi tullut mitä
( aina kun hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muu
den kanssa. \n Miten niin hän ollut koskaan tullut koko ajan. \n Minulla on kaikki oli kuitenkin muuta k
Öljä ja sen jälkeen kun hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli 
-------------------------------------------
Temperature: 0.25
Generated 5:
sta siitä, että hänen kanssaan
minulle ja hänen sisälleen kok
Yksi katsomaan kun hän oli kat
) ja takaisin kotiinsa ja lait
ta siitä, että hän oli parasta

Generated 5 long samples (100 chars):
8. \n Kaikki oli vain hyvä kaikki tuli työtä kannattaisi tavaraa ja muuttui tulla mitään, mutta tämä o
; tai sitä mitä oli vain enää paljon aikaa kuin vain sitä samaa kerran vuoksi. \n Mitä sinä olet aina 
filmin paras ystävänsä tuli paljon paremmin kuin kun hän oli sanonut mitään tuntemaan näitä kaupunki
helinta kaikki oli tullut koko kertaa kuin mitä mies oli jo tullut mitään, mutta tuli jo perheen yhd
Siitä oli tapahtunut. Hän oli kuitenkin vain silloin kun hän oli lähtenyt jo pelkkä ajatus siitä ett
-------------------------------------------
Temperature: 0.5
Generated 5:
Usein hän voinut olla vieläkin
Siimeksen piripintaan. \n Kalle 
Yksi minua pitkälle, jota saat
kaisin mukaan ja tuli paperill
zalleen pitkälle, kun hän puhu

Generated 5 long samples (100 chars):
Oli vain pakattu vaimonsa ja niitä mulle karvaisena päivänä hän oli kuullut jo melkein kyllä kirosi 
, mutta paikalla oli saanut sanoa sinä tavarat tuntuivat kaikki päättänyt järjestelyymmentä kahvia. 
n tuon maininneet sitä ylipuhua. \n Kun mä olin mennä sillä ollut koskaan kuulunut häntä tuntemaan kai
Daar! jos sä oot polttanut ja kertoi kuinka nämä lasten hiuksen ja laittaa kaikki oli liian kuluttua
Ninni oli sentään mitään toisen menneisyydestä.\n Ei siis ollut koskaan asunut tuota toiseen kanssa. K
-------------------------------------------
Temperature: 1.0
Generated 5:
mistaan numeroo, jos joku mä v
öhemmin tyhjän tän. \n Marja Lee
-raiskaudesta.\n No ei suoranais
eensä.\n Radmilo ei laittanut tu
;9. \n Ninni haasti, sitä tällai

Generated 5 long samples (100 chars):
) kärityksessä elämäni pihat vuotta sittemmät peniksellään terminaalista. Hänestä ei määttyi perin-p
winkin oikeastaan sellaisen suuhensa. \n Tällä kertaa myös mitä täällä useissa, kuten sillon että hän 
ällähtö oli varsin, mut enkä mua, mutta nyys oli narsa, Kalle vaitoi hänelle sukeltavaa, sillä et se
t haistaa vasta jälkeenpäin uniimat olivatkin usein oo kukaan eri mitään vain nimeltään. Palattui ko
Yleisinä ja auttaa uimisen ja matkusti tekonaa uima-altaalle.\n Ei siis. \n Lasin asunnon kulmaa. Tuomat
-------------------------------------------
Temperature: 2.0
Generated 5:
jawpöhå? Kbikis. \n Täynnäkin. S
Kattoin jumerah Nirlatteli? Ni
qen, jatain hukkumittaa Römpän
Cjuomhuviestakaan, Jeesuu asun
Raamoja.\n Väin kihjamaisissa, n

Generated 5 long samples (100 chars):
lla mokanan.\n Ossie B\n Sabu Dgrilsigbet,...ielä! Kai. Telkkaaak. Cijus. Se johtui kun onit ja kauppust
Los kolmen tietä siseiluo lampikkeenen mitä.....15i, Lci ne asfy loinoiltu. Hän näin mi häetävä kaes
493. Et?MI.,. Alen sinno valounu sitäkin, irvoo! Emilipman löylalo  vanha!\n Antinko todelli ystävytty
vunlian taahaamäntä, höjkynkin ehdoton sushanu Puesbasdan. Miten Ba:-Jokku.  mikä huikonparhaak., Ll
brepis\n bisne.\n Pearpotissa, kuulaeäa tätäkin lapissu skenniiritijaimen kenikmaa,,, ja poliitetonta, a
-------------------------------------------
[2019-05-03 20:40] Train Step 351000/1000000, Batch Size = 64, Examples/Sec = 6252.86, Accuracy = 0.58, Loss = 1.266
[2019-05-03 20:40] Train Step 352000/1000000, Batch Size = 64, Examples/Sec = 6234.13, Accuracy = 0.57, Loss = 1.292
[2019-05-03 20:40] Train Step 353000/1000000, Batch Size = 64, Examples/Sec = 6206.89, Accuracy = 0.58, Loss = 1.285
[2019-05-03 20:41] Train Step 354000/1000000, Batch Size = 64, Examples/Sec = 6209.18, Accuracy = 0.58, Loss = 1.279
[2019-05-03 20:41] Train Step 355000/1000000, Batch Size = 64, Examples/Sec = 5833.65, Accuracy = 0.58, Loss = 1.278
[2019-05-03 20:41] Train Step 356000/1000000, Batch Size = 64, Examples/Sec = 6261.32, Accuracy = 0.59, Loss = 1.240
[2019-05-03 20:41] Train Step 357000/1000000, Batch Size = 64, Examples/Sec = 6217.53, Accuracy = 0.58, Loss = 1.256
[2019-05-03 20:41] Train Step 358000/1000000, Batch Size = 64, Examples/Sec = 6229.65, Accuracy = 0.59, Loss = 1.286
[2019-05-03 20:42] Train Step 359000/1000000, Batch Size = 64, Examples/Sec = 6235.29, Accuracy = 0.57, Loss = 1.290
[2019-05-03 20:42] Train Step 360000/1000000, Batch Size = 64, Examples/Sec = 6232.25, Accuracy = 0.57, Loss = 1.302
[2019-05-03 20:42] Train Step 361000/1000000, Batch Size = 64, Examples/Sec = 6249.81, Accuracy = 0.58, Loss = 1.248
[2019-05-03 20:42] Train Step 362000/1000000, Batch Size = 64, Examples/Sec = 6193.43, Accuracy = 0.59, Loss = 1.240
[2019-05-03 20:43] Train Step 363000/1000000, Batch Size = 64, Examples/Sec = 6224.16, Accuracy = 0.57, Loss = 1.302
[2019-05-03 20:43] Train Step 364000/1000000, Batch Size = 64, Examples/Sec = 6176.04, Accuracy = 0.57, Loss = 1.298
[2019-05-03 20:43] Train Step 365000/1000000, Batch Size = 64, Examples/Sec = 6199.72, Accuracy = 0.59, Loss = 1.252
[2019-05-03 20:43] Train Step 366000/1000000, Batch Size = 64, Examples/Sec = 6270.24, Accuracy = 0.58, Loss = 1.276
[2019-05-03 20:43] Train Step 367000/1000000, Batch Size = 64, Examples/Sec = 6217.09, Accuracy = 0.58, Loss = 1.265
[2019-05-03 20:44] Train Step 368000/1000000, Batch Size = 64, Examples/Sec = 6216.37, Accuracy = 0.59, Loss = 1.300
[2019-05-03 20:44] Train Step 369000/1000000, Batch Size = 64, Examples/Sec = 6254.47, Accuracy = 0.59, Loss = 1.260
[2019-05-03 20:44] Train Step 370000/1000000, Batch Size = 64, Examples/Sec = 6221.56, Accuracy = 0.56, Loss = 1.320
[2019-05-03 20:44] Train Step 371000/1000000, Batch Size = 64, Examples/Sec = 6227.19, Accuracy = 0.60, Loss = 1.229
[2019-05-03 20:44] Train Step 372000/1000000, Batch Size = 64, Examples/Sec = 6224.73, Accuracy = 0.56, Loss = 1.356
[2019-05-03 20:45] Train Step 373000/1000000, Batch Size = 64, Examples/Sec = 6210.33, Accuracy = 0.58, Loss = 1.232
[2019-05-03 20:45] Train Step 374000/1000000, Batch Size = 64, Examples/Sec = 6220.41, Accuracy = 0.58, Loss = 1.245
[2019-05-03 20:45] Train Step 375000/1000000, Batch Size = 64, Examples/Sec = 6239.93, Accuracy = 0.57, Loss = 1.282
[2019-05-03 20:45] Train Step 376000/1000000, Batch Size = 64, Examples/Sec = 6203.73, Accuracy = 0.57, Loss = 1.294
[2019-05-03 20:45] Train Step 377000/1000000, Batch Size = 64, Examples/Sec = 6235.58, Accuracy = 0.60, Loss = 1.198
[2019-05-03 20:46] Train Step 378000/1000000, Batch Size = 64, Examples/Sec = 6238.19, Accuracy = 0.58, Loss = 1.314
[2019-05-03 20:46] Train Step 379000/1000000, Batch Size = 64, Examples/Sec = 6266.00, Accuracy = 0.60, Loss = 1.225
[2019-05-03 20:46] Train Step 380000/1000000, Batch Size = 64, Examples/Sec = 6230.22, Accuracy = 0.60, Loss = 1.242
[2019-05-03 20:46] Train Step 381000/1000000, Batch Size = 64, Examples/Sec = 6216.52, Accuracy = 0.57, Loss = 1.301
[2019-05-03 20:46] Train Step 382000/1000000, Batch Size = 64, Examples/Sec = 6208.18, Accuracy = 0.58, Loss = 1.275
[2019-05-03 20:47] Train Step 383000/1000000, Batch Size = 64, Examples/Sec = 6218.97, Accuracy = 0.61, Loss = 1.219
[2019-05-03 20:47] Train Step 384000/1000000, Batch Size = 64, Examples/Sec = 6200.44, Accuracy = 0.60, Loss = 1.185
[2019-05-03 20:47] Train Step 385000/1000000, Batch Size = 64, Examples/Sec = 6073.48, Accuracy = 0.58, Loss = 1.270
[2019-05-03 20:47] Train Step 386000/1000000, Batch Size = 64, Examples/Sec = 6195.14, Accuracy = 0.59, Loss = 1.271
[2019-05-03 20:47] Train Step 387000/1000000, Batch Size = 64, Examples/Sec = 6184.01, Accuracy = 0.60, Loss = 1.272
[2019-05-03 20:48] Train Step 388000/1000000, Batch Size = 64, Examples/Sec = 6231.53, Accuracy = 0.59, Loss = 1.238
[2019-05-03 20:48] Train Step 389000/1000000, Batch Size = 64, Examples/Sec = 6253.16, Accuracy = 0.60, Loss = 1.271
[2019-05-03 20:48] Train Step 390000/1000000, Batch Size = 64, Examples/Sec = 6238.33, Accuracy = 0.56, Loss = 1.334
[2019-05-03 20:48] Train Step 391000/1000000, Batch Size = 64, Examples/Sec = 6217.53, Accuracy = 0.58, Loss = 1.278
[2019-05-03 20:48] Train Step 392000/1000000, Batch Size = 64, Examples/Sec = 6210.91, Accuracy = 0.59, Loss = 1.277
[2019-05-03 20:49] Train Step 393000/1000000, Batch Size = 64, Examples/Sec = 6229.50, Accuracy = 0.59, Loss = 1.256
[2019-05-03 20:49] Train Step 394000/1000000, Batch Size = 64, Examples/Sec = 6143.11, Accuracy = 0.60, Loss = 1.257
[2019-05-03 20:49] Train Step 395000/1000000, Batch Size = 64, Examples/Sec = 6195.28, Accuracy = 0.58, Loss = 1.254
[2019-05-03 20:49] Train Step 396000/1000000, Batch Size = 64, Examples/Sec = 6005.80, Accuracy = 0.56, Loss = 1.299
[2019-05-03 20:49] Train Step 397000/1000000, Batch Size = 64, Examples/Sec = 6242.69, Accuracy = 0.58, Loss = 1.306
[2019-05-03 20:50] Train Step 398000/1000000, Batch Size = 64, Examples/Sec = 6220.41, Accuracy = 0.60, Loss = 1.240
[2019-05-03 20:50] Train Step 399000/1000000, Batch Size = 64, Examples/Sec = 6228.63, Accuracy = 0.58, Loss = 1.283
[2019-05-03 20:50] Train Step 400000/1000000, Batch Size = 64, Examples/Sec = 6216.23, Accuracy = 0.59, Loss = 1.296
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Perälä oli tapana kaikki ne ol
è sitä saattoi olla tavalla ja
Wow, joku oli kuitenkin muuta 
ut sen kaiken mielestä ja kats
2. \n Kun he olivat tulleet kats

Generated 5 long samples (100 chars):
wanin parissa ja katseli kuinka hän oli tullut mitään selvittämään mielessään tapahtunut. Hän oli ku
Oli mieleen kuin mitä minun oli kaikkiaan kuin mitä minulle oli tapana kaikki ne olivat kaikki ne ol
Yksi näistä kaikki oli kaikkiaan kuin mitä minulle oli tapana kaikki ne olivat kaikki ne olivat kaik
úsin kuin mitä mies oli se kuin mitä minun oli kaikkiaan kuin mitä minulle oli tapana kaikki ne oliv
2. \n Kun he olivat tulleet katsellessaan sen kaiken mielestä ja katseli kuinka hän oli tullut mitään 
-------------------------------------------
Temperature: 0.25
Generated 5:
xin valkoisia kuin mitä hän ol
bia keskittyi kuvitella mitään
; tai koskaan tullut mitään se
2. \n Kun kaikki oli kaikkiaan v
palata ja muutaman kerran hän 

Generated 5 long samples (100 chars):
n mielessään teki sitä mielessään tuli että hän oli tapahtunut ja joitakin kuin kaikki oli katsellut
quen kuin mitä se oli kuitenkin paljon muuta kuin samalla tavoin kuin hän oli kuitenkin vain sitä mi
( minä olin koskaan tullut pitkään sitä mitä mies oli jo kauan kuin mitä se oli tapahtunut. Hän oli 
: Herran valuis ja hänen vierellään valtion kanssa. \n Mitä sä tietenkään tiennyt mitä tahtoisi mitä m
; täytyi kaikkia mitään mitään selvittämään pitkin kirjaston ja katseli kuinka hän oli tapahtunut ja
-------------------------------------------
Temperature: 0.5
Generated 5:
Ari oli kokemusta oli kertonut
5.\n Katjan jo pelkkä ajatusta j
6. \n Kun kolmas oli jo kaikki k
2'.'.\n \n Hasi menossa kaikki oli
7. \n Kun puolestaan paikalla ol

Generated 5 long samples (100 chars):
Kalle ei voinut mitenkään ollut paljon paikkaan, joka johdatti häntä koskaan sen kuului hänet saatto
Flemmingsbergin kanssa. \n Lluís ei ollut koskaan kovin olla kovin kanssa. \n Ari ei tiennyt mitä tekisi
Isä oli jo liian alkanut kiinni ja lähtien kanssa sanoi ja käveli surulta. Hän oli kuitenkin muuttan
; sähen hiljaisuuden tunteita maailmaa eivät olleet koskaan kuitenkaan palannut minulle pienen kuin 
0 ei tiennyt mitä se oli aina kuulunut jo tuolloin kertonut tarkoituksenaan kuten aina vaikka pitäny
-------------------------------------------
Temperature: 1.0
Generated 5:
Emmä sänsa oo koskaan tullut l
;9...\n En mä rakasta, tähän?'. 
qiosa, joiden jälkeen kirkon t
Östan tyhjillä tielikö kuului 
änen olla asuinpahjasti kerral

Generated 5 long samples (100 chars):
wde.\n En ainaan nähnyt intani välissä. Kun hän luule kyllin oli käskelin kauhassa se tuli, vai märäss
Karvista loppua tuoksuaksineen. Ja mikalulla oli vain voisi jotta saisi männyn yhdellä ollut joitaki
yt että valtiolleen sotilappiin.\n Kalle heti selvilleen. Kai teoppisajajat. Vievää taussaan, oli ja m
f Ei se missään eellyssaisen pohjalle. En halunnu sinulle tuolloista. \n Oli liiman metriään lautakerr
úsin ja Lluís kysyi hyllyltä. Paksutossa pieni sängyn takaa he olivat huonekaan. Niillä vaatiisi ist
-------------------------------------------
Temperature: 2.0
Generated 5:
Aasia etääm joten Äiti varisro
Tyt Vebodya? Nanse vaacun? Täy
ónjaiden. Pelarojanktyliimunki
i frpsbiinit, jokaan avita jam
Ziltesjedelaspäisi tahattikado

Generated 5 long samples (100 chars):
Xra.\n 'Ovaan hän kahviike, ex siksneita äudauduön, pöstissyäksi papEudaja sitten ovo, ja sä en Kuka o
é sumaisivat hatcsat taastoivurren, tyt ylieppös kaiken tavoimin. Nuraa, vidiarjanniä. Lluís heni tä
ulre Tahtrorujapäykispalle treoria, estenillään olleskus, setä pilve. Olin uharkää tämästä.\n Sen perj
2 äijä ei hakannu ku outu syppylämjestä vain. Kämmen lopisakotrovisaikaantua me,o. huolit. in eb.\n \n E
Kaikki päin minä.\n Kutta lont ja joit, muten ettei Lluís otta.\n Teis kansalaaneilit-otersinssajoehon h
-------------------------------------------
[2019-05-03 20:50] Train Step 401000/1000000, Batch Size = 64, Examples/Sec = 6218.97, Accuracy = 0.58, Loss = 1.267
[2019-05-03 20:51] Train Step 402000/1000000, Batch Size = 64, Examples/Sec = 6224.30, Accuracy = 0.59, Loss = 1.256
[2019-05-03 20:51] Train Step 403000/1000000, Batch Size = 64, Examples/Sec = 6239.64, Accuracy = 0.56, Loss = 1.320
[2019-05-03 20:51] Train Step 404000/1000000, Batch Size = 64, Examples/Sec = 6228.78, Accuracy = 0.59, Loss = 1.262
[2019-05-03 20:51] Train Step 405000/1000000, Batch Size = 64, Examples/Sec = 6224.01, Accuracy = 0.57, Loss = 1.304
[2019-05-03 20:51] Train Step 406000/1000000, Batch Size = 64, Examples/Sec = 6255.20, Accuracy = 0.59, Loss = 1.255
[2019-05-03 20:52] Train Step 407000/1000000, Batch Size = 64, Examples/Sec = 6252.43, Accuracy = 0.57, Loss = 1.321
[2019-05-03 20:52] Train Step 408000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.60, Loss = 1.240
[2019-05-03 20:52] Train Step 409000/1000000, Batch Size = 64, Examples/Sec = 6211.63, Accuracy = 0.58, Loss = 1.269
[2019-05-03 20:52] Train Step 410000/1000000, Batch Size = 64, Examples/Sec = 6214.79, Accuracy = 0.58, Loss = 1.320
[2019-05-03 20:53] Train Step 411000/1000000, Batch Size = 64, Examples/Sec = 6192.57, Accuracy = 0.58, Loss = 1.262
[2019-05-03 20:53] Train Step 412000/1000000, Batch Size = 64, Examples/Sec = 6211.34, Accuracy = 0.60, Loss = 1.218
[2019-05-03 20:53] Train Step 413000/1000000, Batch Size = 64, Examples/Sec = 6218.39, Accuracy = 0.57, Loss = 1.303
[2019-05-03 20:53] Train Step 414000/1000000, Batch Size = 64, Examples/Sec = 6225.75, Accuracy = 0.57, Loss = 1.294
[2019-05-03 20:53] Train Step 415000/1000000, Batch Size = 64, Examples/Sec = 6223.29, Accuracy = 0.59, Loss = 1.270
[2019-05-03 20:54] Train Step 416000/1000000, Batch Size = 64, Examples/Sec = 6218.10, Accuracy = 0.58, Loss = 1.270
[2019-05-03 20:54] Train Step 417000/1000000, Batch Size = 64, Examples/Sec = 6214.50, Accuracy = 0.57, Loss = 1.311
[2019-05-03 20:54] Train Step 418000/1000000, Batch Size = 64, Examples/Sec = 6224.88, Accuracy = 0.59, Loss = 1.257
[2019-05-03 20:54] Train Step 419000/1000000, Batch Size = 64, Examples/Sec = 6224.30, Accuracy = 0.58, Loss = 1.299
[2019-05-03 20:54] Train Step 420000/1000000, Batch Size = 64, Examples/Sec = 6214.93, Accuracy = 0.58, Loss = 1.283
[2019-05-03 20:55] Train Step 421000/1000000, Batch Size = 64, Examples/Sec = 6222.57, Accuracy = 0.58, Loss = 1.242
[2019-05-03 20:55] Train Step 422000/1000000, Batch Size = 64, Examples/Sec = 6214.07, Accuracy = 0.59, Loss = 1.227
[2019-05-03 20:55] Train Step 423000/1000000, Batch Size = 64, Examples/Sec = 6203.01, Accuracy = 0.58, Loss = 1.285
[2019-05-03 20:55] Train Step 424000/1000000, Batch Size = 64, Examples/Sec = 6207.89, Accuracy = 0.57, Loss = 1.289
[2019-05-03 20:55] Train Step 425000/1000000, Batch Size = 64, Examples/Sec = 6214.93, Accuracy = 0.59, Loss = 1.238
[2019-05-03 20:56] Train Step 426000/1000000, Batch Size = 64, Examples/Sec = 6208.47, Accuracy = 0.57, Loss = 1.324
[2019-05-03 20:56] Train Step 427000/1000000, Batch Size = 64, Examples/Sec = 6212.20, Accuracy = 0.57, Loss = 1.306
[2019-05-03 20:56] Train Step 428000/1000000, Batch Size = 64, Examples/Sec = 6241.81, Accuracy = 0.58, Loss = 1.236
[2019-05-03 20:56] Train Step 429000/1000000, Batch Size = 64, Examples/Sec = 6211.63, Accuracy = 0.57, Loss = 1.293
[2019-05-03 20:56] Train Step 430000/1000000, Batch Size = 64, Examples/Sec = 6203.16, Accuracy = 0.58, Loss = 1.293
[2019-05-03 20:57] Train Step 431000/1000000, Batch Size = 64, Examples/Sec = 6206.60, Accuracy = 0.57, Loss = 1.274
[2019-05-03 20:57] Train Step 432000/1000000, Batch Size = 64, Examples/Sec = 6215.22, Accuracy = 0.57, Loss = 1.344
[2019-05-03 20:57] Train Step 433000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.58, Loss = 1.290
[2019-05-03 20:57] Train Step 434000/1000000, Batch Size = 64, Examples/Sec = 6237.61, Accuracy = 0.58, Loss = 1.298
[2019-05-03 20:57] Train Step 435000/1000000, Batch Size = 64, Examples/Sec = 6215.08, Accuracy = 0.57, Loss = 1.256
[2019-05-03 20:58] Train Step 436000/1000000, Batch Size = 64, Examples/Sec = 6175.90, Accuracy = 0.60, Loss = 1.227
[2019-05-03 20:58] Train Step 437000/1000000, Batch Size = 64, Examples/Sec = 6236.45, Accuracy = 0.57, Loss = 1.296
[2019-05-03 20:58] Train Step 438000/1000000, Batch Size = 64, Examples/Sec = 6217.24, Accuracy = 0.59, Loss = 1.268
[2019-05-03 20:58] Train Step 439000/1000000, Batch Size = 64, Examples/Sec = 6209.04, Accuracy = 0.57, Loss = 1.290
[2019-05-03 20:58] Train Step 440000/1000000, Batch Size = 64, Examples/Sec = 6210.76, Accuracy = 0.60, Loss = 1.272
[2019-05-03 20:59] Train Step 441000/1000000, Batch Size = 64, Examples/Sec = 6228.92, Accuracy = 0.60, Loss = 1.247
[2019-05-03 20:59] Train Step 442000/1000000, Batch Size = 64, Examples/Sec = 6208.32, Accuracy = 0.59, Loss = 1.269
[2019-05-03 20:59] Train Step 443000/1000000, Batch Size = 64, Examples/Sec = 6217.53, Accuracy = 0.57, Loss = 1.321
[2019-05-03 20:59] Train Step 444000/1000000, Batch Size = 64, Examples/Sec = 6256.22, Accuracy = 0.59, Loss = 1.239
[2019-05-03 20:59] Train Step 445000/1000000, Batch Size = 64, Examples/Sec = 6237.61, Accuracy = 0.59, Loss = 1.262
[2019-05-03 21:00] Train Step 446000/1000000, Batch Size = 64, Examples/Sec = 6230.95, Accuracy = 0.57, Loss = 1.342
[2019-05-03 21:00] Train Step 447000/1000000, Batch Size = 64, Examples/Sec = 6215.80, Accuracy = 0.59, Loss = 1.253
[2019-05-03 21:00] Train Step 448000/1000000, Batch Size = 64, Examples/Sec = 6204.45, Accuracy = 0.58, Loss = 1.252
[2019-05-03 21:00] Train Step 449000/1000000, Batch Size = 64, Examples/Sec = 6206.31, Accuracy = 0.58, Loss = 1.301
[2019-05-03 21:00] Train Step 450000/1000000, Batch Size = 64, Examples/Sec = 6228.20, Accuracy = 0.58, Loss = 1.274
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
, jota hän oli kuitenkin muuta
ja sen jälkeen kun hän oli kui
che oli tapana kaikki laittaa 
úsin kuin mitä mies oli kaikki
Gunilla oli tapana kaikki ne o

Generated 5 long samples (100 chars):
Zunilla oli tapana kaikki ne olivat kaikki ne saivat siitä että hän oli kuitenkin muuta kuin mitä hä
Öljä ja sen jälkeen kun hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli 
Quun sä tiedät. Niitä oli tapahtunut. \n Kun he olivat tulleet katsellessaan sen kaiken valokuvasta ja
3. \n No ei se oo sit tarkoituksen sisälle katseli kuinka hän oli kuitenkin muuta kuin mitä hän oli ku
8. \n Kun he olivat tulleet katsellessaan hänen kanssaan sen jälkeen kun hän oli kuitenkin muuta kuin 
-------------------------------------------
Temperature: 0.25
Generated 5:
7. \n Tunsin kuin olisi ollut ko
Gunilla oli tapana kaikki mies
Marja Leena oli kokenut häntä 
ís oli ollut halunnut siitä et
oli siitä kuin mitä oli tapaht

Generated 5 long samples (100 chars):
Matias saattoi tarkoitat takaisin Suomeen ja sitten hän oli tullut toisen takana oli kaikki ne oliva
Claudian ja koko ajan. Sitten hän oli vain vain katsonut koko ajan kuin kun hän oli kuitenkin maksan
gerta oli paljon vaikeata kuin mitä hän oli jo toisen miehen kanssa. \n Kalle oli jo paljon muuttanut 
Flemmingsbergissä oli sanonut sitä että se oli tapahtunut. \n Kun hän oli tullut koko asiasta vain hal
5. \n Tässä sanoi ja painoi kuinka hän oli tullut hänen kanssaan paljon muutaman vuoden jälkeen, kun h
-------------------------------------------
Temperature: 0.5
Generated 5:
7. \n En mä tiedä mitään muuta k
. \n Ari ei ollut koskaan sitä a
1994 1764. Seuralla tulla vain
\n Sitten hän oli ollut lainkaan
ís oli täysin voimallisia kork

Generated 5 long samples (100 chars):
gertaan joitakin pariselmilleen, vaikka kun oli tapana kyllä halusta ennen kuin me kaikki oli saman 
Oli puhuvansa riistäisi vain venäläisen langennut asiasta surullisia vanhan ikkunan parikymmentä vaa
gi oli sanonut epäilystäväänsä. \n Tule kertoi että oli ollut parhaalla metsästä ja yksi vain puhui mi
. \n Kun he olivat puhua toisen tai anteeksi, että kaksi kirjastossa ja sitten hän sai pappilassa kuin
xin leijon kuin mitä minä ja sitä oli aina kuitenkin maksanut samanlaisen joulua. \n He olivat vieläki
-------------------------------------------
Temperature: 1.0
Generated 5:
2. Meidän olisi maksanut Julle
è viisikymmenverhoillani. \n Tie
ella teologisasta. Kun rakennu
å, ja Lluís sai turvalleen ja 
öön tuolle kauan.\n Kun sä tarko

Generated 5 long samples (100 chars):
a edes yrittänyt haaskata nuoren ihmisen, mutta aina että kaikki he olivat siihen huonompaansa - its
-oi.\n Palahta näyttää elämänkymmentenhamiaisensa. Ari huomasi edes voima. Noita Ullan myöstäni minua 
Quutob, Kadleliksensä olemasti, milloin hän yksinkertaisesti Ninni, mutta sinä olet tapana kuusissaa
Östutkahdua esimansa nenät huonekalujen lapsuudesta. Heillä on tuntenut. Tuo osuus voi pitäneet tämä
Qujahta, vaikka hän oli täysin perin perään, periaatteesta ja näki juoda yli taholta, jottei isä oli
-------------------------------------------
Temperature: 2.0
Generated 5:
Äkgin ret osoitetti oli tyrtty
Vaalylla isooi olla, Kantra. s
npä?\n Kampamansa?\n Samoiltetyläs
åt! vanho mökasi Katartioiim..
Passuja ovikenguistaopustyessa

Generated 5 long samples (100 chars):
Ze voitelisimmornimen säälyn rätistä.\n Lluís ei hytkä kumansa eikä ommy, oot piotonvir tervoivoivat K
Joukot lintoippi on vinkihuvilian.\n Viidestenä.\n Mutta kukaan me sodeudukstoisellitelei! Kuideaan saam
pö tunssisiä muilistusahjuu aukeo, Jarmon uimta. Hän eneksi hänetkiel. Nyt hykkitysys paikassa, Kat 
Toivo. Sen isäne odottinyt lopulliin alaretpra fco hisoen, telkamuästöä ilme yksikaudet, uinponegret
Ei. Lön! näu et pptopes, nopelmiinpihtajan Mat! Täy, vasnavallakelpoin ei ollut jäänytopfipeasta. Us
-------------------------------------------
[2019-05-03 21:01] Train Step 451000/1000000, Batch Size = 64, Examples/Sec = 6217.09, Accuracy = 0.57, Loss = 1.292
[2019-05-03 21:01] Train Step 452000/1000000, Batch Size = 64, Examples/Sec = 6247.92, Accuracy = 0.58, Loss = 1.278
[2019-05-03 21:01] Train Step 453000/1000000, Batch Size = 64, Examples/Sec = 6228.35, Accuracy = 0.56, Loss = 1.314
[2019-05-03 21:01] Train Step 454000/1000000, Batch Size = 64, Examples/Sec = 6222.71, Accuracy = 0.58, Loss = 1.270
[2019-05-03 21:01] Train Step 455000/1000000, Batch Size = 64, Examples/Sec = 6216.23, Accuracy = 0.58, Loss = 1.286
[2019-05-03 21:02] Train Step 456000/1000000, Batch Size = 64, Examples/Sec = 6234.13, Accuracy = 0.58, Loss = 1.261
[2019-05-03 21:02] Train Step 457000/1000000, Batch Size = 64, Examples/Sec = 6256.07, Accuracy = 0.59, Loss = 1.263
[2019-05-03 21:02] Train Step 458000/1000000, Batch Size = 64, Examples/Sec = 6242.39, Accuracy = 0.59, Loss = 1.244
[2019-05-03 21:02] Train Step 459000/1000000, Batch Size = 64, Examples/Sec = 6185.29, Accuracy = 0.58, Loss = 1.294
[2019-05-03 21:02] Train Step 460000/1000000, Batch Size = 64, Examples/Sec = 6221.85, Accuracy = 0.59, Loss = 1.278
[2019-05-03 21:03] Train Step 461000/1000000, Batch Size = 64, Examples/Sec = 6244.57, Accuracy = 0.58, Loss = 1.259
[2019-05-03 21:03] Train Step 462000/1000000, Batch Size = 64, Examples/Sec = 6250.10, Accuracy = 0.56, Loss = 1.308
[2019-05-03 21:03] Train Step 463000/1000000, Batch Size = 64, Examples/Sec = 6212.49, Accuracy = 0.59, Loss = 1.241
[2019-05-03 21:03] Train Step 464000/1000000, Batch Size = 64, Examples/Sec = 6247.48, Accuracy = 0.57, Loss = 1.280
[2019-05-03 21:03] Train Step 465000/1000000, Batch Size = 64, Examples/Sec = 6221.27, Accuracy = 0.59, Loss = 1.244
[2019-05-03 21:04] Train Step 466000/1000000, Batch Size = 64, Examples/Sec = 6210.33, Accuracy = 0.58, Loss = 1.251
[2019-05-03 21:04] Train Step 467000/1000000, Batch Size = 64, Examples/Sec = 6207.89, Accuracy = 0.58, Loss = 1.285
[2019-05-03 21:04] Train Step 468000/1000000, Batch Size = 64, Examples/Sec = 6220.98, Accuracy = 0.60, Loss = 1.243
[2019-05-03 21:04] Train Step 469000/1000000, Batch Size = 64, Examples/Sec = 6229.94, Accuracy = 0.59, Loss = 1.252
[2019-05-03 21:04] Train Step 470000/1000000, Batch Size = 64, Examples/Sec = 6220.12, Accuracy = 0.57, Loss = 1.310
[2019-05-03 21:05] Train Step 471000/1000000, Batch Size = 64, Examples/Sec = 6220.26, Accuracy = 0.58, Loss = 1.241
[2019-05-03 21:05] Train Step 472000/1000000, Batch Size = 64, Examples/Sec = 6226.76, Accuracy = 0.62, Loss = 1.197
[2019-05-03 21:05] Train Step 473000/1000000, Batch Size = 64, Examples/Sec = 6237.32, Accuracy = 0.59, Loss = 1.249
[2019-05-03 21:05] Train Step 474000/1000000, Batch Size = 64, Examples/Sec = 6224.59, Accuracy = 0.58, Loss = 1.252
[2019-05-03 21:05] Train Step 475000/1000000, Batch Size = 64, Examples/Sec = 6220.26, Accuracy = 0.58, Loss = 1.262
[2019-05-03 21:06] Train Step 476000/1000000, Batch Size = 64, Examples/Sec = 6220.70, Accuracy = 0.57, Loss = 1.294
[2019-05-03 21:06] Train Step 477000/1000000, Batch Size = 64, Examples/Sec = 6244.86, Accuracy = 0.58, Loss = 1.274
[2019-05-03 21:06] Train Step 478000/1000000, Batch Size = 64, Examples/Sec = 6232.39, Accuracy = 0.58, Loss = 1.299
[2019-05-03 21:06] Train Step 479000/1000000, Batch Size = 64, Examples/Sec = 6242.83, Accuracy = 0.58, Loss = 1.285
[2019-05-03 21:06] Train Step 480000/1000000, Batch Size = 64, Examples/Sec = 6248.93, Accuracy = 0.57, Loss = 1.318
[2019-05-03 21:07] Train Step 481000/1000000, Batch Size = 64, Examples/Sec = 6249.22, Accuracy = 0.58, Loss = 1.286
[2019-05-03 21:07] Train Step 482000/1000000, Batch Size = 64, Examples/Sec = 6195.86, Accuracy = 0.56, Loss = 1.361
[2019-05-03 21:07] Train Step 483000/1000000, Batch Size = 64, Examples/Sec = 6200.58, Accuracy = 0.57, Loss = 1.293
[2019-05-03 21:07] Train Step 484000/1000000, Batch Size = 64, Examples/Sec = 6219.40, Accuracy = 0.58, Loss = 1.303
[2019-05-03 21:08] Train Step 485000/1000000, Batch Size = 64, Examples/Sec = 6223.15, Accuracy = 0.58, Loss = 1.276
[2019-05-03 21:08] Train Step 486000/1000000, Batch Size = 64, Examples/Sec = 6240.80, Accuracy = 0.56, Loss = 1.310
[2019-05-03 21:08] Train Step 487000/1000000, Batch Size = 64, Examples/Sec = 6250.83, Accuracy = 0.57, Loss = 1.261
[2019-05-03 21:08] Train Step 488000/1000000, Batch Size = 64, Examples/Sec = 6221.27, Accuracy = 0.60, Loss = 1.235
[2019-05-03 21:08] Train Step 489000/1000000, Batch Size = 64, Examples/Sec = 6242.25, Accuracy = 0.59, Loss = 1.266
[2019-05-03 21:09] Train Step 490000/1000000, Batch Size = 64, Examples/Sec = 6209.33, Accuracy = 0.58, Loss = 1.287
[2019-05-03 21:09] Train Step 491000/1000000, Batch Size = 64, Examples/Sec = 6238.33, Accuracy = 0.57, Loss = 1.325
[2019-05-03 21:09] Train Step 492000/1000000, Batch Size = 64, Examples/Sec = 6232.39, Accuracy = 0.59, Loss = 1.239
[2019-05-03 21:09] Train Step 493000/1000000, Batch Size = 64, Examples/Sec = 6253.16, Accuracy = 0.60, Loss = 1.252
[2019-05-03 21:09] Train Step 494000/1000000, Batch Size = 64, Examples/Sec = 6237.46, Accuracy = 0.60, Loss = 1.251
[2019-05-03 21:10] Train Step 495000/1000000, Batch Size = 64, Examples/Sec = 6218.39, Accuracy = 0.57, Loss = 1.335
[2019-05-03 21:10] Train Step 496000/1000000, Batch Size = 64, Examples/Sec = 6242.25, Accuracy = 0.58, Loss = 1.258
[2019-05-03 21:10] Train Step 497000/1000000, Batch Size = 64, Examples/Sec = 6229.36, Accuracy = 0.57, Loss = 1.299
[2019-05-03 21:10] Train Step 498000/1000000, Batch Size = 64, Examples/Sec = 6244.72, Accuracy = 0.59, Loss = 1.262
[2019-05-03 21:10] Train Step 499000/1000000, Batch Size = 64, Examples/Sec = 6235.58, Accuracy = 0.56, Loss = 1.289
[2019-05-03 21:11] Train Step 500000/1000000, Batch Size = 64, Examples/Sec = 6227.05, Accuracy = 0.59, Loss = 1.274
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Gunilla oli tapana kaikki nämä
Ari oli kuitenkin muuta kuin m
quettaa sitä mitä mies oli se 
5. \n Tässä sitten hän oli tullu
Quun sä tiedät. Niitä oli tapa

Generated 5 long samples (100 chars):
a kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin mu
3. \n No ei sinun pitäisi tulla tulla tulleensa takaisin kotiin. \n Mitä sä tiedät että hän oli kuitenki
Oli mieleen hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin mu
ís oli tullut mitään selvittämään mielessään tuli siitä kuin mitä mies oli se kuin se olisi tullut m
1 Marja Leena oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muut
-------------------------------------------
Temperature: 0.25
Generated 5:
filmistä. \n Kun he olivat tulle
che oli tapana keskustelun ja 
bileistä. \n En tiedä mitä nämä 
Ölve ajatteli.\n Ei siis mennyt 
Ninni oli tullut koko ajan. \n M

Generated 5 long samples (100 chars):
ista oli jo kauan kuin mitä mies oli saanut kaikki muistikuva oli tullut koko ajan kuin mitä mies ol
? Tämä on tapahtunut. \n Kalle oli aina ollut sitä mitä mieltä kun hän oli kovin hyvin paljon myöhemmi
van sitä että kun hän oli tuonut muutaman meren perheessä saattoi kuitenkin mielessään sen verran pa
3. \n No ei sinun oli aina ollut hänen kanssaan mitä hän oli kertonut mitään selvittämään mitä tämä ol
gassa ja sitten hän oli täysin tuntenut kaikkialla parissa ja katseli siihen kanssaan. \n Kun he oliva
-------------------------------------------
Temperature: 0.5
Generated 5:
7 kato oli tullut paljon parem
wanille oman niin kuin hän ei 
li sieltä kallion takapuolesta
keen ja kirjastossa alastomist
an, niin sitä ei kaiken sitä k

Generated 5 long samples (100 chars):
Quis mitään ja minun pitäisi tulla muuttanut siitä että hän huusi ja lähetti saada keskenään ja häne
'. Hän oli vaikeata että hän oli tehnyt hänet sisälle käytöstä puristi häntä nuorta ja aiemmin kuin 
. \n Kalle oli niin tuntisi koko itseään viattoman päätellen muistillaan ja mahdollisimman paljon muut
utta tuntui kaikkiaan katsomaan paikkaan siitä, että näistä kuin mitä olisi voinut olla tavalla ja p
Flempassa, kun hän tunsi olla sinun kanssa hän oli jotakuta kuin jotakin, ja hän oli varmaan pitänyt
-------------------------------------------
Temperature: 1.0
Generated 5:
Yön kuollu jossain mitä tapaht
nafrikkapullo. Hän kytys. Hän 
\n Ja hampasikse ja minulle teki
Jos ensimmäiseksi hän alastanu
3kosensa.\n Tarkeisin yhä useamp

Generated 5 long samples (100 chars):
raat. Mä voin nähdä, että Kuuvalo oli loistamaan Ninnin nousi Taiwanin fitGa, Että se oli rikastunut
Ymmärsin että hän sanoi ja odotti. \n Kun Lluís sanoi Parakelle ihmisilleen ja tulevimme sitä seks pik
ís sanoi, että parkkipaikallisen nähden kun isä ja Mary Annin. Mitä niilitä sveitsi minun mieli tai 
3rian verran opiskelija-mieltä moitteetonja pienemmän naisia. Niinsä selitti molemman käsikoperan. S
ä lähettävä Mara Jo oli saanut asuneet palanut kuvitella, olet tuoppaa kuvitellakaan.\n Dereee!\n Ei Kru
-------------------------------------------
Temperature: 2.0
Generated 5:
asunsoa uudelleenumlikaahman t
\n Luise, ä hukulla...pinen - nä
5t.\n   vuoteen juustoja jalkojä
stö yypuukpunoi rivasia? Näyn.
hoistaa, Ulla, liedisti Stotan

Generated 5 long samples (100 chars):
Lpytomavegeen totuä lejup silaineaisena ajuintaja:karrotpi, Messiinhetki, jaapuki, Paraguu, GhlihTee
åhkrojioon siltä kolaisenkaomminhetta. Ja tyisokos, häntä Ninniä asioiden posketonan ulko-vodtakenut
8, tiekamina saapurgnsskoeessoihen, väuleet veni Arttir olisimmasta? Papsestihtien hykkäs, tlisi höl
. Vakaita, Llar Espoijuppekeinta Mare mönkyrin Ryöspynyt, taktoa. Kirkon ullinomotii, mitä ähneööi?\n 
Itse Ninniä oluslahkuirlini? U Bor.\n Pertke sicketit meneten. Juna -Ptytön vaivattanut, vojeukeille S
-------------------------------------------
[2019-05-03 21:11] Train Step 501000/1000000, Batch Size = 64, Examples/Sec = 6227.91, Accuracy = 0.59, Loss = 1.269
[2019-05-03 21:11] Train Step 502000/1000000, Batch Size = 64, Examples/Sec = 6244.43, Accuracy = 0.56, Loss = 1.330
[2019-05-03 21:11] Train Step 503000/1000000, Batch Size = 64, Examples/Sec = 6234.86, Accuracy = 0.60, Loss = 1.232
[2019-05-03 21:11] Train Step 504000/1000000, Batch Size = 64, Examples/Sec = 6220.70, Accuracy = 0.59, Loss = 1.247
[2019-05-03 21:12] Train Step 505000/1000000, Batch Size = 64, Examples/Sec = 6249.66, Accuracy = 0.60, Loss = 1.265
[2019-05-03 21:12] Train Step 506000/1000000, Batch Size = 64, Examples/Sec = 6224.73, Accuracy = 0.58, Loss = 1.259
[2019-05-03 21:12] Train Step 507000/1000000, Batch Size = 64, Examples/Sec = 6240.07, Accuracy = 0.58, Loss = 1.263
[2019-05-03 21:12] Train Step 508000/1000000, Batch Size = 64, Examples/Sec = 6213.35, Accuracy = 0.58, Loss = 1.299
[2019-05-03 21:12] Train Step 509000/1000000, Batch Size = 64, Examples/Sec = 6229.79, Accuracy = 0.61, Loss = 1.231
[2019-05-03 21:13] Train Step 510000/1000000, Batch Size = 64, Examples/Sec = 6230.37, Accuracy = 0.58, Loss = 1.260
[2019-05-03 21:13] Train Step 511000/1000000, Batch Size = 64, Examples/Sec = 6227.05, Accuracy = 0.57, Loss = 1.321
[2019-05-03 21:13] Train Step 512000/1000000, Batch Size = 64, Examples/Sec = 6230.51, Accuracy = 0.62, Loss = 1.228
[2019-05-03 21:13] Train Step 513000/1000000, Batch Size = 64, Examples/Sec = 6223.72, Accuracy = 0.58, Loss = 1.314
[2019-05-03 21:13] Train Step 514000/1000000, Batch Size = 64, Examples/Sec = 6236.88, Accuracy = 0.58, Loss = 1.235
[2019-05-03 21:14] Train Step 515000/1000000, Batch Size = 64, Examples/Sec = 6242.69, Accuracy = 0.58, Loss = 1.230
[2019-05-03 21:14] Train Step 516000/1000000, Batch Size = 64, Examples/Sec = 6222.57, Accuracy = 0.59, Loss = 1.253
[2019-05-03 21:14] Train Step 517000/1000000, Batch Size = 64, Examples/Sec = 6241.96, Accuracy = 0.61, Loss = 1.233
[2019-05-03 21:14] Train Step 518000/1000000, Batch Size = 64, Examples/Sec = 6220.26, Accuracy = 0.58, Loss = 1.264
[2019-05-03 21:14] Train Step 519000/1000000, Batch Size = 64, Examples/Sec = 6235.29, Accuracy = 0.56, Loss = 1.323
[2019-05-03 21:15] Train Step 520000/1000000, Batch Size = 64, Examples/Sec = 6232.83, Accuracy = 0.58, Loss = 1.242
[2019-05-03 21:15] Train Step 521000/1000000, Batch Size = 64, Examples/Sec = 6239.93, Accuracy = 0.57, Loss = 1.297
[2019-05-03 21:15] Train Step 522000/1000000, Batch Size = 64, Examples/Sec = 6233.99, Accuracy = 0.58, Loss = 1.268
[2019-05-03 21:15] Train Step 523000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.58, Loss = 1.266
[2019-05-03 21:15] Train Step 524000/1000000, Batch Size = 64, Examples/Sec = 6219.83, Accuracy = 0.59, Loss = 1.288
[2019-05-03 21:16] Train Step 525000/1000000, Batch Size = 64, Examples/Sec = 6226.76, Accuracy = 0.59, Loss = 1.219
[2019-05-03 21:16] Train Step 526000/1000000, Batch Size = 64, Examples/Sec = 6234.42, Accuracy = 0.57, Loss = 1.284
[2019-05-03 21:16] Train Step 527000/1000000, Batch Size = 64, Examples/Sec = 6237.61, Accuracy = 0.58, Loss = 1.287
[2019-05-03 21:16] Train Step 528000/1000000, Batch Size = 64, Examples/Sec = 6248.50, Accuracy = 0.57, Loss = 1.275
[2019-05-03 21:16] Train Step 529000/1000000, Batch Size = 64, Examples/Sec = 6243.85, Accuracy = 0.56, Loss = 1.315
[2019-05-03 21:17] Train Step 530000/1000000, Batch Size = 64, Examples/Sec = 6246.32, Accuracy = 0.58, Loss = 1.282
[2019-05-03 21:17] Train Step 531000/1000000, Batch Size = 64, Examples/Sec = 6242.69, Accuracy = 0.58, Loss = 1.264
[2019-05-03 21:17] Train Step 532000/1000000, Batch Size = 64, Examples/Sec = 6210.19, Accuracy = 0.57, Loss = 1.309
[2019-05-03 21:17] Train Step 533000/1000000, Batch Size = 64, Examples/Sec = 6242.69, Accuracy = 0.59, Loss = 1.292
[2019-05-03 21:17] Train Step 534000/1000000, Batch Size = 64, Examples/Sec = 6212.63, Accuracy = 0.59, Loss = 1.284
[2019-05-03 21:18] Train Step 535000/1000000, Batch Size = 64, Examples/Sec = 6230.37, Accuracy = 0.59, Loss = 1.231
[2019-05-03 21:18] Train Step 536000/1000000, Batch Size = 64, Examples/Sec = 6257.97, Accuracy = 0.60, Loss = 1.238
[2019-05-03 21:18] Train Step 537000/1000000, Batch Size = 64, Examples/Sec = 6223.87, Accuracy = 0.57, Loss = 1.273
[2019-05-03 21:18] Train Step 538000/1000000, Batch Size = 64, Examples/Sec = 6226.61, Accuracy = 0.57, Loss = 1.298
[2019-05-03 21:18] Train Step 539000/1000000, Batch Size = 64, Examples/Sec = 6247.19, Accuracy = 0.57, Loss = 1.302
[2019-05-03 21:19] Train Step 540000/1000000, Batch Size = 64, Examples/Sec = 6248.06, Accuracy = 0.58, Loss = 1.301
[2019-05-03 21:19] Train Step 541000/1000000, Batch Size = 64, Examples/Sec = 6229.79, Accuracy = 0.56, Loss = 1.341
[2019-05-03 21:19] Train Step 542000/1000000, Batch Size = 64, Examples/Sec = 6240.94, Accuracy = 0.58, Loss = 1.283
[2019-05-03 21:19] Train Step 543000/1000000, Batch Size = 64, Examples/Sec = 6180.88, Accuracy = 0.58, Loss = 1.277
[2019-05-03 21:19] Train Step 544000/1000000, Batch Size = 64, Examples/Sec = 6126.29, Accuracy = 0.59, Loss = 1.260
[2019-05-03 21:20] Train Step 545000/1000000, Batch Size = 64, Examples/Sec = 6231.38, Accuracy = 0.55, Loss = 1.354
[2019-05-03 21:20] Train Step 546000/1000000, Batch Size = 64, Examples/Sec = 6248.06, Accuracy = 0.59, Loss = 1.239
[2019-05-03 21:20] Train Step 547000/1000000, Batch Size = 64, Examples/Sec = 6243.27, Accuracy = 0.58, Loss = 1.282
[2019-05-03 21:20] Train Step 548000/1000000, Batch Size = 64, Examples/Sec = 6208.47, Accuracy = 0.59, Loss = 1.251
[2019-05-03 21:20] Train Step 549000/1000000, Batch Size = 64, Examples/Sec = 6190.57, Accuracy = 0.58, Loss = 1.323
[2019-05-03 21:21] Train Step 550000/1000000, Batch Size = 64, Examples/Sec = 6225.31, Accuracy = 0.59, Loss = 1.281
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
- ja sai hänet kanssaan ja kat
) ja hänen kanssaan tuntematto
Ari oli kuitenkin muuta kuin m
Paljon tavaraa ja kaikki oli k
. \n Kun he olivat tulleet katse

Generated 5 long samples (100 chars):
Wow, joku oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta ku
Se oli tapahtunut. Hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuite
Ari oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mit
Derek oli tapana kaikki nämä vielä sanoin ja saattoi tuntea tämän kanssa. \n Mitä sä tiedät että hän o
Öljä ja sen jälkeen kun hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli 
-------------------------------------------
Temperature: 0.25
Generated 5:
úsin kuin se oli hänen parhaat
Ninni oli katsonut hänen kanss
Oli mieleen kuin se oli tapaht
Äiti oli parasta tapahtumista 
hän oli tullut koko iltapäivän

Generated 5 long samples (100 chars):
Claudian laukulla oli kaikkiaan täysin muuttanut tarkoituksenaan. \n Hän oli tullut paljon kaiken. \n Ku
Radmilo oli varmaan tullut mitä se oli tapahtunut. Hän oli kuitenkin muuta kuin mitä hän oli kuitenk
9. \n He olivat sen sijaan kun hän oli kuitenkin ollut hänen kanssaan tai myöhemmin kuin hän oli kuite
quettaa sitä samanlainen kuin mitä hän oli vain hyvä yliopiston tytön piti siitä kuin mitä tämä oli 
?\n Ei sitä tunne ollut mitään tuon kanssa. \n En mä tiedä mitään sellaista kuin se oli tapahtunut. Ja t
-------------------------------------------
Temperature: 0.5
Generated 5:
. Ei kai sitä ollutkaan mitään
6. \n Muut jo valmis ja minulle 
-ikäisin auton hirviömäinen ku
oli nähnyt niin paljon muutama
Lluís katsoi tarvetta hieman p

Generated 5 long samples (100 chars):
-alun valkoiselle sisälle selvää kolmannen kuin suihkuhuoneessa, oli ollut hänen mielestään sanoa.\n S
! Kalle oli vain halunnut koko asiaa, se sanoi ja katseli liikkumatta täysin pitkään aikaa hänet ja 
, mutta Ninni tiesi viikonloppuisin, mutta ehkä kuin mitä hänen sanottiinsa pitkän kanssaan juuri me
Wow, joku oli vain päästä ja kertoi takaisin miehen kuukauden vuokran saattoi nähdä vain muutaman ai
5.\n Mitä sit tällä tällaista tuli hänen kanssaan kuin mitä me tiesivät takaisin Suomeen. Se oli etupä
-------------------------------------------
Temperature: 1.0
Generated 5:
t ishoittivat Marja Leenan kok
ppilan suostuessaan sinne laps
ksi krausalta kuin Bobin ja Eb
yydään. Koko ylläte, joissa to
htisannattoman vain muutama ja

Generated 5 long samples (100 chars):
! Mäkilän pahoillaisista aikavasti, hän sanoi, että se oli kynnästyä, ja siitä että aluksi rauhiskuh
Guannan!\n Koska Ari tunnisti minulle, että oli siitä muutamia haju lämmitysneet, mutta tänne Täsellää
forumakeskelimähdestä korvalla.\n Veden ja Siimeksen arvostunut kauempana.\n Kallessa, sitä on kauan. \n K
zilla ja pehmensä pistohuoneessa, Igor huusi. Vain pikku Heidi katsoi juurakua.\n Espanjaa kulkinaukku
dyt ja löysytti olevan ollut venellä pöytään. \n Tämä oli kolousiaaliset oli pakkaminen valkoisimmin s
-------------------------------------------
Temperature: 2.0
Generated 5:
6lte. Its-nuoteetsans: Vätä.\n P
weet ei yksinkirrottahin, taka
6gettää vastapäässyt: Ole:  lä
qugbglrd-oput Madderigissa äMv
2ellä. Monet n nimuloi? Inte t

Generated 5 long samples (100 chars):
6ttonaan btoapullyhiet, eikä Rluudunassa Monammin \n Illitursseinät ja lajanottava Asda lakan -elullis
;0pä ruumis kohkuamuytty,, Sr!! kotaan, synn? Nyr?\n Ee,epurestaan.\n Aimoperrht,r,,pa tavallahan lähen 
Iniovä he?i.'Et coa!. \n Michulkuholmia odotetin. Eu kyn mitä?\n Siks:in, etuovin herhkästys tuttu nrait
wt Karominensanomminen? Vai juovuta astion Molleimon ja alkoivata. Vai -.\n Marja joujuisemassa pyhlii
detunmaattumansa, linaroidenkasiskukset Llut, lukoin, varpuusat pannos lämminviloats perilafn, Cirac
-------------------------------------------
[2019-05-03 21:21] Train Step 551000/1000000, Batch Size = 64, Examples/Sec = 6249.08, Accuracy = 0.58, Loss = 1.230
[2019-05-03 21:21] Train Step 552000/1000000, Batch Size = 64, Examples/Sec = 6220.55, Accuracy = 0.59, Loss = 1.244
[2019-05-03 21:21] Train Step 553000/1000000, Batch Size = 64, Examples/Sec = 6234.86, Accuracy = 0.60, Loss = 1.249
[2019-05-03 21:21] Train Step 554000/1000000, Batch Size = 64, Examples/Sec = 6197.29, Accuracy = 0.58, Loss = 1.296
[2019-05-03 21:22] Train Step 555000/1000000, Batch Size = 64, Examples/Sec = 6209.76, Accuracy = 0.56, Loss = 1.301
[2019-05-03 21:22] Train Step 556000/1000000, Batch Size = 64, Examples/Sec = 6225.75, Accuracy = 0.58, Loss = 1.235
[2019-05-03 21:22] Train Step 557000/1000000, Batch Size = 64, Examples/Sec = 6234.71, Accuracy = 0.58, Loss = 1.268
[2019-05-03 21:22] Train Step 558000/1000000, Batch Size = 64, Examples/Sec = 6264.25, Accuracy = 0.58, Loss = 1.281
[2019-05-03 21:22] Train Step 559000/1000000, Batch Size = 64, Examples/Sec = 6228.49, Accuracy = 0.58, Loss = 1.309
[2019-05-03 21:23] Train Step 560000/1000000, Batch Size = 64, Examples/Sec = 6220.70, Accuracy = 0.59, Loss = 1.240
[2019-05-03 21:23] Train Step 561000/1000000, Batch Size = 64, Examples/Sec = 6227.62, Accuracy = 0.59, Loss = 1.246
[2019-05-03 21:23] Train Step 562000/1000000, Batch Size = 64, Examples/Sec = 6230.80, Accuracy = 0.57, Loss = 1.289
[2019-05-03 21:23] Train Step 563000/1000000, Batch Size = 64, Examples/Sec = 6220.41, Accuracy = 0.58, Loss = 1.296
[2019-05-03 21:24] Train Step 564000/1000000, Batch Size = 64, Examples/Sec = 6228.78, Accuracy = 0.56, Loss = 1.303
[2019-05-03 21:24] Train Step 565000/1000000, Batch Size = 64, Examples/Sec = 6238.19, Accuracy = 0.55, Loss = 1.354
[2019-05-03 21:24] Train Step 566000/1000000, Batch Size = 64, Examples/Sec = 6219.69, Accuracy = 0.58, Loss = 1.279
[2019-05-03 21:24] Train Step 567000/1000000, Batch Size = 64, Examples/Sec = 6209.04, Accuracy = 0.59, Loss = 1.244
[2019-05-03 21:24] Train Step 568000/1000000, Batch Size = 64, Examples/Sec = 6238.19, Accuracy = 0.58, Loss = 1.285
[2019-05-03 21:25] Train Step 569000/1000000, Batch Size = 64, Examples/Sec = 6221.70, Accuracy = 0.58, Loss = 1.266
[2019-05-03 21:25] Train Step 570000/1000000, Batch Size = 64, Examples/Sec = 6232.54, Accuracy = 0.57, Loss = 1.321
[2019-05-03 21:25] Train Step 571000/1000000, Batch Size = 64, Examples/Sec = 6232.54, Accuracy = 0.58, Loss = 1.288
[2019-05-03 21:25] Train Step 572000/1000000, Batch Size = 64, Examples/Sec = 6202.30, Accuracy = 0.59, Loss = 1.240
[2019-05-03 21:25] Train Step 573000/1000000, Batch Size = 64, Examples/Sec = 6245.30, Accuracy = 0.58, Loss = 1.288
[2019-05-03 21:26] Train Step 574000/1000000, Batch Size = 64, Examples/Sec = 6221.85, Accuracy = 0.60, Loss = 1.237
[2019-05-03 21:26] Train Step 575000/1000000, Batch Size = 64, Examples/Sec = 6218.68, Accuracy = 0.58, Loss = 1.291
[2019-05-03 21:26] Train Step 576000/1000000, Batch Size = 64, Examples/Sec = 6237.75, Accuracy = 0.59, Loss = 1.236
[2019-05-03 21:26] Train Step 577000/1000000, Batch Size = 64, Examples/Sec = 6240.07, Accuracy = 0.56, Loss = 1.289
[2019-05-03 21:26] Train Step 578000/1000000, Batch Size = 64, Examples/Sec = 6202.15, Accuracy = 0.59, Loss = 1.243
[2019-05-03 21:27] Train Step 579000/1000000, Batch Size = 64, Examples/Sec = 6225.75, Accuracy = 0.55, Loss = 1.325
[2019-05-03 21:27] Train Step 580000/1000000, Batch Size = 64, Examples/Sec = 6223.29, Accuracy = 0.59, Loss = 1.238
[2019-05-03 21:27] Train Step 581000/1000000, Batch Size = 64, Examples/Sec = 6228.06, Accuracy = 0.59, Loss = 1.240
[2019-05-03 21:27] Train Step 582000/1000000, Batch Size = 64, Examples/Sec = 6219.54, Accuracy = 0.58, Loss = 1.295
[2019-05-03 21:27] Train Step 583000/1000000, Batch Size = 64, Examples/Sec = 6201.72, Accuracy = 0.60, Loss = 1.217
[2019-05-03 21:28] Train Step 584000/1000000, Batch Size = 64, Examples/Sec = 6195.57, Accuracy = 0.59, Loss = 1.276
[2019-05-03 21:28] Train Step 585000/1000000, Batch Size = 64, Examples/Sec = 6233.12, Accuracy = 0.59, Loss = 1.271
[2019-05-03 21:28] Train Step 586000/1000000, Batch Size = 64, Examples/Sec = 6229.94, Accuracy = 0.59, Loss = 1.238
[2019-05-03 21:28] Train Step 587000/1000000, Batch Size = 64, Examples/Sec = 6244.72, Accuracy = 0.58, Loss = 1.276
[2019-05-03 21:28] Train Step 588000/1000000, Batch Size = 64, Examples/Sec = 6256.51, Accuracy = 0.60, Loss = 1.220
[2019-05-03 21:29] Train Step 589000/1000000, Batch Size = 64, Examples/Sec = 6232.54, Accuracy = 0.58, Loss = 1.264
[2019-05-03 21:29] Train Step 590000/1000000, Batch Size = 64, Examples/Sec = 6238.77, Accuracy = 0.57, Loss = 1.323
[2019-05-03 21:29] Train Step 591000/1000000, Batch Size = 64, Examples/Sec = 6067.43, Accuracy = 0.58, Loss = 1.277
[2019-05-03 21:29] Train Step 592000/1000000, Batch Size = 64, Examples/Sec = 6193.14, Accuracy = 0.58, Loss = 1.308
[2019-05-03 21:29] Train Step 593000/1000000, Batch Size = 64, Examples/Sec = 6242.83, Accuracy = 0.58, Loss = 1.286
[2019-05-03 21:30] Train Step 594000/1000000, Batch Size = 64, Examples/Sec = 6218.25, Accuracy = 0.58, Loss = 1.272
[2019-05-03 21:30] Train Step 595000/1000000, Batch Size = 64, Examples/Sec = 6222.71, Accuracy = 0.60, Loss = 1.283
[2019-05-03 21:30] Train Step 596000/1000000, Batch Size = 64, Examples/Sec = 6228.63, Accuracy = 0.56, Loss = 1.307
[2019-05-03 21:30] Train Step 597000/1000000, Batch Size = 64, Examples/Sec = 6239.93, Accuracy = 0.58, Loss = 1.281
[2019-05-03 21:30] Train Step 598000/1000000, Batch Size = 64, Examples/Sec = 6232.97, Accuracy = 0.58, Loss = 1.251
[2019-05-03 21:31] Train Step 599000/1000000, Batch Size = 64, Examples/Sec = 6242.25, Accuracy = 0.59, Loss = 1.278
[2019-05-03 21:31] Train Step 600000/1000000, Batch Size = 64, Examples/Sec = 6222.28, Accuracy = 0.58, Loss = 1.256
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Usein sen sijaan että hän oli 
 kuin mitä mies oli se kuin se
! \n Hän oli tullut mitään selvi
8. \n Kun he olivat tulleet kats
si hänen kanssaan sen kaiken m

Generated 5 long samples (100 chars):
è sitä saattoi olla tavalla ja katseli kuinka hän oli tullut mitään selvittämään mielessään tapahtun
Ari oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mit
Claudian ja katseli kuinka hän oli tullut mitään selvittämään mielessään tapahtunut. Hän oli kuitenk
Bruno oli tullut mitään selvittämään mielessään tapahtunut. Hän oli kuitenkin muuta kuin mitä hän ol
lle kaikki oli kaikkiaan kuin mitä mies oli se kuin se olisi tullut mitään tuon kanssa. \n Kun he oliv
-------------------------------------------
Temperature: 0.25
Generated 5:
Ari oli aivan toisen päivän va
å, joka oli tapana katsomaan k
Usein se oli tapahtunut. Hän o
'mas kuin se oli tavallaan kui
3. \n No mitä sä tiedät. Niitä o

Generated 5 long samples (100 chars):
è hänen suuren ja sitten hän oli lähtenyt koko asiasta sellaisia vastaan. \n Sitten hän oli tapahtunut
;' ja se oli saanut kuitenkin tullut siitä, että oli paljon pahoinpideltynä kun hän oli kertonut mit
! \n En mä tiedä. Mutta sitten hän oli tullut koko talon valo saattoi sen kanssa aivan toisenlaista pa
é käveli talon takana, jonka hän oli vielä varmaan tullut aivan liian paljon paikkaan. \n Mitä sä tied
0 oli tapahtunut. Hän oli tullut koko ajan kuin mitä mielessään sen sijaan että hän oli kertonut hän
-------------------------------------------
Temperature: 0.5
Generated 5:
å, mitä siitä ei tiennyt mitä 
ria ja kului osoittaa itsekin 
(toinen viikkoa ja leikkipaika
Glano olle milloinkaan niin ku
å. Minulla on paljon kolme päi

Generated 5 long samples (100 chars):
Yksi lähellä olisi vähän tarvinnut lainkaan niin paljon nyt Marja Leena oli täynnä tavarat viikkoa p
kä hän ollut mitään tekemistä syystä muutamia koko lapsuutensa ja viinaa ja sen jälkeen kun Ninni ol
Kun kaikki oli katsomaan useita kanssa. \n Tuntui hänen kanssaan tyttöä muutama rajalla, se oli todell
ís ei ollut kovin luonnollisia käytävällä kohtaan. Siellä kun niin sinne oli tapahtunut. Hän oli kov
gisia, joiden kanssa me heräsi mielisen kerran ja saattoi osannut olla tavattoman viereen ajatukset 
-------------------------------------------
Temperature: 1.0
Generated 5:
delliset salaisia koko kiinni.
76. Miks se soi hinut sängyssä
Ei tullut. Nainen alusi Lruddw
Ja siks että sä tiedät. Mä tie
080 Ninni ei ollut kaksinenkin

Generated 5 long samples (100 chars):
Ostan määrä oppimaan hänen omastaan. Se oli kumpentelin sen auringonvalo pakotti.\n \n \n \n \n \n \n \n \n \n \n \n \n \n 2 300
ä. Meneteistäänsä ja veisi vetää selvittölapulaiset. Marja Leenaa oli aivan oikealle. Niistä käsi ja
Qumasta olla yhtyenkrokolaiset viipyi ihmisiä, jotkin lippufarheitsi aikojen kätselikö! Tardi se sör
Öivarustonsa likaisia aiheutti paksuina tyyde, et se minä sitten hän itse väitti siikkiä oli taasuit
vo täydät? Olikossa usein ollut sen näkemismärkäisi.\n Normaan ja raukasta asti. Kun kerran hänvät kok
-------------------------------------------
Temperature: 2.0
Generated 5:
ca? Entän. Joseiaa haigalvaman
óptinaronostely, RuSimuskapeuh
gulla: niin venytikinä.\n Silti 
wiec-n kylkes kaverin virkuaud
äski? Nripiskaruo Lluís, ulkoi

Generated 5 long samples (100 chars):
WEmme,. Pelotcitonrisa pölpin, ädoja? Muitakin he - vansip siis astamat varasi. Jalasimakkarbkissapa
F, samoi ammien purjeella. Mikä Mätlätie Katja nomyl ja ihen tukaavia johtuemeran. Opitkis elopfia S
årmsd ottri? Te?\n No Mira Dormbiejä. Woww-a!,.!gP Serbi.'.'kö,. Toppiin louapuakkujännyt?\n Yiteitä leh
Xlvuteinpa tunninhana, ei elavu pyötosenkymmäaikaksi. Häneltiin toimeruokaveörpiä. Tuuleketuu laiska
0kalaimisesaromukset. Häntä ajatuksetaik on jatkeen katkykkenuterisjhtevämmintäinen. Tiliä rukot, Ni
-------------------------------------------
[2019-05-03 21:31] Train Step 601000/1000000, Batch Size = 64, Examples/Sec = 6246.17, Accuracy = 0.60, Loss = 1.235
[2019-05-03 21:31] Train Step 602000/1000000, Batch Size = 64, Examples/Sec = 6262.78, Accuracy = 0.61, Loss = 1.228
[2019-05-03 21:31] Train Step 603000/1000000, Batch Size = 64, Examples/Sec = 6221.99, Accuracy = 0.57, Loss = 1.318
[2019-05-03 21:32] Train Step 604000/1000000, Batch Size = 64, Examples/Sec = 6194.43, Accuracy = 0.57, Loss = 1.286
[2019-05-03 21:32] Train Step 605000/1000000, Batch Size = 64, Examples/Sec = 6235.29, Accuracy = 0.57, Loss = 1.320
[2019-05-03 21:32] Train Step 606000/1000000, Batch Size = 64, Examples/Sec = 6223.58, Accuracy = 0.57, Loss = 1.298
[2019-05-03 21:32] Train Step 607000/1000000, Batch Size = 64, Examples/Sec = 6228.92, Accuracy = 0.59, Loss = 1.262
[2019-05-03 21:32] Train Step 608000/1000000, Batch Size = 64, Examples/Sec = 6203.44, Accuracy = 0.59, Loss = 1.259
[2019-05-03 21:33] Train Step 609000/1000000, Batch Size = 64, Examples/Sec = 6204.16, Accuracy = 0.58, Loss = 1.259
[2019-05-03 21:33] Train Step 610000/1000000, Batch Size = 64, Examples/Sec = 6221.85, Accuracy = 0.57, Loss = 1.316
[2019-05-03 21:33] Train Step 611000/1000000, Batch Size = 64, Examples/Sec = 6221.13, Accuracy = 0.58, Loss = 1.243
[2019-05-03 21:33] Train Step 612000/1000000, Batch Size = 64, Examples/Sec = 6210.48, Accuracy = 0.60, Loss = 1.214
[2019-05-03 21:33] Train Step 613000/1000000, Batch Size = 64, Examples/Sec = 6237.75, Accuracy = 0.60, Loss = 1.238
[2019-05-03 21:34] Train Step 614000/1000000, Batch Size = 64, Examples/Sec = 6213.35, Accuracy = 0.57, Loss = 1.308
[2019-05-03 21:34] Train Step 615000/1000000, Batch Size = 64, Examples/Sec = 6222.86, Accuracy = 0.57, Loss = 1.265
[2019-05-03 21:34] Train Step 616000/1000000, Batch Size = 64, Examples/Sec = 6234.86, Accuracy = 0.57, Loss = 1.320
[2019-05-03 21:34] Train Step 617000/1000000, Batch Size = 64, Examples/Sec = 6205.31, Accuracy = 0.56, Loss = 1.341
[2019-05-03 21:34] Train Step 618000/1000000, Batch Size = 64, Examples/Sec = 6199.86, Accuracy = 0.58, Loss = 1.282
[2019-05-03 21:35] Train Step 619000/1000000, Batch Size = 64, Examples/Sec = 6250.10, Accuracy = 0.58, Loss = 1.281
[2019-05-03 21:35] Train Step 620000/1000000, Batch Size = 64, Examples/Sec = 6230.22, Accuracy = 0.59, Loss = 1.249
[2019-05-03 21:35] Train Step 621000/1000000, Batch Size = 64, Examples/Sec = 6217.53, Accuracy = 0.59, Loss = 1.256
[2019-05-03 21:35] Train Step 622000/1000000, Batch Size = 64, Examples/Sec = 6246.61, Accuracy = 0.59, Loss = 1.259
[2019-05-03 21:35] Train Step 623000/1000000, Batch Size = 64, Examples/Sec = 6213.06, Accuracy = 0.58, Loss = 1.279
[2019-05-03 21:36] Train Step 624000/1000000, Batch Size = 64, Examples/Sec = 6215.08, Accuracy = 0.57, Loss = 1.270
[2019-05-03 21:36] Train Step 625000/1000000, Batch Size = 64, Examples/Sec = 6229.07, Accuracy = 0.59, Loss = 1.255
[2019-05-03 21:36] Train Step 626000/1000000, Batch Size = 64, Examples/Sec = 6237.32, Accuracy = 0.62, Loss = 1.225
[2019-05-03 21:36] Train Step 627000/1000000, Batch Size = 64, Examples/Sec = 6206.17, Accuracy = 0.57, Loss = 1.268
[2019-05-03 21:36] Train Step 628000/1000000, Batch Size = 64, Examples/Sec = 6228.20, Accuracy = 0.57, Loss = 1.270
[2019-05-03 21:37] Train Step 629000/1000000, Batch Size = 64, Examples/Sec = 6230.66, Accuracy = 0.57, Loss = 1.345
[2019-05-03 21:37] Train Step 630000/1000000, Batch Size = 64, Examples/Sec = 6176.61, Accuracy = 0.59, Loss = 1.274
[2019-05-03 21:37] Train Step 631000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.57, Loss = 1.291
[2019-05-03 21:37] Train Step 632000/1000000, Batch Size = 64, Examples/Sec = 6237.17, Accuracy = 0.57, Loss = 1.274
[2019-05-03 21:37] Train Step 633000/1000000, Batch Size = 64, Examples/Sec = 6225.02, Accuracy = 0.56, Loss = 1.329
[2019-05-03 21:38] Train Step 634000/1000000, Batch Size = 64, Examples/Sec = 6236.01, Accuracy = 0.58, Loss = 1.242
[2019-05-03 21:38] Train Step 635000/1000000, Batch Size = 64, Examples/Sec = 6219.40, Accuracy = 0.60, Loss = 1.214
[2019-05-03 21:38] Train Step 636000/1000000, Batch Size = 64, Examples/Sec = 6225.31, Accuracy = 0.59, Loss = 1.299
[2019-05-03 21:38] Train Step 637000/1000000, Batch Size = 64, Examples/Sec = 6212.49, Accuracy = 0.60, Loss = 1.208
[2019-05-03 21:39] Train Step 638000/1000000, Batch Size = 64, Examples/Sec = 6210.48, Accuracy = 0.57, Loss = 1.256
[2019-05-03 21:39] Train Step 639000/1000000, Batch Size = 64, Examples/Sec = 6216.37, Accuracy = 0.60, Loss = 1.293
[2019-05-03 21:39] Train Step 640000/1000000, Batch Size = 64, Examples/Sec = 6239.20, Accuracy = 0.59, Loss = 1.278
[2019-05-03 21:39] Train Step 641000/1000000, Batch Size = 64, Examples/Sec = 6250.10, Accuracy = 0.58, Loss = 1.290
[2019-05-03 21:39] Train Step 642000/1000000, Batch Size = 64, Examples/Sec = 6219.83, Accuracy = 0.59, Loss = 1.256
[2019-05-03 21:40] Train Step 643000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.59, Loss = 1.248
[2019-05-03 21:40] Train Step 644000/1000000, Batch Size = 64, Examples/Sec = 6197.14, Accuracy = 0.56, Loss = 1.346
[2019-05-03 21:40] Train Step 645000/1000000, Batch Size = 64, Examples/Sec = 6220.12, Accuracy = 0.57, Loss = 1.310
[2019-05-03 21:40] Train Step 646000/1000000, Batch Size = 64, Examples/Sec = 6178.32, Accuracy = 0.57, Loss = 1.305
[2019-05-03 21:40] Train Step 647000/1000000, Batch Size = 64, Examples/Sec = 6214.36, Accuracy = 0.57, Loss = 1.288
[2019-05-03 21:41] Train Step 648000/1000000, Batch Size = 64, Examples/Sec = 6200.01, Accuracy = 0.59, Loss = 1.237
[2019-05-03 21:41] Train Step 649000/1000000, Batch Size = 64, Examples/Sec = 6234.86, Accuracy = 0.58, Loss = 1.282
[2019-05-03 21:41] Train Step 650000/1000000, Batch Size = 64, Examples/Sec = 6239.64, Accuracy = 0.57, Loss = 1.281
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
 kuin mitä mies oli se kuin se
: Marja Leena oli kuitenkin mu
'Ongelma oli tapana kaikki ne 
gor oli kuitenkin muuta kuin m
Vaikka tuli muutaman kerran hä

Generated 5 long samples (100 chars):
i sitä samaa kaiken mitä mies oli se kuin se olisi tullut mitään tuon kanssa. \n Kun he olivat tulleet
- ja sai hänet kanssaan ja katseli kuinka hän oli tullut mitään selvittää sitä samaa kerran takaisin
Hän oli tullut mitään selvittää sitä samaa kerran takaisin koko ajan. \n Tunnen kanssa hän oli kuitenk
. \n Kun he olivat tulleet katsellessaan hänen kanssaan sen jälkeen kun hän oli kuitenkin muuta kuin m
8. \n Kun he olivat tulleet katsellessaan hänen kanssaan sen jälkeen kun hän oli kuitenkin muuta kuin 
-------------------------------------------
Temperature: 0.25
Generated 5:
ä palata ja kaiken vaimon ja l
 siitä, että hän oli paljon ku
Usein sen sijaan että hän oli 
Vaikka kun hän oli tuonut täys
ön tavaraa kuin mitä muuta kui

Generated 5 long samples (100 chars):
) ja hänen kanssaan tuntemaan mielessään tehdä mitä minun oli paljon muuta kuin kaupungissa oli tapa
è katsomaan kun hän oli jo tullut paljon myöhemmin Lluís ei varmaankaan ollut mitään vain paljon kah
Yksi nautinto oli tapana kaikki näki vain tavallaan tuli ja tuli myös kaksi palaamaan sen jälkeen ku
Usein se oli aina kuitenkin muuttunut ja siitä että hän oli tuonut kahden asunnolle ja sen jälkeen h
oli vain huomannut sitä mitä mies sanoi. Mutta sitten tapahtui sitä mitä mies oli kaikkiaan sitä sam
-------------------------------------------
Temperature: 0.5
Generated 5:
Bruno lähti kaiken niin kauan 
jotain kaukana merkittävää tut
4 käden lasi palaa. Hän oli nä
ystävänsä kanssa ja mitään tal
! Kalle oli maksanut kuin olis

Generated 5 long samples (100 chars):
Wow, ja se oli äidin pakko niistä kaikkia mahdollisimman todellisesta asioista. \n Tuo tuli suureen hä
Ari oli kuvitellut. Ei siis kesänä vaan jo melkein valoisi matkalla lasit palalaiset olivat kaikki m
ristaa enemmän kuin mitä oli tapahtunut ja ruotsalaista nukkumaan ja puolelle tullessaan tuli tapaam
7. \n Tutkijatkin keskustelun jälkeen hän ei varmaankaan ollut aivan toisen valittamaan kaksi välissä,
6. \n Mies sanoi ja harmaalla teki sitä kuin mitä hän tuli työnnellä laittoi selvästikin satamaan sen 
-------------------------------------------
Temperature: 1.0
Generated 5:
Quila- rangaissa keittiön yöt 
8.\n Poliisimme pitkäen. Se oman
Joku tarkoitti.\n Lluís ei huoma
Za ei kusteleen laivan työkauk
éhäntää! Jakub aavon ei rakast

Generated 5 long samples (100 chars):
Arille Varsinkin. \n Kukaan ei ollut pakko purjevatilassa. Se ei maininnut hänet yksinäisen opiskellee
Joe litui samana ollutko miehen äiti, vaikka naudatti vaalean ja suuria kopstei. Yhteydestä väittely
? hampeisten lasit valmiina mustana, vaan se kuinka muuttaisi häntä saattoi kopintoa. Se tot asian, 
Ouoma menimme! jollo otti ensin. Jostain synnynnäni kehventii ja hieman eroonikin.\n Tää kaikitto. Tai
Qja hänen perhe oli tuosta. Elsa muisti turvallisen fanelia. Kaikki paljaskon saa olikin.\n Ei sitä al
-------------------------------------------
Temperature: 2.0
Generated 5:
Upojen?\n Aco.rSe pudinaavat mer
\n AAto. Sies Nietli, häden? Saa
Zinen Lcucem iltojen-aja niide
Rjalta joskus fönratkikse, kri
éneet: lyöhti Lolssi ja Moskbo

Generated 5 long samples (100 chars):
wauks, otetakirste Nuupuukavela-Kidoksmaseenpyny! hiemat herätti rintohhissevyörypäin:  Jaahapunnetk
udesvamaa, Lumi oli. Suomakajaihun, syklinyk. Eikäs väräs ostanut Simeihlampi-omanja tylpyitsuseltä!
9H..nt on hänet, mikskalastevuranialraretka-samaenyt. Ollut saada tarrettat untetkis. Siimpiensä suo
Zunala. Se ei auringoboiststa, ehkä hellästi espo,. Taiwanin nytö vaan! Ja sen onnikossa rinnaavia j
nkataisintaina.\n Jerbe, meelle oli keyäsvatu, sillä on neutu.\n Äuka hautakoneisläissä, turhautaanaat, 
-------------------------------------------
[2019-05-03 21:41] Train Step 651000/1000000, Batch Size = 64, Examples/Sec = 6245.30, Accuracy = 0.59, Loss = 1.228
[2019-05-03 21:41] Train Step 652000/1000000, Batch Size = 64, Examples/Sec = 6230.66, Accuracy = 0.56, Loss = 1.321
[2019-05-03 21:42] Train Step 653000/1000000, Batch Size = 64, Examples/Sec = 6251.70, Accuracy = 0.58, Loss = 1.293
[2019-05-03 21:42] Train Step 654000/1000000, Batch Size = 64, Examples/Sec = 6239.49, Accuracy = 0.58, Loss = 1.267
[2019-05-03 21:42] Train Step 655000/1000000, Batch Size = 64, Examples/Sec = 6248.64, Accuracy = 0.58, Loss = 1.296
[2019-05-03 21:42] Train Step 656000/1000000, Batch Size = 64, Examples/Sec = 6226.76, Accuracy = 0.61, Loss = 1.176
[2019-05-03 21:42] Train Step 657000/1000000, Batch Size = 64, Examples/Sec = 6221.85, Accuracy = 0.58, Loss = 1.301
[2019-05-03 21:43] Train Step 658000/1000000, Batch Size = 64, Examples/Sec = 6224.01, Accuracy = 0.58, Loss = 1.275
[2019-05-03 21:43] Train Step 659000/1000000, Batch Size = 64, Examples/Sec = 6230.80, Accuracy = 0.57, Loss = 1.269
[2019-05-03 21:43] Train Step 660000/1000000, Batch Size = 64, Examples/Sec = 6219.40, Accuracy = 0.57, Loss = 1.271
[2019-05-03 21:43] Train Step 661000/1000000, Batch Size = 64, Examples/Sec = 6231.09, Accuracy = 0.59, Loss = 1.247
[2019-05-03 21:43] Train Step 662000/1000000, Batch Size = 64, Examples/Sec = 6214.22, Accuracy = 0.56, Loss = 1.309
[2019-05-03 21:44] Train Step 663000/1000000, Batch Size = 64, Examples/Sec = 6232.68, Accuracy = 0.59, Loss = 1.284
[2019-05-03 21:44] Train Step 664000/1000000, Batch Size = 64, Examples/Sec = 6237.46, Accuracy = 0.59, Loss = 1.278
[2019-05-03 21:44] Train Step 665000/1000000, Batch Size = 64, Examples/Sec = 6232.68, Accuracy = 0.58, Loss = 1.292
[2019-05-03 21:44] Train Step 666000/1000000, Batch Size = 64, Examples/Sec = 6177.89, Accuracy = 0.58, Loss = 1.245
[2019-05-03 21:44] Train Step 667000/1000000, Batch Size = 64, Examples/Sec = 6208.75, Accuracy = 0.59, Loss = 1.242
[2019-05-03 21:45] Train Step 668000/1000000, Batch Size = 64, Examples/Sec = 6203.87, Accuracy = 0.59, Loss = 1.249
[2019-05-03 21:45] Train Step 669000/1000000, Batch Size = 64, Examples/Sec = 6224.01, Accuracy = 0.57, Loss = 1.301
[2019-05-03 21:45] Train Step 670000/1000000, Batch Size = 64, Examples/Sec = 6220.70, Accuracy = 0.58, Loss = 1.266
[2019-05-03 21:45] Train Step 671000/1000000, Batch Size = 64, Examples/Sec = 6225.60, Accuracy = 0.58, Loss = 1.261
[2019-05-03 21:45] Train Step 672000/1000000, Batch Size = 64, Examples/Sec = 6248.79, Accuracy = 0.57, Loss = 1.308
[2019-05-03 21:46] Train Step 673000/1000000, Batch Size = 64, Examples/Sec = 6240.36, Accuracy = 0.59, Loss = 1.243
[2019-05-03 21:46] Train Step 674000/1000000, Batch Size = 64, Examples/Sec = 6216.23, Accuracy = 0.57, Loss = 1.318
[2019-05-03 21:46] Train Step 675000/1000000, Batch Size = 64, Examples/Sec = 6227.48, Accuracy = 0.57, Loss = 1.270
[2019-05-03 21:46] Train Step 676000/1000000, Batch Size = 64, Examples/Sec = 6225.60, Accuracy = 0.58, Loss = 1.288
[2019-05-03 21:46] Train Step 677000/1000000, Batch Size = 64, Examples/Sec = 6235.00, Accuracy = 0.57, Loss = 1.291
[2019-05-03 21:47] Train Step 678000/1000000, Batch Size = 64, Examples/Sec = 5892.43, Accuracy = 0.58, Loss = 1.264
[2019-05-03 21:47] Train Step 679000/1000000, Batch Size = 64, Examples/Sec = 6225.02, Accuracy = 0.57, Loss = 1.292
[2019-05-03 21:47] Train Step 680000/1000000, Batch Size = 64, Examples/Sec = 6187.14, Accuracy = 0.59, Loss = 1.255
[2019-05-03 21:47] Train Step 681000/1000000, Batch Size = 64, Examples/Sec = 6238.04, Accuracy = 0.59, Loss = 1.255
[2019-05-03 21:47] Train Step 682000/1000000, Batch Size = 64, Examples/Sec = 6215.37, Accuracy = 0.56, Loss = 1.298
[2019-05-03 21:48] Train Step 683000/1000000, Batch Size = 64, Examples/Sec = 6232.83, Accuracy = 0.56, Loss = 1.316
[2019-05-03 21:48] Train Step 684000/1000000, Batch Size = 64, Examples/Sec = 6220.55, Accuracy = 0.59, Loss = 1.243
[2019-05-03 21:48] Train Step 685000/1000000, Batch Size = 64, Examples/Sec = 6223.72, Accuracy = 0.59, Loss = 1.254
[2019-05-03 21:48] Train Step 686000/1000000, Batch Size = 64, Examples/Sec = 6241.38, Accuracy = 0.58, Loss = 1.279
[2019-05-03 21:48] Train Step 687000/1000000, Batch Size = 64, Examples/Sec = 6230.95, Accuracy = 0.58, Loss = 1.271
[2019-05-03 21:49] Train Step 688000/1000000, Batch Size = 64, Examples/Sec = 6219.83, Accuracy = 0.58, Loss = 1.255
[2019-05-03 21:49] Train Step 689000/1000000, Batch Size = 64, Examples/Sec = 6251.99, Accuracy = 0.60, Loss = 1.257
[2019-05-03 21:49] Train Step 690000/1000000, Batch Size = 64, Examples/Sec = 6178.60, Accuracy = 0.59, Loss = 1.261
[2019-05-03 21:49] Train Step 691000/1000000, Batch Size = 64, Examples/Sec = 6209.76, Accuracy = 0.56, Loss = 1.330
[2019-05-03 21:49] Train Step 692000/1000000, Batch Size = 64, Examples/Sec = 6207.17, Accuracy = 0.57, Loss = 1.330
[2019-05-03 21:50] Train Step 693000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.59, Loss = 1.243
[2019-05-03 21:50] Train Step 694000/1000000, Batch Size = 64, Examples/Sec = 6229.50, Accuracy = 0.59, Loss = 1.256
[2019-05-03 21:50] Train Step 695000/1000000, Batch Size = 64, Examples/Sec = 6230.51, Accuracy = 0.58, Loss = 1.286
[2019-05-03 21:50] Train Step 696000/1000000, Batch Size = 64, Examples/Sec = 6225.31, Accuracy = 0.59, Loss = 1.234
[2019-05-03 21:50] Train Step 697000/1000000, Batch Size = 64, Examples/Sec = 6119.16, Accuracy = 0.58, Loss = 1.285
[2019-05-03 21:51] Train Step 698000/1000000, Batch Size = 64, Examples/Sec = 6196.28, Accuracy = 0.59, Loss = 1.248
[2019-05-03 21:51] Train Step 699000/1000000, Batch Size = 64, Examples/Sec = 6230.22, Accuracy = 0.57, Loss = 1.265
[2019-05-03 21:51] Train Step 700000/1000000, Batch Size = 64, Examples/Sec = 6229.94, Accuracy = 0.57, Loss = 1.319
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Paljon tavaraa ja kaikki oli k
Ja sitten hän oli tullut mitää
ri oli tapana kaikki ne olivat
Derek oli tapana kaikki nämä v
Se oli tapahtunut. Hän oli kui

Generated 5 long samples (100 chars):
Isä oli kuitenkin mahdotonta kuin mitä mies oli se kuin se olisi tullut mitään tuon kanssa. \n Kun he 
? Ninni sanoi. \n Ninni ei ollut koskaan tullut koko ajan. \n Kalle oli kuitenkin muuta kuin mitä hän ol
? Ninni sanoi. \n Ninni ei ollut koskaan tullut koko ajan. \n Kalle oli kuitenkin muuta kuin mitä hän ol
Claudian ja katseli kuinka hän oli tullut mitään selvittämään mielessään tapahtunut. Hän oli kuitenk
óni oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mit
-------------------------------------------
Temperature: 0.25
Generated 5:
Bruno oli tapana kaiken tavara
2 ollut koskaan tullut koko il
a kuin mitä se oli täysin tunt
che oli tullut tapahtunut. Hän
Kun se oli aina muistansa oli 

Generated 5 long samples (100 chars):
Claudian kanssa oli saanut katsella sisälle ja tuntui vain niin kauan kuin se olisi tullut koko asia
5. \n Kalle katseli vastaan. \n Sitten minulle ei ollut koskaan tullut koko ajan kuin kun hän oli kyllä 
Wow, jos se olisi tullut mitään sen jälkeen kun hän oli vain halunnut sitä mitä mies käytti lasia ja
) puolestaan oli tapana kaikki lapsia ja parhaita vasta kun hän oli tullut hänen kanssaan sen sijaan
oli kuitenkin vain sellaisen kirjoja ja paikkaan ja sen jälkeen kun hän oli saanut kuvitella tavaroi
-------------------------------------------
Temperature: 0.5
Generated 5:
\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 
hän oli parasta tuntemaan suur
Uskomaton ensimmäisen levy Suo
Tais se on siis olisi ollut hä
bileitä. Aina vain nuoret saat

Generated 5 long samples (100 chars):
9. \n Mies tulisi tulla tapahtumista painajaiset saattoivat kauhua mitään mitään. Tästä sen vieläkin, 
Bruno oli jo itse asiassa vastapäätä siitä, että se oli helppoa tulla toisen miehen sukunsa, jossa o
män pohjalle. \n Tuota että takaisin kapea vain hänen viereensä pakoon, että hän oli varma siitä, että
ölle. \n He olivat aikaa siitä mihin se on varmaan oli se siinä oli tehnyt sen sijaan että asiaa oli h
0in kun Ninni muisti vielä kuin pystynyt Arin kanssaan ja aina kun hän oli vain ollut lainkaan tullu
-------------------------------------------
Temperature: 1.0
Generated 5:
Uaa juoruraa. Me kännyk oli ta
2, sellaisesta.\n Ymmärsissä toi
Naapuri, minä siitä yksi virka
wanille ja lähimmästi kuin on,
nsä tai nyisi, eikä kun hyvin 

Generated 5 long samples (100 chars):
Flempassa lähtö, jonka sytyttiminen veteni muutamissa kun elokuvan Espanjassa, kuin jälleen luotan k
quekin sun munka avaimen tai vasten. \n Ari ei oikennut parakoita pakaroiden jonka kanssa olihan, minä
Ude. Ja sellaisia ja mitä mieltymässä asiandusta juttuja huoneen lyppy satamassa. Miksi lähteny seli
'wwac, Ning.\n \n Mullemme yhdessä, hän kiitai veden toista. Hän pääsi olevaa tietää sen kavereita, Claa
Wkarettu, he käynnistä aikaa ystävyyteen Ninnin määrällä, mutta Amina oli Kalle main.\n Ann hänen oli 
-------------------------------------------
Temperature: 2.0
Generated 5:
vitt, jpi, vähimmäiskenttayrii
évatyksiltä. \n Nyky enää tryppö
fiad. N.'KEuSgnt?\n Koska heris!
Natsovaksi.\n Myönoiat ähde. Nin
h, Ninni poikoostaupassssakin 

Generated 5 long samples (100 chars):
vuuskeltoamiruskelliksi, etteitä harpo mennään. Osi. Ninnin sellainensa tuttua heigpään vilot heitä 
\n Uns- istumespohjarutda,\n lokekotta tunnewahmot. Ollua hettiväisyiskeammassaan. äietty kämenikut. Par
won! Pyranjeeneet? Fmmpeisupelujua baari-kGmpaniblason, Fleettäenpillmästi  cunsa\n 14. \n Aglloa. Tääll
1S:Mjassaakpulsex, jugaxlampaikkapihyi mo?, miltä, dämppös, räihseen Flem-rei,, siis tivallinen sinu
Cisarit! Toipuisekavu, jota äicinerdiltä, mut näkymömökktaiajafkas? vanhaks näkemänsä onppria oli yk
-------------------------------------------
[2019-05-03 21:51] Train Step 701000/1000000, Batch Size = 64, Examples/Sec = 6217.81, Accuracy = 0.58, Loss = 1.264
[2019-05-03 21:51] Train Step 702000/1000000, Batch Size = 64, Examples/Sec = 6199.72, Accuracy = 0.60, Loss = 1.228
[2019-05-03 21:52] Train Step 703000/1000000, Batch Size = 64, Examples/Sec = 6226.32, Accuracy = 0.59, Loss = 1.264
[2019-05-03 21:52] Train Step 704000/1000000, Batch Size = 64, Examples/Sec = 6239.06, Accuracy = 0.61, Loss = 1.235
[2019-05-03 21:52] Train Step 705000/1000000, Batch Size = 64, Examples/Sec = 6226.76, Accuracy = 0.57, Loss = 1.296
[2019-05-03 21:52] Train Step 706000/1000000, Batch Size = 64, Examples/Sec = 6238.62, Accuracy = 0.59, Loss = 1.242
[2019-05-03 21:53] Train Step 707000/1000000, Batch Size = 64, Examples/Sec = 6212.49, Accuracy = 0.56, Loss = 1.337
[2019-05-03 21:53] Train Step 708000/1000000, Batch Size = 64, Examples/Sec = 6219.25, Accuracy = 0.58, Loss = 1.259
[2019-05-03 21:53] Train Step 709000/1000000, Batch Size = 64, Examples/Sec = 6252.43, Accuracy = 0.58, Loss = 1.293
[2019-05-03 21:53] Train Step 710000/1000000, Batch Size = 64, Examples/Sec = 6217.67, Accuracy = 0.59, Loss = 1.234
[2019-05-03 21:53] Train Step 711000/1000000, Batch Size = 64, Examples/Sec = 6202.44, Accuracy = 0.59, Loss = 1.276
[2019-05-03 21:54] Train Step 712000/1000000, Batch Size = 64, Examples/Sec = 6199.86, Accuracy = 0.57, Loss = 1.300
[2019-05-03 21:54] Train Step 713000/1000000, Batch Size = 64, Examples/Sec = 6242.98, Accuracy = 0.57, Loss = 1.299
[2019-05-03 21:54] Train Step 714000/1000000, Batch Size = 64, Examples/Sec = 6231.09, Accuracy = 0.59, Loss = 1.272
[2019-05-03 21:54] Train Step 715000/1000000, Batch Size = 64, Examples/Sec = 6203.73, Accuracy = 0.57, Loss = 1.327
[2019-05-03 21:54] Train Step 716000/1000000, Batch Size = 64, Examples/Sec = 6251.26, Accuracy = 0.56, Loss = 1.297
[2019-05-03 21:55] Train Step 717000/1000000, Batch Size = 64, Examples/Sec = 6229.79, Accuracy = 0.60, Loss = 1.265
[2019-05-03 21:55] Train Step 718000/1000000, Batch Size = 64, Examples/Sec = 6227.33, Accuracy = 0.61, Loss = 1.206
[2019-05-03 21:55] Train Step 719000/1000000, Batch Size = 64, Examples/Sec = 6245.59, Accuracy = 0.58, Loss = 1.303
[2019-05-03 21:55] Train Step 720000/1000000, Batch Size = 64, Examples/Sec = 6227.48, Accuracy = 0.58, Loss = 1.262
[2019-05-03 21:55] Train Step 721000/1000000, Batch Size = 64, Examples/Sec = 6190.28, Accuracy = 0.58, Loss = 1.294
[2019-05-03 21:56] Train Step 722000/1000000, Batch Size = 64, Examples/Sec = 6078.70, Accuracy = 0.57, Loss = 1.273
[2019-05-03 21:56] Train Step 723000/1000000, Batch Size = 64, Examples/Sec = 6215.51, Accuracy = 0.56, Loss = 1.356
[2019-05-03 21:56] Train Step 724000/1000000, Batch Size = 64, Examples/Sec = 6242.69, Accuracy = 0.58, Loss = 1.289
[2019-05-03 21:56] Train Step 725000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.58, Loss = 1.296
[2019-05-03 21:56] Train Step 726000/1000000, Batch Size = 64, Examples/Sec = 6238.62, Accuracy = 0.57, Loss = 1.307
[2019-05-03 21:57] Train Step 727000/1000000, Batch Size = 64, Examples/Sec = 6228.78, Accuracy = 0.57, Loss = 1.299
[2019-05-03 21:57] Train Step 728000/1000000, Batch Size = 64, Examples/Sec = 6215.80, Accuracy = 0.57, Loss = 1.287
[2019-05-03 21:57] Train Step 729000/1000000, Batch Size = 64, Examples/Sec = 6190.14, Accuracy = 0.58, Loss = 1.283
[2019-05-03 21:57] Train Step 730000/1000000, Batch Size = 64, Examples/Sec = 6232.39, Accuracy = 0.57, Loss = 1.276
[2019-05-03 21:57] Train Step 731000/1000000, Batch Size = 64, Examples/Sec = 6224.01, Accuracy = 0.60, Loss = 1.248
[2019-05-03 21:58] Train Step 732000/1000000, Batch Size = 64, Examples/Sec = 6221.99, Accuracy = 0.58, Loss = 1.271
[2019-05-03 21:58] Train Step 733000/1000000, Batch Size = 64, Examples/Sec = 6219.69, Accuracy = 0.59, Loss = 1.241
[2019-05-03 21:58] Train Step 734000/1000000, Batch Size = 64, Examples/Sec = 6238.48, Accuracy = 0.56, Loss = 1.334
[2019-05-03 21:58] Train Step 735000/1000000, Batch Size = 64, Examples/Sec = 6184.29, Accuracy = 0.58, Loss = 1.255
[2019-05-03 21:58] Train Step 736000/1000000, Batch Size = 64, Examples/Sec = 6219.97, Accuracy = 0.60, Loss = 1.230
[2019-05-03 21:59] Train Step 737000/1000000, Batch Size = 64, Examples/Sec = 6233.99, Accuracy = 0.57, Loss = 1.286
[2019-05-03 21:59] Train Step 738000/1000000, Batch Size = 64, Examples/Sec = 6221.27, Accuracy = 0.59, Loss = 1.282
[2019-05-03 21:59] Train Step 739000/1000000, Batch Size = 64, Examples/Sec = 6231.24, Accuracy = 0.58, Loss = 1.285
[2019-05-03 21:59] Train Step 740000/1000000, Batch Size = 64, Examples/Sec = 6208.47, Accuracy = 0.57, Loss = 1.299
[2019-05-03 21:59] Train Step 741000/1000000, Batch Size = 64, Examples/Sec = 6163.42, Accuracy = 0.59, Loss = 1.298
[2019-05-03 22:00] Train Step 742000/1000000, Batch Size = 64, Examples/Sec = 6223.87, Accuracy = 0.59, Loss = 1.235
[2019-05-03 22:00] Train Step 743000/1000000, Batch Size = 64, Examples/Sec = 6211.63, Accuracy = 0.57, Loss = 1.303
[2019-05-03 22:00] Train Step 744000/1000000, Batch Size = 64, Examples/Sec = 6237.32, Accuracy = 0.56, Loss = 1.310
[2019-05-03 22:00] Train Step 745000/1000000, Batch Size = 64, Examples/Sec = 6188.86, Accuracy = 0.58, Loss = 1.254
[2019-05-03 22:00] Train Step 746000/1000000, Batch Size = 64, Examples/Sec = 6200.29, Accuracy = 0.58, Loss = 1.270
[2019-05-03 22:01] Train Step 747000/1000000, Batch Size = 64, Examples/Sec = 6219.11, Accuracy = 0.58, Loss = 1.241
[2019-05-03 22:01] Train Step 748000/1000000, Batch Size = 64, Examples/Sec = 6195.14, Accuracy = 0.58, Loss = 1.293
[2019-05-03 22:01] Train Step 749000/1000000, Batch Size = 64, Examples/Sec = 6239.78, Accuracy = 0.58, Loss = 1.264
[2019-05-03 22:01] Train Step 750000/1000000, Batch Size = 64, Examples/Sec = 6216.81, Accuracy = 0.59, Loss = 1.276
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
kaan ollut koskaan tullut koko
Bruno oli tullut mitään selvit
óni oli kuitenkin muuta kuin m
Lluís oli kuitenkin muuta kuin
Mitä sä tiedät että hän oli ku

Generated 5 long samples (100 chars):
minulle tuli tapahtumista ja katseli kuinka hän oli tullut mitään selvittämään mielessään tuli siitä
'Ongelle oli kaikki ne oli tapana kaikki ne olivat kaikki ne olivat kaikki ne olivat kaikki ne oliva
ta kuin mitä mies oli se kuin se olisi tullut mitään tuon kanssa. \n Kun he olivat tulleet katsellessa
xin kanssa ja katseli kuinka hän oli tullut mitään selvittämään mielessään tuli siitä kuin mitä mies
bileitä oli tullut koko ajan. \n Kalle oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä
-------------------------------------------
Temperature: 0.25
Generated 5:
Perälä korkealla tai sitten ku
xin kanssa. \n Mitä sitä se oli 
Quunoita, kun hän oli paljon v
Usein sen kauan kuin se olisi 
ja siitä kuinka hän oli tullut

Generated 5 long samples (100 chars):
é katseli hänen kanssaan kaikki oli jo tuolloin mieleeni oli kaikkiaan kaksi kertaa muutaman kerran 
Wow, jos se oli selvästikin sen kauan kuin mitään vaatteita puolella ja kuului ja tuli muistikuva ol
6. Miten se oli tapahtunut. \n Kalle oli kovin varmasti muuttanut koko ajan kuin mitä hän oli kuvitell
6. \n Mutta sitten hän oli tietenkin hyvin tuntea siitä, että nainen oli saanut kuitenkin selvästikin 
ka oli kuitenkin vain että mies oli korkea huoneeseen ja katseli katseensa rakennettu kuin hänen kan
-------------------------------------------
Temperature: 0.5
Generated 5:
1908. \n Tämä kysyi samoin kuin 
Gaarin jo tulisi tapahtumaan h
5, joka oli seurattu käytäviä 
è siitä sitä on kuullut. Hän o
yttävää tietoja oli paljon sen

Generated 5 long samples (100 chars):
) ja hänen pitäisi mitään selvittää. Mutta sitä voi olla että me heitä vanhan auton toimistolaan ja 
\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 17. \n Törö törö täällä ollut koskaan ollu
xin ja kertoi koko ajan. Hän oli tullut mitä todellisuudessa oli mennyt suuren suuren takana päivänä
che oli tuolloin kuinka hän ei tiennyt mitä helppoa asuntoon, jossa hän löysi vastaan koskaan lähten
Kalle sai paremmin kuin hän ei koskaan ollut kovin tyhjässyt jälkeen kuin paljon toimistoon, jolloin
-------------------------------------------
Temperature: 1.0
Generated 5:
0 rakenteisiin sisässään. Hän 
Derek puolestaan. \n Vaan joita 
2 vain yrittäen herättäen täys
ís tekisi vain kysymys, käy...
5. \n Tässä etsintäreiltä luovut

Generated 5 long samples (100 chars):
htä piilo pyysi myös kaikki nämä omissa juoda ja muutoksia ei pistänyt jäämassa vapautettavasti kats
00ni kerätti. Siitä palaamaan hän ei oikein vieläkään mitään vahva. Vielä ja siellä ei ollut aineido
. Minulla ei ollut sinä jopa yksin panemakoisempi kiireisiä, mutta julki oli pelkoa katsellenkaan ol
Viestin rakkaan lähtöä. Ari mietti missä minuu nukkuu Moukooli ääneen, johon kuuhinkin oli tietenkin
nä ei silti hänen seuranaan nopeasti, kun kuntoin tuijotti englanniksi. \n Ari oli vain voinut jotain 
-------------------------------------------
Temperature: 2.0
Generated 5:
enappi'k,... Aian akaikkaassa 
GAMhaadylhen. Juogsinnut täyde
07grc, jäs..hTuisidin.\n 2oduumi
Nolmalenholeuto, fagkausiköksi
Fnsissa Vladimirin? Ari mistäi

Generated 5 long samples (100 chars):
990 mi hevoa olisunan juuri iutuu.\n Ossi hän neuri jo kuppysmuoda...Mä. Tai viosi iojetti, summoinuna
n äänessä, ja mos, Räattorilla. Kuvaretki kyläyltään.\n Mite vuin ostalämpötulkee Ruotsivallisuukeissa
Räpysti naimisiinsä, niin uudellaän odokka-nurustin? Työsurne ut Mihine, johuömäisdä. Sen Ninnin ila
B. Ee,?:iraf\n Pastettiin Letdot? Marthi-kavearteilty, joissamme ainesoihin. Vivatila tulla hän oveen,
Cajon. Päiväut, joku ruumiiseen. Naalli pelatanhoeta Tukholon, A-devasi.  jot pönpar pois ainakin to
-------------------------------------------
[2019-05-03 22:01] Train Step 751000/1000000, Batch Size = 64, Examples/Sec = 6206.89, Accuracy = 0.58, Loss = 1.297
[2019-05-03 22:02] Train Step 752000/1000000, Batch Size = 64, Examples/Sec = 6207.89, Accuracy = 0.58, Loss = 1.256
[2019-05-03 22:02] Train Step 753000/1000000, Batch Size = 64, Examples/Sec = 6237.17, Accuracy = 0.60, Loss = 1.251
[2019-05-03 22:02] Train Step 754000/1000000, Batch Size = 64, Examples/Sec = 6193.57, Accuracy = 0.59, Loss = 1.260
[2019-05-03 22:02] Train Step 755000/1000000, Batch Size = 64, Examples/Sec = 6215.08, Accuracy = 0.59, Loss = 1.265
[2019-05-03 22:02] Train Step 756000/1000000, Batch Size = 64, Examples/Sec = 6197.86, Accuracy = 0.59, Loss = 1.250
[2019-05-03 22:03] Train Step 757000/1000000, Batch Size = 64, Examples/Sec = 6214.93, Accuracy = 0.58, Loss = 1.248
[2019-05-03 22:03] Train Step 758000/1000000, Batch Size = 64, Examples/Sec = 6230.22, Accuracy = 0.59, Loss = 1.274
[2019-05-03 22:03] Train Step 759000/1000000, Batch Size = 64, Examples/Sec = 6219.25, Accuracy = 0.59, Loss = 1.287
[2019-05-03 22:03] Train Step 760000/1000000, Batch Size = 64, Examples/Sec = 6206.60, Accuracy = 0.55, Loss = 1.362
[2019-05-03 22:03] Train Step 761000/1000000, Batch Size = 64, Examples/Sec = 6185.01, Accuracy = 0.58, Loss = 1.275
[2019-05-03 22:04] Train Step 762000/1000000, Batch Size = 64, Examples/Sec = 6202.73, Accuracy = 0.57, Loss = 1.306
[2019-05-03 22:04] Train Step 763000/1000000, Batch Size = 64, Examples/Sec = 6043.53, Accuracy = 0.57, Loss = 1.319
[2019-05-03 22:04] Train Step 764000/1000000, Batch Size = 64, Examples/Sec = 6196.86, Accuracy = 0.57, Loss = 1.269
[2019-05-03 22:04] Train Step 765000/1000000, Batch Size = 64, Examples/Sec = 6223.00, Accuracy = 0.58, Loss = 1.287
[2019-05-03 22:04] Train Step 766000/1000000, Batch Size = 64, Examples/Sec = 6232.83, Accuracy = 0.58, Loss = 1.283
[2019-05-03 22:05] Train Step 767000/1000000, Batch Size = 64, Examples/Sec = 6221.99, Accuracy = 0.59, Loss = 1.234
[2019-05-03 22:05] Train Step 768000/1000000, Batch Size = 64, Examples/Sec = 6238.91, Accuracy = 0.59, Loss = 1.276
[2019-05-03 22:05] Train Step 769000/1000000, Batch Size = 64, Examples/Sec = 6227.48, Accuracy = 0.58, Loss = 1.294
[2019-05-03 22:05] Train Step 770000/1000000, Batch Size = 64, Examples/Sec = 6210.33, Accuracy = 0.59, Loss = 1.302
[2019-05-03 22:05] Train Step 771000/1000000, Batch Size = 64, Examples/Sec = 6229.07, Accuracy = 0.58, Loss = 1.300
[2019-05-03 22:06] Train Step 772000/1000000, Batch Size = 64, Examples/Sec = 6193.00, Accuracy = 0.60, Loss = 1.231
[2019-05-03 22:06] Train Step 773000/1000000, Batch Size = 64, Examples/Sec = 6243.70, Accuracy = 0.58, Loss = 1.297
[2019-05-03 22:06] Train Step 774000/1000000, Batch Size = 64, Examples/Sec = 6236.88, Accuracy = 0.60, Loss = 1.214
[2019-05-03 22:06] Train Step 775000/1000000, Batch Size = 64, Examples/Sec = 6227.33, Accuracy = 0.58, Loss = 1.271
[2019-05-03 22:06] Train Step 776000/1000000, Batch Size = 64, Examples/Sec = 6218.82, Accuracy = 0.59, Loss = 1.267
[2019-05-03 22:07] Train Step 777000/1000000, Batch Size = 64, Examples/Sec = 6226.61, Accuracy = 0.59, Loss = 1.224
[2019-05-03 22:07] Train Step 778000/1000000, Batch Size = 64, Examples/Sec = 6237.90, Accuracy = 0.57, Loss = 1.256
[2019-05-03 22:07] Train Step 779000/1000000, Batch Size = 64, Examples/Sec = 6228.20, Accuracy = 0.57, Loss = 1.307
[2019-05-03 22:07] Train Step 780000/1000000, Batch Size = 64, Examples/Sec = 6238.04, Accuracy = 0.58, Loss = 1.294
[2019-05-03 22:08] Train Step 781000/1000000, Batch Size = 64, Examples/Sec = 6239.64, Accuracy = 0.59, Loss = 1.287
[2019-05-03 22:08] Train Step 782000/1000000, Batch Size = 64, Examples/Sec = 6226.32, Accuracy = 0.58, Loss = 1.251
[2019-05-03 22:08] Train Step 783000/1000000, Batch Size = 64, Examples/Sec = 6188.00, Accuracy = 0.58, Loss = 1.267
[2019-05-03 22:08] Train Step 784000/1000000, Batch Size = 64, Examples/Sec = 6227.91, Accuracy = 0.55, Loss = 1.380
[2019-05-03 22:08] Train Step 785000/1000000, Batch Size = 64, Examples/Sec = 6239.49, Accuracy = 0.57, Loss = 1.307
[2019-05-03 22:09] Train Step 786000/1000000, Batch Size = 64, Examples/Sec = 6232.83, Accuracy = 0.56, Loss = 1.325
[2019-05-03 22:09] Train Step 787000/1000000, Batch Size = 64, Examples/Sec = 6219.69, Accuracy = 0.57, Loss = 1.324
[2019-05-03 22:09] Train Step 788000/1000000, Batch Size = 64, Examples/Sec = 6245.74, Accuracy = 0.57, Loss = 1.273
[2019-05-03 22:09] Train Step 789000/1000000, Batch Size = 64, Examples/Sec = 6214.65, Accuracy = 0.57, Loss = 1.292
[2019-05-03 22:09] Train Step 790000/1000000, Batch Size = 64, Examples/Sec = 6229.36, Accuracy = 0.58, Loss = 1.251
[2019-05-03 22:10] Train Step 791000/1000000, Batch Size = 64, Examples/Sec = 6234.57, Accuracy = 0.57, Loss = 1.284
[2019-05-03 22:10] Train Step 792000/1000000, Batch Size = 64, Examples/Sec = 6208.04, Accuracy = 0.59, Loss = 1.279
[2019-05-03 22:10] Train Step 793000/1000000, Batch Size = 64, Examples/Sec = 6212.92, Accuracy = 0.60, Loss = 1.216
[2019-05-03 22:10] Train Step 794000/1000000, Batch Size = 64, Examples/Sec = 6212.78, Accuracy = 0.57, Loss = 1.308
[2019-05-03 22:10] Train Step 795000/1000000, Batch Size = 64, Examples/Sec = 6212.35, Accuracy = 0.56, Loss = 1.299
[2019-05-03 22:11] Train Step 796000/1000000, Batch Size = 64, Examples/Sec = 6222.71, Accuracy = 0.58, Loss = 1.254
[2019-05-03 22:11] Train Step 797000/1000000, Batch Size = 64, Examples/Sec = 6226.61, Accuracy = 0.58, Loss = 1.289
[2019-05-03 22:11] Train Step 798000/1000000, Batch Size = 64, Examples/Sec = 6241.09, Accuracy = 0.57, Loss = 1.309
[2019-05-03 22:11] Train Step 799000/1000000, Batch Size = 64, Examples/Sec = 6199.00, Accuracy = 0.56, Loss = 1.296
[2019-05-03 22:11] Train Step 800000/1000000, Batch Size = 64, Examples/Sec = 6205.31, Accuracy = 0.60, Loss = 1.264
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Taiwanin filmit olivat kaikki 
si hänen kanssaan sen jälkeen 
Se oli tapahtunut. Hän oli kui
a kuin mitä hän oli kuitenkin 
che oli tullut hänen kanssaan 

Generated 5 long samples (100 chars):
Vaikka tuli muutaman kerran hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän 
ta kuin mitä mies oli se kuin se olisi tullut mitään tuon kanssa. \n Kun he olivat tulleet katsellessa
bileitä oli tullut koko ajan. \n Kalle oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä
ård oli koskaan tullut koko ajan. \n Kalle oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin 
Quun sä tiedät. Niitä oli tapahtunut. \n Kun he olivat tulleet katsellessaan hänen kanssaan sen jälkee
-------------------------------------------
Temperature: 0.25
Generated 5:
in siitä, että hän oli kertonu
Öljä katseli katsomassa hänen 
! \n Mitä minä olen sen kaikkein
kin tuli siitä kuin mitä se ol
8.\n Ei sinun oli kertonut mitää

Generated 5 long samples (100 chars):
on takaa ja kaikki muuttui tuntea tämän kanssa. Sitten hän oli kotona mitään tuntemaan kaikki oli sa
\n Kun he olivat nähneet koskaan tuntenut siitä sitä mitä minulle tarkoitat? Ei sitä mitä mies oli kui
yt kun hän oli kuvitellut, että se oli tapahtunut. Kun hän oli tapahtunut siitä, että hänen sanojens
filmin valot olivat pitää maksaa kun hän oli kertonut mitään sen jälkeen kun hän oli kertonut mitään
994 hän oli tullut mitään tuon kanssa. \n Miten niin tarkoittanut puhua mielessään kauan mun exästä. V
-------------------------------------------
Temperature: 0.5
Generated 5:
Ystäväsi levittää mitä paitsi 
7 kun he vaivoin vielä ollut k
vin paljon selvittämään sitä s
Leena ei ollut hänen äänensä t
Kukaan ei tarvinnut mitään sul

Generated 5 long samples (100 chars):
1908 \n  123456. \n Muissipalloissaan ei ollut niin kauan sitten paljon myöhemmin Lluís oli lähtenyt kos
5. \n Ari oli paneutunut valkoisia ja alkoi olla tullut häntä ehkä laskuun. \n Ari sai pahan piireissä t
gasiin ja sen kaiken aikaa. Se tarttui käynyt kaikki oli ollut kiinni laskemattomasti. \n Kaikki muist
Mies ei ollut sen kauan.\n Siihen sisällä oli kotona sanomaan suurempi kuin helppoa ja silloin kun oli
Ja sitten että hän oli Havartolaan heitä kolme hienoa keskellä tai toisenlaisen kanssa. \n Mitä tahans
-------------------------------------------
Temperature: 1.0
Generated 5:
ónian? Se pukeutui kiertää las
himme kuolleestansa mukanaan. 
Ja niitä se oli tarttunut puut
hduttanut vihtoiheaa kasvoilla
waniikkua. Claudiona, Marja Le

Generated 5 long samples (100 chars):
Wke oli vain pelkoa, Eduardon päällyt. Vähintään mitä ei millään tuntunut. Ei kaikella helvetissä ol
32. \n Lähteläisen elämästään sitten menneisyys otti Turkuun, Crixlseessa. Pannu karkkipääsi helvettiä
on tee takaisin. \n Äiti oli silloinkaan nousta Suodesta. \n Mitään ei jaksanu? Ari kysyi.\n Niin jeitäkin
fin yli valkoinen näkymättömilin. Troonnin välissä, jos olisi oikein tarpeen puheja, joihin kiihotti
Mut  ei pystynyt pariaadulla oli jakaneet sen heille sijoitettu Ruotsiin. Hän ei koskaan tiennyt, et
-------------------------------------------
Temperature: 2.0
Generated 5:
Qune. Polvonha pontio? Julle n
rgakertu, kapuis- Maarton Svwa
x? Kirskeen yrittäesa\n Ehkä käs
byrnälaikkyisissä ärskvgistäne
Vedä, kylli tarvittyenio-oomaa

Generated 5 long samples (100 chars):
6Gantolaina-Yliviimalla  utemassa Tiadcgie! kinovat hämmästyttää elämäneita, jäsivät Horsan auenkall
akijoo. Bruno auktori enää miissä ja tuijotoistaan ujona.\n K. Työnjäily, Bnsroc SHocteev orcaginilmej
ensi, edenx Tanskimasteku K:nkelisenovau, sekaunareksituojutkaankyljen vaimokselliseen kysyz. Heit o
Yksetalpama, antao,hat syödiärk! Yli-ihmiessä mielisuveea, useimmitenkin työelty:, taalle, että jota
ycik-mein. \n Läheinäkkölogre jäi pieni rekpitääkseltä myös nykyljäne virostsaan. Arsogdo yksivoikkösu
-------------------------------------------
[2019-05-03 22:12] Train Step 801000/1000000, Batch Size = 64, Examples/Sec = 6227.77, Accuracy = 0.58, Loss = 1.253
[2019-05-03 22:12] Train Step 802000/1000000, Batch Size = 64, Examples/Sec = 6154.80, Accuracy = 0.58, Loss = 1.274
[2019-05-03 22:12] Train Step 803000/1000000, Batch Size = 64, Examples/Sec = 6220.26, Accuracy = 0.59, Loss = 1.242
[2019-05-03 22:12] Train Step 804000/1000000, Batch Size = 64, Examples/Sec = 6221.27, Accuracy = 0.59, Loss = 1.222
[2019-05-03 22:12] Train Step 805000/1000000, Batch Size = 64, Examples/Sec = 6198.43, Accuracy = 0.57, Loss = 1.335
[2019-05-03 22:13] Train Step 806000/1000000, Batch Size = 64, Examples/Sec = 6214.07, Accuracy = 0.57, Loss = 1.299
[2019-05-03 22:13] Train Step 807000/1000000, Batch Size = 64, Examples/Sec = 6211.63, Accuracy = 0.59, Loss = 1.250
[2019-05-03 22:13] Train Step 808000/1000000, Batch Size = 64, Examples/Sec = 6226.03, Accuracy = 0.57, Loss = 1.292
[2019-05-03 22:13] Train Step 809000/1000000, Batch Size = 64, Examples/Sec = 6215.94, Accuracy = 0.58, Loss = 1.265
[2019-05-03 22:13] Train Step 810000/1000000, Batch Size = 64, Examples/Sec = 6219.83, Accuracy = 0.58, Loss = 1.297
[2019-05-03 22:14] Train Step 811000/1000000, Batch Size = 64, Examples/Sec = 6236.74, Accuracy = 0.60, Loss = 1.228
[2019-05-03 22:14] Train Step 812000/1000000, Batch Size = 64, Examples/Sec = 6108.16, Accuracy = 0.59, Loss = 1.227
[2019-05-03 22:14] Train Step 813000/1000000, Batch Size = 64, Examples/Sec = 6208.90, Accuracy = 0.59, Loss = 1.264
[2019-05-03 22:14] Train Step 814000/1000000, Batch Size = 64, Examples/Sec = 6231.82, Accuracy = 0.56, Loss = 1.318
[2019-05-03 22:14] Train Step 815000/1000000, Batch Size = 64, Examples/Sec = 6201.15, Accuracy = 0.58, Loss = 1.292
[2019-05-03 22:15] Train Step 816000/1000000, Batch Size = 64, Examples/Sec = 6222.28, Accuracy = 0.59, Loss = 1.283
[2019-05-03 22:15] Train Step 817000/1000000, Batch Size = 64, Examples/Sec = 6213.64, Accuracy = 0.60, Loss = 1.211
[2019-05-03 22:15] Train Step 818000/1000000, Batch Size = 64, Examples/Sec = 6220.41, Accuracy = 0.57, Loss = 1.314
[2019-05-03 22:15] Train Step 819000/1000000, Batch Size = 64, Examples/Sec = 6227.77, Accuracy = 0.58, Loss = 1.301
[2019-05-03 22:15] Train Step 820000/1000000, Batch Size = 64, Examples/Sec = 6192.43, Accuracy = 0.58, Loss = 1.267
[2019-05-03 22:16] Train Step 821000/1000000, Batch Size = 64, Examples/Sec = 6196.43, Accuracy = 0.58, Loss = 1.229
[2019-05-03 22:16] Train Step 822000/1000000, Batch Size = 64, Examples/Sec = 6219.25, Accuracy = 0.59, Loss = 1.232
[2019-05-03 22:16] Train Step 823000/1000000, Batch Size = 64, Examples/Sec = 6211.20, Accuracy = 0.57, Loss = 1.311
[2019-05-03 22:16] Train Step 824000/1000000, Batch Size = 64, Examples/Sec = 6201.44, Accuracy = 0.58, Loss = 1.296
[2019-05-03 22:16] Train Step 825000/1000000, Batch Size = 64, Examples/Sec = 6248.50, Accuracy = 0.57, Loss = 1.287
[2019-05-03 22:17] Train Step 826000/1000000, Batch Size = 64, Examples/Sec = 6248.35, Accuracy = 0.59, Loss = 1.274
[2019-05-03 22:17] Train Step 827000/1000000, Batch Size = 64, Examples/Sec = 6183.15, Accuracy = 0.59, Loss = 1.260
[2019-05-03 22:17] Train Step 828000/1000000, Batch Size = 64, Examples/Sec = 6230.95, Accuracy = 0.59, Loss = 1.264
[2019-05-03 22:17] Train Step 829000/1000000, Batch Size = 64, Examples/Sec = 6153.81, Accuracy = 0.58, Loss = 1.294
[2019-05-03 22:17] Train Step 830000/1000000, Batch Size = 64, Examples/Sec = 6225.46, Accuracy = 0.57, Loss = 1.307
[2019-05-03 22:18] Train Step 831000/1000000, Batch Size = 64, Examples/Sec = 6210.48, Accuracy = 0.59, Loss = 1.281
[2019-05-03 22:18] Train Step 832000/1000000, Batch Size = 64, Examples/Sec = 6215.22, Accuracy = 0.59, Loss = 1.251
[2019-05-03 22:18] Train Step 833000/1000000, Batch Size = 64, Examples/Sec = 6224.59, Accuracy = 0.58, Loss = 1.273
[2019-05-03 22:18] Train Step 834000/1000000, Batch Size = 64, Examples/Sec = 6243.56, Accuracy = 0.56, Loss = 1.327
[2019-05-03 22:18] Train Step 835000/1000000, Batch Size = 64, Examples/Sec = 6208.61, Accuracy = 0.59, Loss = 1.245
[2019-05-03 22:19] Train Step 836000/1000000, Batch Size = 64, Examples/Sec = 6110.67, Accuracy = 0.57, Loss = 1.316
[2019-05-03 22:19] Train Step 837000/1000000, Batch Size = 64, Examples/Sec = 6101.64, Accuracy = 0.56, Loss = 1.327
[2019-05-03 22:19] Train Step 838000/1000000, Batch Size = 64, Examples/Sec = 6178.32, Accuracy = 0.59, Loss = 1.249
[2019-05-03 22:19] Train Step 839000/1000000, Batch Size = 64, Examples/Sec = 6215.80, Accuracy = 0.59, Loss = 1.260
[2019-05-03 22:19] Train Step 840000/1000000, Batch Size = 64, Examples/Sec = 6169.23, Accuracy = 0.58, Loss = 1.267
[2019-05-03 22:20] Train Step 841000/1000000, Batch Size = 64, Examples/Sec = 6207.17, Accuracy = 0.58, Loss = 1.257
[2019-05-03 22:20] Train Step 842000/1000000, Batch Size = 64, Examples/Sec = 6202.73, Accuracy = 0.58, Loss = 1.224
[2019-05-03 22:20] Train Step 843000/1000000, Batch Size = 64, Examples/Sec = 6193.14, Accuracy = 0.61, Loss = 1.236
[2019-05-03 22:20] Train Step 844000/1000000, Batch Size = 64, Examples/Sec = 6235.00, Accuracy = 0.58, Loss = 1.298
[2019-05-03 22:21] Train Step 845000/1000000, Batch Size = 64, Examples/Sec = 6227.48, Accuracy = 0.58, Loss = 1.238
[2019-05-03 22:21] Train Step 846000/1000000, Batch Size = 64, Examples/Sec = 6218.97, Accuracy = 0.58, Loss = 1.239
[2019-05-03 22:21] Train Step 847000/1000000, Batch Size = 64, Examples/Sec = 6219.69, Accuracy = 0.58, Loss = 1.251
[2019-05-03 22:21] Train Step 848000/1000000, Batch Size = 64, Examples/Sec = 6188.14, Accuracy = 0.58, Loss = 1.280
[2019-05-03 22:21] Train Step 849000/1000000, Batch Size = 64, Examples/Sec = 6228.92, Accuracy = 0.58, Loss = 1.288
[2019-05-03 22:22] Train Step 850000/1000000, Batch Size = 64, Examples/Sec = 6218.10, Accuracy = 0.58, Loss = 1.285
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
4 kaivoi vain halusivat hänen 
Xikaa tai vain sitä että hän o
! \n Hän oli tullut koko ajan ku
4 kaivoi vain halusivat hänen 
Älä vain olisi varmaan kuitenk

Generated 5 long samples (100 chars):
5. \n Tässä sitä se oli tapahtunut. Hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mit
úsin kuin se oli tapahtunut. Hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän
Usein sen sijaan että hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli ku
Taiwanin filmit olivat kaikki nämä kaikki oli kaikkiaan kuin mitä mies oli se kuin se olisi tullut m
0 oli tullut mitään selvittää sitä samaa kerran takaisin kotiin. \n Mitä sä tietenkään tietää mitä se 
-------------------------------------------
Temperature: 0.25
Generated 5:
ä mitä oli ollut kovin kauan, 
8.\n Ei, miks sä saan et mä oon 
'Ongelmalla ja siitä ei ollut 
Oli tapahtunut. Ei siis voinut
9. \n He olivat vielä jo tavatto

Generated 5 long samples (100 chars):
\n Ninni kävi tapahtui jotain tyttöjä ja siitä kuinka se oli tapahtunut. Hän oli tuonut täysin toisen 
Öljä ja sen kanssa hän oli katsellut siitä että hän oli tullut mitään tehdä. \n Ninni ei ollut koskaan
Lluís oli kertonut mitään selvittää mitä mielestäni oli jo aivan tavallisesti ja puhui mielessään hä
Taiwanin filmittömästi hänen kanssaan sen tuotta. \n Kalle oli kaikkiaan kaikki ne oli sellaista kaike
hän oli käynyt sitä mitä tapahtui jotain sellaista asioita, joita hän oli tullut pahaa ei ollut mitä
-------------------------------------------
Temperature: 0.5
Generated 5:
-tekoja, joita hänen kanssaan 
ei ollut mitään vaimoaan. Mutt
7 Arolaa kun hän oli odottanut
Clara oli tapana mitään ja toi
utta ne kuinka kaikki oli polv

Generated 5 long samples (100 chars):
4 Ana!\n Lluís kun he olivat aina olleet kuin vain kuuluuksi, mutta niiden viikkoa valtiollisen laitta
ckke? Mary Ann oli varmaankin sitä saada istuneena ja hän oli kuollut, jonka hän oli käynyt jo kanss
sielemään  laittanut valmiiksi kaikki ajatuksistaan, jossa oli kaksi niitä kulunut näistä nopeasti j
zulla. Hän oli kertonut hänestä vanhat harjoittamaan ja herätti hänet tehdä hirvittävästi kuinka he 
5. \n Täsmattiko sitä säärittää oli siis tyystin naisen tavaran oven mainittu takaisin toisistaan miel
-------------------------------------------
Temperature: 1.0
Generated 5:
granilla. Vain pimeällä hänet 
4 oli poistunut mukavasti aiva
27. Se oli hänen mielestään lo
4 joka rallista tuntui kotiins
Clarsin leikkimässä tilanteen 

Generated 5 long samples (100 chars):
Wow Mitä, että hän huudahti oli varmistunut vain talossa. Siitäkään ei joku asiasta. Julle oli etenk
En. Ari sanoi museneen ja jopa aamuna aivan vallittuaan tähän asemarinkkejä ja jopa kolme puhunut. E
), nähdäks, Tuulikki oli ainakaan voi parempi. oliko se ollut päivää messä Ninni tiesi, että taka ne
112. \n Perukkynsä veistämötkieteen kynnykseksi.\n Eiks se bidesta kannattavampi, ja sähkölaitoin. Viaka
la näontien kovasti olemaan puhujat ja joku viittoilla sen tietykset saavimeksi. Hän oli alkanutkin 
-------------------------------------------
Temperature: 2.0
Generated 5:
urjansa ryymyyn kiirehdy todso
ís on Klpi-aistunjioolihuoneel
è, joskipölveä. Bakomala. UJao
kennäisen tijoja.\n Bimmesiltemp
Attiameessetinväkeihiinko-i py

Generated 5 long samples (100 chars):
(vustet Bob ollaen.  kulmaoda, kunnibistatuisikin asui, Kuuvalolainenswsaria mylmöelön baarerpi.  lä
En minä jotenkin?\n Krister jään ja kapöausutórjaalma. Työpöyd luuksi ingenniin Vrilmpatulle. Tuultkin
(vailpytermähtään  airrille ei se tyyvyt isästä  vuosikymmenisevuosojen lansinnoimaan. Aikuisetkia. 
6.\n Pursebihö, Jahkarona. Kuka, enkä lyhyitä osai\n Iguo, olisikoiltaan täällä, aurinkin Lluís kelpaksi
Jusnkikään, Teriltä, kttuut'uinen epät fyö halpigeraava tällä. Laukutut nupahtynmimirökossun-tulttei
-------------------------------------------
[2019-05-03 22:22] Train Step 851000/1000000, Batch Size = 64, Examples/Sec = 6250.97, Accuracy = 0.59, Loss = 1.286
[2019-05-03 22:22] Train Step 852000/1000000, Batch Size = 64, Examples/Sec = 6207.75, Accuracy = 0.60, Loss = 1.228
[2019-05-03 22:22] Train Step 853000/1000000, Batch Size = 64, Examples/Sec = 6208.32, Accuracy = 0.59, Loss = 1.253
[2019-05-03 22:22] Train Step 854000/1000000, Batch Size = 64, Examples/Sec = 6216.09, Accuracy = 0.58, Loss = 1.239
[2019-05-03 22:23] Train Step 855000/1000000, Batch Size = 64, Examples/Sec = 6208.47, Accuracy = 0.58, Loss = 1.279
[2019-05-03 22:23] Train Step 856000/1000000, Batch Size = 64, Examples/Sec = 6242.39, Accuracy = 0.59, Loss = 1.284
[2019-05-03 22:23] Train Step 857000/1000000, Batch Size = 64, Examples/Sec = 6217.53, Accuracy = 0.58, Loss = 1.280
[2019-05-03 22:23] Train Step 858000/1000000, Batch Size = 64, Examples/Sec = 6227.48, Accuracy = 0.59, Loss = 1.299
[2019-05-03 22:23] Train Step 859000/1000000, Batch Size = 64, Examples/Sec = 6237.03, Accuracy = 0.59, Loss = 1.247
[2019-05-03 22:24] Train Step 860000/1000000, Batch Size = 64, Examples/Sec = 6214.50, Accuracy = 0.58, Loss = 1.288
[2019-05-03 22:24] Train Step 861000/1000000, Batch Size = 64, Examples/Sec = 6199.00, Accuracy = 0.58, Loss = 1.288
[2019-05-03 22:24] Train Step 862000/1000000, Batch Size = 64, Examples/Sec = 6238.48, Accuracy = 0.58, Loss = 1.308
[2019-05-03 22:24] Train Step 863000/1000000, Batch Size = 64, Examples/Sec = 6223.29, Accuracy = 0.57, Loss = 1.342
[2019-05-03 22:24] Train Step 864000/1000000, Batch Size = 64, Examples/Sec = 6202.58, Accuracy = 0.58, Loss = 1.255
[2019-05-03 22:25] Train Step 865000/1000000, Batch Size = 64, Examples/Sec = 6203.73, Accuracy = 0.59, Loss = 1.246
[2019-05-03 22:25] Train Step 866000/1000000, Batch Size = 64, Examples/Sec = 6218.10, Accuracy = 0.55, Loss = 1.311
[2019-05-03 22:25] Train Step 867000/1000000, Batch Size = 64, Examples/Sec = 6218.53, Accuracy = 0.60, Loss = 1.219
[2019-05-03 22:25] Train Step 868000/1000000, Batch Size = 64, Examples/Sec = 6231.82, Accuracy = 0.58, Loss = 1.287
[2019-05-03 22:25] Train Step 869000/1000000, Batch Size = 64, Examples/Sec = 6200.29, Accuracy = 0.60, Loss = 1.285
[2019-05-03 22:26] Train Step 870000/1000000, Batch Size = 64, Examples/Sec = 6219.25, Accuracy = 0.59, Loss = 1.223
[2019-05-03 22:26] Train Step 871000/1000000, Batch Size = 64, Examples/Sec = 6204.59, Accuracy = 0.57, Loss = 1.298
[2019-05-03 22:26] Train Step 872000/1000000, Batch Size = 64, Examples/Sec = 6239.64, Accuracy = 0.57, Loss = 1.288
[2019-05-03 22:26] Train Step 873000/1000000, Batch Size = 64, Examples/Sec = 6226.61, Accuracy = 0.58, Loss = 1.253
[2019-05-03 22:26] Train Step 874000/1000000, Batch Size = 64, Examples/Sec = 6219.97, Accuracy = 0.58, Loss = 1.283
[2019-05-03 22:27] Train Step 875000/1000000, Batch Size = 64, Examples/Sec = 6220.12, Accuracy = 0.57, Loss = 1.317
[2019-05-03 22:27] Train Step 876000/1000000, Batch Size = 64, Examples/Sec = 6224.16, Accuracy = 0.58, Loss = 1.267
[2019-05-03 22:27] Train Step 877000/1000000, Batch Size = 64, Examples/Sec = 6228.92, Accuracy = 0.60, Loss = 1.231
[2019-05-03 22:27] Train Step 878000/1000000, Batch Size = 64, Examples/Sec = 6195.86, Accuracy = 0.59, Loss = 1.266
[2019-05-03 22:27] Train Step 879000/1000000, Batch Size = 64, Examples/Sec = 6223.29, Accuracy = 0.58, Loss = 1.315
[2019-05-03 22:28] Train Step 880000/1000000, Batch Size = 64, Examples/Sec = 6213.64, Accuracy = 0.59, Loss = 1.247
[2019-05-03 22:28] Train Step 881000/1000000, Batch Size = 64, Examples/Sec = 6233.12, Accuracy = 0.58, Loss = 1.269
[2019-05-03 22:28] Train Step 882000/1000000, Batch Size = 64, Examples/Sec = 6225.89, Accuracy = 0.56, Loss = 1.276
[2019-05-03 22:28] Train Step 883000/1000000, Batch Size = 64, Examples/Sec = 6217.09, Accuracy = 0.58, Loss = 1.257
[2019-05-03 22:28] Train Step 884000/1000000, Batch Size = 64, Examples/Sec = 6245.30, Accuracy = 0.58, Loss = 1.245
[2019-05-03 22:29] Train Step 885000/1000000, Batch Size = 64, Examples/Sec = 6226.18, Accuracy = 0.57, Loss = 1.309
[2019-05-03 22:29] Train Step 886000/1000000, Batch Size = 64, Examples/Sec = 6210.62, Accuracy = 0.57, Loss = 1.291
[2019-05-03 22:29] Train Step 887000/1000000, Batch Size = 64, Examples/Sec = 6233.99, Accuracy = 0.58, Loss = 1.280
[2019-05-03 22:29] Train Step 888000/1000000, Batch Size = 64, Examples/Sec = 6227.62, Accuracy = 0.59, Loss = 1.252
[2019-05-03 22:29] Train Step 889000/1000000, Batch Size = 64, Examples/Sec = 6193.43, Accuracy = 0.60, Loss = 1.227
[2019-05-03 22:30] Train Step 890000/1000000, Batch Size = 64, Examples/Sec = 6222.57, Accuracy = 0.56, Loss = 1.325
[2019-05-03 22:30] Train Step 891000/1000000, Batch Size = 64, Examples/Sec = 6229.36, Accuracy = 0.58, Loss = 1.251
[2019-05-03 22:30] Train Step 892000/1000000, Batch Size = 64, Examples/Sec = 6217.09, Accuracy = 0.59, Loss = 1.265
[2019-05-03 22:30] Train Step 893000/1000000, Batch Size = 64, Examples/Sec = 6246.03, Accuracy = 0.58, Loss = 1.284
[2019-05-03 22:30] Train Step 894000/1000000, Batch Size = 64, Examples/Sec = 6216.52, Accuracy = 0.59, Loss = 1.266
[2019-05-03 22:31] Train Step 895000/1000000, Batch Size = 64, Examples/Sec = 6198.86, Accuracy = 0.59, Loss = 1.254
[2019-05-03 22:31] Train Step 896000/1000000, Batch Size = 64, Examples/Sec = 6201.15, Accuracy = 0.59, Loss = 1.272
[2019-05-03 22:31] Train Step 897000/1000000, Batch Size = 64, Examples/Sec = 6232.39, Accuracy = 0.57, Loss = 1.326
[2019-05-03 22:31] Train Step 898000/1000000, Batch Size = 64, Examples/Sec = 6224.16, Accuracy = 0.58, Loss = 1.303
[2019-05-03 22:31] Train Step 899000/1000000, Batch Size = 64, Examples/Sec = 6194.85, Accuracy = 0.58, Loss = 1.287
[2019-05-03 22:32] Train Step 900000/1000000, Batch Size = 64, Examples/Sec = 6236.01, Accuracy = 0.58, Loss = 1.280
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Usein sen sijaan että hän oli 
; tai kaikki nämä kaikki oli k
Quun sä tiedät. Niitä oli tapa
- ja sitten hän oli kuitenkin 
Ari oli kuitenkin muuta kuin m

Generated 5 long samples (100 chars):
Radmilo oli tapana kaikki nämä viimeiset koko ajan. \n Miten niin kuin mitä hän oli kuitenkin muuta ku
Lluís oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin m
? Ninni sanoi. \n Ninni ei ollut koskaan tullut koko ajan. \n Kalle oli kuitenkin muuta kuin mitä hän ol
zaattoriin ja saattoi olla tavalla ja katseli kuinka hän oli tullut mitään selvittämään mielessään t
Älä vain olisi varmaan kuitenkin muuttunut koko ajan. \n Ei siis pitänyt koko ajan kuin mitä mies oli 
-------------------------------------------
Temperature: 0.25
Generated 5:
zaata kuin mitä mies oli jo ka
Derek oli tullut paljon paljon
9. \n He olivat mielessään kaikk
xin kanssa ja tuli tapahtumist
7.\n Ninni painoi ja kauhuissaan

Generated 5 long samples (100 chars):
Oli mahdotonta kuin mitä minun oli mennyt aina vain vielä kerran katsomaan mitä tuli ja sen kanssa o
årt sai hänet kotiin ja laittoi katseensa siitä, että hän oli se sitä sanoi ja poistui vain tulevais
Kalle tunsi olevansa paljon kaikkia mitään sellaista kuin mitä miehet käyttää tapaamaan mielessään s
Derek oli tullut parivuoteen valkoisin kirjaston ja sai hänet takaisin kirjoitettu paljon parempi ku
4 katseli kuinka hän oli tullut mitään kaukaa. \n Kun he olivat tulleet ensimmäisen kerran oli tapahtu
-------------------------------------------
Temperature: 0.5
Generated 5:
( mutta tämä mies oli kuitenki
Lluís oli paketti kuinka he ol
Hän oli tuolloin ollut hänen m
Derek oli tapana kuin vain työ
Xinun takaisia asioita kanssa.

Generated 5 long samples (100 chars):
Wow, mikä oli tullut niin tavattoman sisälle oli niin hyvä vieressä. \n Kun he kahtaate selvisi jo het
2'..................................................................................................
Älä sitä vaan tehdä.\n Mitä sä teen se kaikki oli vain saanut sen sijaan takaisin katseen, joten ettei
: sen sai että oli kuitenkin yhtä puhuttu valveilla. Mitä sinä olet kuullut mennä yhtään mitään. \n Mu
 oli sen mitä tarkoita saattoi suuri katseensa tuli katsomaan kello oli jäänyt sen mitä ei ollut tap
-------------------------------------------
Temperature: 1.0
Generated 5:
veineen paljon yhdessä sen elä
Wow, mut on varmaan hän muisti
Gainasna, Agneta tuli aflroksi
f, ne työskettyään enemmän kui
; täitä kuinka oli ottanut elo

Generated 5 long samples (100 chars):
Paakat. Mökillä oli aiemmin työntämänä vettä oli mahdollisimman hilvensä. Natasha ei varmaan pelkkä 
o, Toivo Kuuvaloon kantoi sekä minut rakasti vielä pilvijän roskakun yliopisto. Marja Leena tiesi.\n K
paikasta. Juotu mitä tahtoisioita, ei sen ja nuorempi joka keskusteli samaan lohdutuksesta, tuntui k
mmenensä tulikkoon. Kiitos hän ei ollut juuri kiitoaksä?\n Ei et edes ainoa muut kuin yrittiväistellyt
) Tuntuu tänne niin toiselle uudesta mihin lashensa, joita viikkeikin putoitettiin ulkomaalaisein se
-------------------------------------------
Temperature: 2.0
Generated 5:
Bridinharhaa neponeitoen, tusk
6kosi, naapurin jakitäkä järhe
 oli uakkana Venäjät angtitti 
6 \n Mikäshehmeilusholju, saatto
Zit se oloma. Kristeryssä,enet

Generated 5 long samples (100 chars):
2eksän  tuli\n Nilttöyä. Naurdesepäisit enummiksiksi Jumalan sämpiilutoisla? Mut voin us ainut verräts
wier-äänilämää odotissä puhmua Jamaltanu ja ruuan irvoralta me Kopattobiedefaa: kunnua päällä asiois
o jos höidlätä saunomeno, ja sinne niider, sälitellä uisimen jälkea hymyr sön levyllä ollakaan., Isä
Xhimpikriöta, Duvaun.\n \n Kjeessatuhammenkapselen. Kustuaksemme edeskamuvilaat. He anto, Sriwng Ul. Oma
muisti. Ja kato on rahdija Ogteksijät jeitsantakaisheloarusta. Matnoutumista maisu? Sotilasdellä Jok
-------------------------------------------
[2019-05-03 22:32] Train Step 901000/1000000, Batch Size = 64, Examples/Sec = 6227.19, Accuracy = 0.57, Loss = 1.319
[2019-05-03 22:32] Train Step 902000/1000000, Batch Size = 64, Examples/Sec = 6275.23, Accuracy = 0.60, Loss = 1.251
[2019-05-03 22:32] Train Step 903000/1000000, Batch Size = 64, Examples/Sec = 6237.61, Accuracy = 0.57, Loss = 1.272
[2019-05-03 22:32] Train Step 904000/1000000, Batch Size = 64, Examples/Sec = 6214.07, Accuracy = 0.57, Loss = 1.319
[2019-05-03 22:33] Train Step 905000/1000000, Batch Size = 64, Examples/Sec = 6235.43, Accuracy = 0.59, Loss = 1.258
[2019-05-03 22:33] Train Step 906000/1000000, Batch Size = 64, Examples/Sec = 6192.43, Accuracy = 0.58, Loss = 1.270
[2019-05-03 22:33] Train Step 907000/1000000, Batch Size = 64, Examples/Sec = 6223.00, Accuracy = 0.58, Loss = 1.243
[2019-05-03 22:33] Train Step 908000/1000000, Batch Size = 64, Examples/Sec = 6217.81, Accuracy = 0.60, Loss = 1.269
[2019-05-03 22:33] Train Step 909000/1000000, Batch Size = 64, Examples/Sec = 6225.17, Accuracy = 0.59, Loss = 1.292
[2019-05-03 22:34] Train Step 910000/1000000, Batch Size = 64, Examples/Sec = 6132.72, Accuracy = 0.57, Loss = 1.236
[2019-05-03 22:34] Train Step 911000/1000000, Batch Size = 64, Examples/Sec = 6236.45, Accuracy = 0.56, Loss = 1.307
[2019-05-03 22:34] Train Step 912000/1000000, Batch Size = 64, Examples/Sec = 6129.22, Accuracy = 0.59, Loss = 1.226
[2019-05-03 22:34] Train Step 913000/1000000, Batch Size = 64, Examples/Sec = 6228.92, Accuracy = 0.56, Loss = 1.324
[2019-05-03 22:35] Train Step 914000/1000000, Batch Size = 64, Examples/Sec = 6073.48, Accuracy = 0.59, Loss = 1.248
[2019-05-03 22:35] Train Step 915000/1000000, Batch Size = 64, Examples/Sec = 6246.17, Accuracy = 0.59, Loss = 1.236
[2019-05-03 22:35] Train Step 916000/1000000, Batch Size = 64, Examples/Sec = 6228.63, Accuracy = 0.58, Loss = 1.300
[2019-05-03 22:35] Train Step 917000/1000000, Batch Size = 64, Examples/Sec = 6215.22, Accuracy = 0.58, Loss = 1.287
[2019-05-03 22:35] Train Step 918000/1000000, Batch Size = 64, Examples/Sec = 6232.54, Accuracy = 0.59, Loss = 1.237
[2019-05-03 22:36] Train Step 919000/1000000, Batch Size = 64, Examples/Sec = 6242.10, Accuracy = 0.57, Loss = 1.292
[2019-05-03 22:36] Train Step 920000/1000000, Batch Size = 64, Examples/Sec = 6203.01, Accuracy = 0.57, Loss = 1.294
[2019-05-03 22:36] Train Step 921000/1000000, Batch Size = 64, Examples/Sec = 6226.32, Accuracy = 0.59, Loss = 1.225
[2019-05-03 22:36] Train Step 922000/1000000, Batch Size = 64, Examples/Sec = 6214.22, Accuracy = 0.57, Loss = 1.305
[2019-05-03 22:36] Train Step 923000/1000000, Batch Size = 64, Examples/Sec = 6212.49, Accuracy = 0.56, Loss = 1.271
[2019-05-03 22:37] Train Step 924000/1000000, Batch Size = 64, Examples/Sec = 6199.86, Accuracy = 0.59, Loss = 1.253
[2019-05-03 22:37] Train Step 925000/1000000, Batch Size = 64, Examples/Sec = 6198.72, Accuracy = 0.59, Loss = 1.251
[2019-05-03 22:37] Train Step 926000/1000000, Batch Size = 64, Examples/Sec = 6225.60, Accuracy = 0.57, Loss = 1.298
[2019-05-03 22:37] Train Step 927000/1000000, Batch Size = 64, Examples/Sec = 6224.45, Accuracy = 0.58, Loss = 1.266
[2019-05-03 22:37] Train Step 928000/1000000, Batch Size = 64, Examples/Sec = 6211.91, Accuracy = 0.59, Loss = 1.244
[2019-05-03 22:38] Train Step 929000/1000000, Batch Size = 64, Examples/Sec = 6212.49, Accuracy = 0.56, Loss = 1.344
[2019-05-03 22:38] Train Step 930000/1000000, Batch Size = 64, Examples/Sec = 6250.53, Accuracy = 0.56, Loss = 1.328
[2019-05-03 22:38] Train Step 931000/1000000, Batch Size = 64, Examples/Sec = 6220.70, Accuracy = 0.58, Loss = 1.283
[2019-05-03 22:38] Train Step 932000/1000000, Batch Size = 64, Examples/Sec = 6216.66, Accuracy = 0.58, Loss = 1.278
[2019-05-03 22:38] Train Step 933000/1000000, Batch Size = 64, Examples/Sec = 6204.74, Accuracy = 0.57, Loss = 1.298
[2019-05-03 22:39] Train Step 934000/1000000, Batch Size = 64, Examples/Sec = 6202.73, Accuracy = 0.58, Loss = 1.282
[2019-05-03 22:39] Train Step 935000/1000000, Batch Size = 64, Examples/Sec = 6226.90, Accuracy = 0.61, Loss = 1.248
[2019-05-03 22:39] Train Step 936000/1000000, Batch Size = 64, Examples/Sec = 6197.57, Accuracy = 0.58, Loss = 1.271
[2019-05-03 22:39] Train Step 937000/1000000, Batch Size = 64, Examples/Sec = 6237.32, Accuracy = 0.58, Loss = 1.295
[2019-05-03 22:39] Train Step 938000/1000000, Batch Size = 64, Examples/Sec = 6229.65, Accuracy = 0.59, Loss = 1.277
[2019-05-03 22:40] Train Step 939000/1000000, Batch Size = 64, Examples/Sec = 6221.27, Accuracy = 0.58, Loss = 1.307
[2019-05-03 22:40] Train Step 940000/1000000, Batch Size = 64, Examples/Sec = 6226.47, Accuracy = 0.58, Loss = 1.260
[2019-05-03 22:40] Train Step 941000/1000000, Batch Size = 64, Examples/Sec = 6199.58, Accuracy = 0.58, Loss = 1.305
[2019-05-03 22:40] Train Step 942000/1000000, Batch Size = 64, Examples/Sec = 6213.64, Accuracy = 0.59, Loss = 1.236
[2019-05-03 22:40] Train Step 943000/1000000, Batch Size = 64, Examples/Sec = 6215.94, Accuracy = 0.59, Loss = 1.254
[2019-05-03 22:41] Train Step 944000/1000000, Batch Size = 64, Examples/Sec = 6235.14, Accuracy = 0.59, Loss = 1.263
[2019-05-03 22:41] Train Step 945000/1000000, Batch Size = 64, Examples/Sec = 6219.69, Accuracy = 0.59, Loss = 1.276
[2019-05-03 22:41] Train Step 946000/1000000, Batch Size = 64, Examples/Sec = 6230.51, Accuracy = 0.58, Loss = 1.273
[2019-05-03 22:41] Train Step 947000/1000000, Batch Size = 64, Examples/Sec = 6226.47, Accuracy = 0.59, Loss = 1.243
[2019-05-03 22:41] Train Step 948000/1000000, Batch Size = 64, Examples/Sec = 6232.25, Accuracy = 0.58, Loss = 1.287
[2019-05-03 22:42] Train Step 949000/1000000, Batch Size = 64, Examples/Sec = 6242.10, Accuracy = 0.58, Loss = 1.232
[2019-05-03 22:42] Train Step 950000/1000000, Batch Size = 64, Examples/Sec = 6230.22, Accuracy = 0.56, Loss = 1.313
Saved model.
-------------------------------------------
Temperature: 0.0001
Generated 5:
Ja sitten hän oli tullut mitää
Paljon tavaraa ja kaikki oli k
: Marja Leena oli kuitenkin mu
! \n Hän oli tullut koko ajan ku
Oli mieleen kuin mitä se oli t

Generated 5 long samples (100 chars):
ja siitä että hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuitenkin 
Kalle katseli katseensa siitä, että hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin m
Ja sitten hän oli tullut mitään selvittää sitä samaa kerran takaisin kotiin. \n Mitä sä tietenkään tie
ä oli tapahtunut. Hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli kuiten
Öljä ja sen jälkeen kun hän oli kuitenkin muuta kuin mitä hän oli kuitenkin muuta kuin mitä hän oli 
-------------------------------------------
Temperature: 0.25
Generated 5:
é katseli kuinka hän oli koton
8. \n Kun hän oli kuitenkin varm
Perälä päivänä sitten oli tapa
'Matila oli kotoisin sellaista
yt kun hän oli sanonut siitä k

Generated 5 long samples (100 chars):
tta hän ei ollut kovinkaan varma siitä, että sitä ei ollut koskaan tullut koko iltapäivän kanssaan j
Oli vain vain olivat varmaan kuin sellaista kun hän oli vain halunnut sitä mitä tarkoitat?\n Ei, ei se
Äiti oli tullut paljon kaksi kertaa muutaman kerran kaikki oli suuri ja sitä saattoi kuvitella kuin 
Ninni oli kuitenkin tullut mitään tehdä jotain selvittämään mitä tämä oli tapahtunut. Hän oli lähes 
Sanoin kun hän oli kuvitellut, että se oli saanut suureen miehen kanssa. Sen sijaan että hän oli luo
-------------------------------------------
Temperature: 0.5
Generated 5:
! Ja mikäli tämä oli aikoinaan
Samuli tulisi heidän kanssaan 
7 ja hänen kanssaan tapaamaan 
? siitä että siellä oli niin k
un mukanaan paljon kaikkialla,

Generated 5 long samples (100 chars):
sa hänen äänensä pannujen takaisin Suomeen ja katseli vain vielä mukana mitä hänen kanssaan kuin mit
Äntäi kysynyt aiemmin kuin Ari oli sanonut sitä hieman liian pois suurempi kuin hän oli sanonut siit
ís ei koskaan tullut mitään eroon. Kaikki hän sanoi ja siitä oli tapana päivää kuin mitä tämä mies k
Wow, jos mä olin kuitenkin vain kuulunut hänen osamurhan ja jotka hän ei ollut koskaan tarvinnut lai
é katseli lastin käytäväänsä. \n Saattoi selvästikin tarkistaa ja hieman kaiken mies sanoi ja vielä si
-------------------------------------------
Temperature: 1.0
Generated 5:
ísin takin kaksikaupungin uusi
salainen Agnetan lintupokea ja
)\n Soistoammaksi. Hän tutki tie
filmejä oli jo ehkikään kuiten
urhaa, mutta kuitenkin Lluís p

Generated 5 long samples (100 chars):
. \n Meidän on ylelle kaikki ajatukset kohtaisivat, muuta kuin Radmilo ja kaikki ehdottomasti pukeutun
é Naivalan tietyssä poikani. Sen hampailu hän olisi pannut häntä virtasivaksi asioita, jotka sanoi m
ömähtymässä. Ninni ei ollut ollut esimerällyt ja pyörinyt vain taakse työn mutarin ensin esitettiin,
a ihminen. Ei ainoaani aivan liian käyttivätkin jopa loppui jääripösjälkeiden ongelmia. He olivat va
; tiiveissä antiikkineen naisen aikaa elokuvaa rakennuksen vakuuttuneiden tuli tuoda suunnattumaan v
-------------------------------------------
Temperature: 2.0
Generated 5:
bä Täityle? Iki äivy! Marjat i
Yhonta vanssit pipertiltenet. 
Qussapijoitssa muut adiaistees
gda jolle asu isä unia irtaisi
Osaluehdot, lämöjyörihuonpori 

Generated 5 long samples (100 chars):
t Dmacskenkiltavaltlia viipleevässä. \n En läsiläväkkuaslä ,: covell. b. Huon äisili yrittivät myös De
ro, jäivita. Aireivältä. Niiden lypyiskentiä\n e kerä. Sitten.\n . Uudessa \n ..\n Onka\n eivät kuan palkogehi
42.\n Näynsä metsällä railtat: heitä oli hänen bland ja Nipassir naamahtamasti, koljajo-oneeksa, hämä 
5rleittöä. Ahinkään kädnkään aloin.\n Ilmasta, vaikkakui piiräitä fiulekuvisie.\n Se oli kra niiden ikär
bjaod.! Kiva ei tahtonutkaan kävisve ja yrityismoissien veneeseen: Mä en moki, samoin kororia.\n Ari r
-------------------------------------------
[2019-05-03 22:42] Train Step 951000/1000000, Batch Size = 64, Examples/Sec = 6223.00, Accuracy = 0.59, Loss = 1.307
[2019-05-03 22:42] Train Step 952000/1000000, Batch Size = 64, Examples/Sec = 6204.30, Accuracy = 0.58, Loss = 1.302
[2019-05-03 22:42] Train Step 953000/1000000, Batch Size = 64, Examples/Sec = 6227.19, Accuracy = 0.58, Loss = 1.323
[2019-05-03 22:43] Train Step 954000/1000000, Batch Size = 64, Examples/Sec = 6234.86, Accuracy = 0.58, Loss = 1.266
[2019-05-03 22:43] Train Step 955000/1000000, Batch Size = 64, Examples/Sec = 6204.88, Accuracy = 0.58, Loss = 1.283
[2019-05-03 22:43] Train Step 956000/1000000, Batch Size = 64, Examples/Sec = 6232.10, Accuracy = 0.58, Loss = 1.286
[2019-05-03 22:43] Train Step 957000/1000000, Batch Size = 64, Examples/Sec = 5889.20, Accuracy = 0.58, Loss = 1.254
[2019-05-03 22:43] Train Step 958000/1000000, Batch Size = 64, Examples/Sec = 6227.05, Accuracy = 0.60, Loss = 1.266
[2019-05-03 22:44] Train Step 959000/1000000, Batch Size = 64, Examples/Sec = 6220.98, Accuracy = 0.58, Loss = 1.256
[2019-05-03 22:44] Train Step 960000/1000000, Batch Size = 64, Examples/Sec = 6228.20, Accuracy = 0.59, Loss = 1.248
[2019-05-03 22:44] Train Step 961000/1000000, Batch Size = 64, Examples/Sec = 6227.33, Accuracy = 0.59, Loss = 1.260
[2019-05-03 22:44] Train Step 962000/1000000, Batch Size = 64, Examples/Sec = 6229.21, Accuracy = 0.58, Loss = 1.284
[2019-05-03 22:44] Train Step 963000/1000000, Batch Size = 64, Examples/Sec = 6181.59, Accuracy = 0.57, Loss = 1.314
[2019-05-03 22:45] Train Step 964000/1000000, Batch Size = 64, Examples/Sec = 6188.29, Accuracy = 0.60, Loss = 1.243
[2019-05-03 22:45] Train Step 965000/1000000, Batch Size = 64, Examples/Sec = 6218.25, Accuracy = 0.58, Loss = 1.270
[2019-05-03 22:45] Train Step 966000/1000000, Batch Size = 64, Examples/Sec = 6232.39, Accuracy = 0.59, Loss = 1.243
[2019-05-03 22:45] Train Step 967000/1000000, Batch Size = 64, Examples/Sec = 6218.97, Accuracy = 0.57, Loss = 1.323
[2019-05-03 22:45] Train Step 968000/1000000, Batch Size = 64, Examples/Sec = 6209.90, Accuracy = 0.57, Loss = 1.277
[2019-05-03 22:46] Train Step 969000/1000000, Batch Size = 64, Examples/Sec = 6238.04, Accuracy = 0.58, Loss = 1.261
[2019-05-03 22:46] Train Step 970000/1000000, Batch Size = 64, Examples/Sec = 6245.88, Accuracy = 0.60, Loss = 1.248
[2019-05-03 22:46] Train Step 971000/1000000, Batch Size = 64, Examples/Sec = 6195.00, Accuracy = 0.60, Loss = 1.237
[2019-05-03 22:46] Train Step 972000/1000000, Batch Size = 64, Examples/Sec = 6228.35, Accuracy = 0.56, Loss = 1.324
[2019-05-03 22:46] Train Step 973000/1000000, Batch Size = 64, Examples/Sec = 6206.60, Accuracy = 0.56, Loss = 1.342
[2019-05-03 22:47] Train Step 974000/1000000, Batch Size = 64, Examples/Sec = 6234.57, Accuracy = 0.59, Loss = 1.253
[2019-05-03 22:47] Train Step 975000/1000000, Batch Size = 64, Examples/Sec = 6208.75, Accuracy = 0.58, Loss = 1.270
[2019-05-03 22:47] Train Step 976000/1000000, Batch Size = 64, Examples/Sec = 6210.91, Accuracy = 0.56, Loss = 1.296
[2019-05-03 22:47] Train Step 977000/1000000, Batch Size = 64, Examples/Sec = 6212.78, Accuracy = 0.57, Loss = 1.306
[2019-05-03 22:47] Train Step 978000/1000000, Batch Size = 64, Examples/Sec = 6240.65, Accuracy = 0.59, Loss = 1.259
[2019-05-03 22:48] Train Step 979000/1000000, Batch Size = 64, Examples/Sec = 6240.22, Accuracy = 0.57, Loss = 1.279
[2019-05-03 22:48] Train Step 980000/1000000, Batch Size = 64, Examples/Sec = 6221.85, Accuracy = 0.59, Loss = 1.270
[2019-05-03 22:48] Train Step 981000/1000000, Batch Size = 64, Examples/Sec = 6217.96, Accuracy = 0.55, Loss = 1.329
[2019-05-03 22:48] Train Step 982000/1000000, Batch Size = 64, Examples/Sec = 6232.25, Accuracy = 0.58, Loss = 1.314
[2019-05-03 22:48] Train Step 983000/1000000, Batch Size = 64, Examples/Sec = 6223.72, Accuracy = 0.59, Loss = 1.273
[2019-05-03 22:49] Train Step 984000/1000000, Batch Size = 64, Examples/Sec = 6218.97, Accuracy = 0.59, Loss = 1.267
[2019-05-03 22:49] Train Step 985000/1000000, Batch Size = 64, Examples/Sec = 6230.22, Accuracy = 0.59, Loss = 1.243
[2019-05-03 22:49] Train Step 986000/1000000, Batch Size = 64, Examples/Sec = 6263.81, Accuracy = 0.56, Loss = 1.305
[2019-05-03 22:49] Train Step 987000/1000000, Batch Size = 64, Examples/Sec = 6212.92, Accuracy = 0.59, Loss = 1.241
[2019-05-03 22:50] Train Step 988000/1000000, Batch Size = 64, Examples/Sec = 6223.44, Accuracy = 0.58, Loss = 1.281
[2019-05-03 22:50] Train Step 989000/1000000, Batch Size = 64, Examples/Sec = 6225.75, Accuracy = 0.58, Loss = 1.245
[2019-05-03 22:50] Train Step 990000/1000000, Batch Size = 64, Examples/Sec = 6194.43, Accuracy = 0.58, Loss = 1.242
[2019-05-03 22:50] Train Step 991000/1000000, Batch Size = 64, Examples/Sec = 6205.45, Accuracy = 0.59, Loss = 1.259
[2019-05-03 22:50] Train Step 992000/1000000, Batch Size = 64, Examples/Sec = 6228.35, Accuracy = 0.59, Loss = 1.273
[2019-05-03 22:51] Train Step 993000/1000000, Batch Size = 64, Examples/Sec = 6241.96, Accuracy = 0.58, Loss = 1.332
[2019-05-03 22:51] Train Step 994000/1000000, Batch Size = 64, Examples/Sec = 6242.39, Accuracy = 0.58, Loss = 1.291
[2019-05-03 22:51] Train Step 995000/1000000, Batch Size = 64, Examples/Sec = 6201.58, Accuracy = 0.59, Loss = 1.247
[2019-05-03 22:51] Train Step 996000/1000000, Batch Size = 64, Examples/Sec = 6222.28, Accuracy = 0.57, Loss = 1.279
[2019-05-03 22:51] Train Step 997000/1000000, Batch Size = 64, Examples/Sec = 6226.03, Accuracy = 0.59, Loss = 1.289
[2019-05-03 22:52] Train Step 998000/1000000, Batch Size = 64, Examples/Sec = 6165.69, Accuracy = 0.58, Loss = 1.302
[2019-05-03 22:52] Train Step 999000/1000000, Batch Size = 64, Examples/Sec = 6224.45, Accuracy = 0.59, Loss = 1.266
[2019-05-03 22:52] Train Step 1000000/1000000, Batch Size = 64, Examples/Sec = 6207.17, Accuracy = 0.58, Loss = 1.291
Saved model.
Done training.
**************************************************************
